






ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¸ã‚¹ã‚­ãƒƒãƒ—
ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³ã«ç§»å‹•










					e-dash



è³‡æ–™è«‹æ±‚ãƒ‡ãƒ¢äºˆç´„å°‚é–€å®¶ã«ç›¸è«‡ãƒ­ã‚°ã‚¤ãƒ³
ãƒ‹ãƒ¥ãƒ¼ã‚¹News
ãƒ—ãƒ­ãƒ€ã‚¯ãƒˆProducts
ã‚»ãƒŸãƒŠãƒ¼Seminar
ã‚¹ãƒˆãƒ¼ãƒªãƒ¼Story
ãŠå½¹ç«‹ã¡è³‡æ–™White Paper
é‹å–¶ä¼šç¤¾Company
å³å´ã«é…ç½®ã™ã‚‹ãƒ¡ãƒ‹ãƒ¥ãƒ¼

è³‡æ–™è«‹æ±‚
ãƒ‡ãƒ¢äºˆç´„
å°‚é–€å®¶ã«ç›¸è«‡
ãƒ­ã‚°ã‚¤ãƒ³





ç„¡æ–™
ãŠå•ã„åˆã‚ã›













e-dashã®ã‚µãƒ¼ãƒ“ã‚¹æ¦‚è¦ã‚„å°å…¥å¾Œã®ã‚µãƒãƒ¼ãƒˆã®æµã‚Œãªã©ã‚’ã”è¦§ã„ãŸã ã‘ã¾ã™
è³‡æ–™è«‹æ±‚ã¸







å®Ÿéš›ã®åˆ©ç”¨ç”»é¢ã‚’ã”è¦§ã„ãŸã ããªãŒã‚‰ã€Œe-dashã€ã‚’èª¬æ˜ã—ã¾ã™
ãƒ‡ãƒ¢äºˆç´„ã¸







e-dashã®å°‚é–€å®¶ãƒãƒ¼ãƒ ã¸ãŠå›°ã‚Šã®å†…å®¹ã‚’ãŠæ°—è»½ã«ã”ç›¸è«‡ãã ã•ã„
å°‚é–€å®¶ç›¸è«‡ã¸







				ãƒ­ã‚°ã‚¤ãƒ³






seminarã‚»ãƒŸãƒŠãƒ¼
ãƒˆãƒƒãƒ—/ã‚»ãƒŸãƒŠãƒ¼

















SHARE
























				ã‚ã‚‰ã‚†ã‚‹ä¼æ¥­ãŒã€è‡ªç¤¾ã«é©ã—ãŸé“ç­‹ã§
				äº‹æ¥­ã®æˆé•·ã¨è„±ç‚­ç´ åŒ–ã‚’ä¸¡æ–¹å®Ÿç¾ã§ãã‚‹ã‚ˆã†ã«ã€‚



				ã”å¸Œæœ›ã®ãŠå–ã‚Šçµ„ã¿å†…å®¹ã«å¿œã˜ãŸã”ææ¡ˆãŒå¯èƒ½ã§ã™ã€‚è©³ã—ãã¯ãŠå•ã„åˆã‚ã›ãã ã•ã„ã€‚




è³‡æ–™ã‚’è«‹æ±‚ã™ã‚‹


ãƒ‡ãƒ¢ã‚’äºˆç´„ã™ã‚‹


å°‚é–€å®¶ã«ç›¸è«‡ã™ã‚‹











ãƒ‹ãƒ¥ãƒ¼ã‚¹News
ãƒ—ãƒ­ãƒ€ã‚¯ãƒˆProducts
ã‚»ãƒŸãƒŠãƒ¼Seminar
ã‚¹ãƒˆãƒ¼ãƒªãƒ¼Story
ãŠå½¹ç«‹ã¡è³‡æ–™White Paper






PRODUCT-SITE
å¤–éƒ¨ã‚µã‚¤ãƒˆã¸é·ç§»ã—ã¾ã™ã€‚





























é‹å–¶ä¼šç¤¾


ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ãƒãƒªã‚·ãƒ¼


accel.


accel DB


Carbon Offset





èªè¨¼ç•ªå·ï¼šJP23/00000419

					ã€’107-0052
					æ±äº¬éƒ½æ¸¯åŒºèµ¤å‚å››ä¸ç›®8ç•ª18å·
					èµ¤å‚JEBL 6éš



				Â© 2023 e-dash Co., Ltd.



MENUãƒ‹ãƒ¥ãƒ¼ã‚¹News
ãƒ—ãƒ­ãƒ€ã‚¯ãƒˆProducts
ã‚»ãƒŸãƒŠãƒ¼Seminar
ã‚¹ãƒˆãƒ¼ãƒªãƒ¼Story
ãŠå½¹ç«‹ã¡è³‡æ–™White Paper
é‹å–¶ä¼šç¤¾Company
å³å´ã«é…ç½®ã™ã‚‹ãƒ¡ãƒ‹ãƒ¥ãƒ¼

è³‡æ–™è«‹æ±‚
ãƒ‡ãƒ¢äºˆç´„
å°‚é–€å®¶ã«ç›¸è«‡
ãƒ­ã‚°ã‚¤ãƒ³








ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¸ã‚¹ã‚­ãƒƒãƒ—
ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³ã«ç§»å‹•





					e-dash



è³‡æ–™è«‹æ±‚ãƒ‡ãƒ¢äºˆç´„å°‚é–€å®¶ã«ç›¸è«‡ãƒ­ã‚°ã‚¤ãƒ³
ãƒ‹ãƒ¥ãƒ¼ã‚¹News
ãƒ—ãƒ­ãƒ€ã‚¯ãƒˆProducts
ã‚»ãƒŸãƒŠãƒ¼Seminar
ã‚¹ãƒˆãƒ¼ãƒªãƒ¼Story
ãŠå½¹ç«‹ã¡è³‡æ–™White Paper
é‹å–¶ä¼šç¤¾Company
å³å´ã«é…ç½®ã™ã‚‹ãƒ¡ãƒ‹ãƒ¥ãƒ¼

è³‡æ–™è«‹æ±‚
ãƒ‡ãƒ¢äºˆç´„
å°‚é–€å®¶ã«ç›¸è«‡
ãƒ­ã‚°ã‚¤ãƒ³





ç„¡æ–™
ãŠå•ã„åˆã‚ã›













e-dashã®ã‚µãƒ¼ãƒ“ã‚¹æ¦‚è¦ã‚„å°å…¥å¾Œã®ã‚µãƒãƒ¼ãƒˆã®æµã‚Œãªã©ã‚’ã”è¦§ã„ãŸã ã‘ã¾ã™
è³‡æ–™è«‹æ±‚ã¸







å®Ÿéš›ã®åˆ©ç”¨ç”»é¢ã‚’ã”è¦§ã„ãŸã ããªãŒã‚‰ã€Œe-dashã€ã‚’èª¬æ˜ã—ã¾ã™
ãƒ‡ãƒ¢äºˆç´„ã¸







e-dashã®å°‚é–€å®¶ãƒãƒ¼ãƒ ã¸ãŠå›°ã‚Šã®å†…å®¹ã‚’ãŠæ°—è»½ã«ã”ç›¸è«‡ãã ã•ã„
å°‚é–€å®¶ç›¸è«‡ã¸







				ãƒ­ã‚°ã‚¤ãƒ³








					e-dash



è³‡æ–™è«‹æ±‚ãƒ‡ãƒ¢äºˆç´„å°‚é–€å®¶ã«ç›¸è«‡ãƒ­ã‚°ã‚¤ãƒ³
ãƒ‹ãƒ¥ãƒ¼ã‚¹News
ãƒ—ãƒ­ãƒ€ã‚¯ãƒˆProducts
ã‚»ãƒŸãƒŠãƒ¼Seminar
ã‚¹ãƒˆãƒ¼ãƒªãƒ¼Story
ãŠå½¹ç«‹ã¡è³‡æ–™White Paper
é‹å–¶ä¼šç¤¾Company
å³å´ã«é…ç½®ã™ã‚‹ãƒ¡ãƒ‹ãƒ¥ãƒ¼

è³‡æ–™è«‹æ±‚
ãƒ‡ãƒ¢äºˆç´„
å°‚é–€å®¶ã«ç›¸è«‡
ãƒ­ã‚°ã‚¤ãƒ³





ç„¡æ–™
ãŠå•ã„åˆã‚ã›













e-dashã®ã‚µãƒ¼ãƒ“ã‚¹æ¦‚è¦ã‚„å°å…¥å¾Œã®ã‚µãƒãƒ¼ãƒˆã®æµã‚Œãªã©ã‚’ã”è¦§ã„ãŸã ã‘ã¾ã™
è³‡æ–™è«‹æ±‚ã¸







å®Ÿéš›ã®åˆ©ç”¨ç”»é¢ã‚’ã”è¦§ã„ãŸã ããªãŒã‚‰ã€Œe-dashã€ã‚’èª¬æ˜ã—ã¾ã™
ãƒ‡ãƒ¢äºˆç´„ã¸







e-dashã®å°‚é–€å®¶ãƒãƒ¼ãƒ ã¸ãŠå›°ã‚Šã®å†…å®¹ã‚’ãŠæ°—è»½ã«ã”ç›¸è«‡ãã ã•ã„
å°‚é–€å®¶ç›¸è«‡ã¸







				ãƒ­ã‚°ã‚¤ãƒ³






					e-dash



è³‡æ–™è«‹æ±‚ãƒ‡ãƒ¢äºˆç´„å°‚é–€å®¶ã«ç›¸è«‡ãƒ­ã‚°ã‚¤ãƒ³
è³‡æ–™è«‹æ±‚
ãƒ‡ãƒ¢äºˆç´„
å°‚é–€å®¶ã«ç›¸è«‡
ãƒ­ã‚°ã‚¤ãƒ³
ãƒ‹ãƒ¥ãƒ¼ã‚¹News
ãƒ—ãƒ­ãƒ€ã‚¯ãƒˆProducts
ã‚»ãƒŸãƒŠãƒ¼Seminar
ã‚¹ãƒˆãƒ¼ãƒªãƒ¼Story
ãŠå½¹ç«‹ã¡è³‡æ–™White Paper
é‹å–¶ä¼šç¤¾Company
å³å´ã«é…ç½®ã™ã‚‹ãƒ¡ãƒ‹ãƒ¥ãƒ¼

è³‡æ–™è«‹æ±‚
ãƒ‡ãƒ¢äºˆç´„
å°‚é–€å®¶ã«ç›¸è«‡
ãƒ­ã‚°ã‚¤ãƒ³



ãƒ‹ãƒ¥ãƒ¼ã‚¹News
ãƒ—ãƒ­ãƒ€ã‚¯ãƒˆProducts
ã‚»ãƒŸãƒŠãƒ¼Seminar
ã‚¹ãƒˆãƒ¼ãƒªãƒ¼Story
ãŠå½¹ç«‹ã¡è³‡æ–™White Paper
é‹å–¶ä¼šç¤¾Company
å³å´ã«é…ç½®ã™ã‚‹ãƒ¡ãƒ‹ãƒ¥ãƒ¼

è³‡æ–™è«‹æ±‚
ãƒ‡ãƒ¢äºˆç´„
å°‚é–€å®¶ã«ç›¸è«‡
ãƒ­ã‚°ã‚¤ãƒ³



ãƒ‹ãƒ¥ãƒ¼ã‚¹News
ãƒ‹ãƒ¥ãƒ¼ã‚¹
News
ãƒ—ãƒ­ãƒ€ã‚¯ãƒˆProducts
ãƒ—ãƒ­ãƒ€ã‚¯ãƒˆ
Products
ã‚»ãƒŸãƒŠãƒ¼Seminar
ã‚»ãƒŸãƒŠãƒ¼
Seminar
ã‚¹ãƒˆãƒ¼ãƒªãƒ¼Story
ã‚¹ãƒˆãƒ¼ãƒªãƒ¼
Story
ãŠå½¹ç«‹ã¡è³‡æ–™White Paper
ãŠå½¹ç«‹ã¡è³‡æ–™
White Paper
é‹å–¶ä¼šç¤¾Company
é‹å–¶ä¼šç¤¾
Company
å³å´ã«é…ç½®ã™ã‚‹ãƒ¡ãƒ‹ãƒ¥ãƒ¼

è³‡æ–™è«‹æ±‚
ãƒ‡ãƒ¢äºˆç´„
å°‚é–€å®¶ã«ç›¸è«‡
ãƒ­ã‚°ã‚¤ãƒ³


å³å´ã«é…ç½®ã™ã‚‹ãƒ¡ãƒ‹ãƒ¥ãƒ¼

è³‡æ–™è«‹æ±‚
ãƒ‡ãƒ¢äºˆç´„
å°‚é–€å®¶ã«ç›¸è«‡
ãƒ­ã‚°ã‚¤ãƒ³

è³‡æ–™è«‹æ±‚
ãƒ‡ãƒ¢äºˆç´„
å°‚é–€å®¶ã«ç›¸è«‡
ãƒ­ã‚°ã‚¤ãƒ³



ç„¡æ–™
ãŠå•ã„åˆã‚ã›













e-dashã®ã‚µãƒ¼ãƒ“ã‚¹æ¦‚è¦ã‚„å°å…¥å¾Œã®ã‚µãƒãƒ¼ãƒˆã®æµã‚Œãªã©ã‚’ã”è¦§ã„ãŸã ã‘ã¾ã™
è³‡æ–™è«‹æ±‚ã¸







å®Ÿéš›ã®åˆ©ç”¨ç”»é¢ã‚’ã”è¦§ã„ãŸã ããªãŒã‚‰ã€Œe-dashã€ã‚’èª¬æ˜ã—ã¾ã™
ãƒ‡ãƒ¢äºˆç´„ã¸







e-dashã®å°‚é–€å®¶ãƒãƒ¼ãƒ ã¸ãŠå›°ã‚Šã®å†…å®¹ã‚’ãŠæ°—è»½ã«ã”ç›¸è«‡ãã ã•ã„
å°‚é–€å®¶ç›¸è«‡ã¸







				ãƒ­ã‚°ã‚¤ãƒ³




ç„¡æ–™
ãŠå•ã„åˆã‚ã›













e-dashã®ã‚µãƒ¼ãƒ“ã‚¹æ¦‚è¦ã‚„å°å…¥å¾Œã®ã‚µãƒãƒ¼ãƒˆã®æµã‚Œãªã©ã‚’ã”è¦§ã„ãŸã ã‘ã¾ã™
è³‡æ–™è«‹æ±‚ã¸







å®Ÿéš›ã®åˆ©ç”¨ç”»é¢ã‚’ã”è¦§ã„ãŸã ããªãŒã‚‰ã€Œe-dashã€ã‚’èª¬æ˜ã—ã¾ã™
ãƒ‡ãƒ¢äºˆç´„ã¸







e-dashã®å°‚é–€å®¶ãƒãƒ¼ãƒ ã¸ãŠå›°ã‚Šã®å†…å®¹ã‚’ãŠæ°—è»½ã«ã”ç›¸è«‡ãã ã•ã„
å°‚é–€å®¶ç›¸è«‡ã¸







ç„¡æ–™
ãŠå•ã„åˆã‚ã›





ç„¡æ–™
ãŠå•ã„åˆã‚ã›












e-dashã®ã‚µãƒ¼ãƒ“ã‚¹æ¦‚è¦ã‚„å°å…¥å¾Œã®ã‚µãƒãƒ¼ãƒˆã®æµã‚Œãªã©ã‚’ã”è¦§ã„ãŸã ã‘ã¾ã™
è³‡æ–™è«‹æ±‚ã¸







å®Ÿéš›ã®åˆ©ç”¨ç”»é¢ã‚’ã”è¦§ã„ãŸã ããªãŒã‚‰ã€Œe-dashã€ã‚’èª¬æ˜ã—ã¾ã™
ãƒ‡ãƒ¢äºˆç´„ã¸







e-dashã®å°‚é–€å®¶ãƒãƒ¼ãƒ ã¸ãŠå›°ã‚Šã®å†…å®¹ã‚’ãŠæ°—è»½ã«ã”ç›¸è«‡ãã ã•ã„
å°‚é–€å®¶ç›¸è«‡ã¸












e-dashã®ã‚µãƒ¼ãƒ“ã‚¹æ¦‚è¦ã‚„å°å…¥å¾Œã®ã‚µãƒãƒ¼ãƒˆã®æµã‚Œãªã©ã‚’ã”è¦§ã„ãŸã ã‘ã¾ã™
è³‡æ–™è«‹æ±‚ã¸







å®Ÿéš›ã®åˆ©ç”¨ç”»é¢ã‚’ã”è¦§ã„ãŸã ããªãŒã‚‰ã€Œe-dashã€ã‚’èª¬æ˜ã—ã¾ã™
ãƒ‡ãƒ¢äºˆç´„ã¸







e-dashã®å°‚é–€å®¶ãƒãƒ¼ãƒ ã¸ãŠå›°ã‚Šã®å†…å®¹ã‚’ãŠæ°—è»½ã«ã”ç›¸è«‡ãã ã•ã„
å°‚é–€å®¶ç›¸è«‡ã¸










e-dashã®ã‚µãƒ¼ãƒ“ã‚¹æ¦‚è¦ã‚„å°å…¥å¾Œã®ã‚µãƒãƒ¼ãƒˆã®æµã‚Œãªã©ã‚’ã”è¦§ã„ãŸã ã‘ã¾ã™
è³‡æ–™è«‹æ±‚ã¸







å®Ÿéš›ã®åˆ©ç”¨ç”»é¢ã‚’ã”è¦§ã„ãŸã ããªãŒã‚‰ã€Œe-dashã€ã‚’èª¬æ˜ã—ã¾ã™
ãƒ‡ãƒ¢äºˆç´„ã¸







e-dashã®å°‚é–€å®¶ãƒãƒ¼ãƒ ã¸ãŠå›°ã‚Šã®å†…å®¹ã‚’ãŠæ°—è»½ã«ã”ç›¸è«‡ãã ã•ã„
å°‚é–€å®¶ç›¸è«‡ã¸








e-dashã®ã‚µãƒ¼ãƒ“ã‚¹æ¦‚è¦ã‚„å°å…¥å¾Œã®ã‚µãƒãƒ¼ãƒˆã®æµã‚Œãªã©ã‚’ã”è¦§ã„ãŸã ã‘ã¾ã™
è³‡æ–™è«‹æ±‚ã¸






e-dashã®ã‚µãƒ¼ãƒ“ã‚¹æ¦‚è¦ã‚„å°å…¥å¾Œã®ã‚µãƒãƒ¼ãƒˆã®æµã‚Œãªã©ã‚’ã”è¦§ã„ãŸã ã‘ã¾ã™
è³‡æ–™è«‹æ±‚ã¸





e-dashã®ã‚µãƒ¼ãƒ“ã‚¹æ¦‚è¦ã‚„å°å…¥å¾Œã®ã‚µãƒãƒ¼ãƒˆã®æµã‚Œãªã©ã‚’ã”è¦§ã„ãŸã ã‘ã¾ã™
è³‡æ–™è«‹æ±‚ã¸





å®Ÿéš›ã®åˆ©ç”¨ç”»é¢ã‚’ã”è¦§ã„ãŸã ããªãŒã‚‰ã€Œe-dashã€ã‚’èª¬æ˜ã—ã¾ã™
ãƒ‡ãƒ¢äºˆç´„ã¸






å®Ÿéš›ã®åˆ©ç”¨ç”»é¢ã‚’ã”è¦§ã„ãŸã ããªãŒã‚‰ã€Œe-dashã€ã‚’èª¬æ˜ã—ã¾ã™
ãƒ‡ãƒ¢äºˆç´„ã¸





å®Ÿéš›ã®åˆ©ç”¨ç”»é¢ã‚’ã”è¦§ã„ãŸã ããªãŒã‚‰ã€Œe-dashã€ã‚’èª¬æ˜ã—ã¾ã™
ãƒ‡ãƒ¢äºˆç´„ã¸





e-dashã®å°‚é–€å®¶ãƒãƒ¼ãƒ ã¸ãŠå›°ã‚Šã®å†…å®¹ã‚’ãŠæ°—è»½ã«ã”ç›¸è«‡ãã ã•ã„
å°‚é–€å®¶ç›¸è«‡ã¸






e-dashã®å°‚é–€å®¶ãƒãƒ¼ãƒ ã¸ãŠå›°ã‚Šã®å†…å®¹ã‚’ãŠæ°—è»½ã«ã”ç›¸è«‡ãã ã•ã„
å°‚é–€å®¶ç›¸è«‡ã¸





e-dashã®å°‚é–€å®¶ãƒãƒ¼ãƒ ã¸ãŠå›°ã‚Šã®å†…å®¹ã‚’ãŠæ°—è»½ã«ã”ç›¸è«‡ãã ã•ã„
å°‚é–€å®¶ç›¸è«‡ã¸

				ãƒ­ã‚°ã‚¤ãƒ³



seminarã‚»ãƒŸãƒŠãƒ¼
ãƒˆãƒƒãƒ—/ã‚»ãƒŸãƒŠãƒ¼



seminarã‚»ãƒŸãƒŠãƒ¼
ãƒˆãƒƒãƒ—/ã‚»ãƒŸãƒŠãƒ¼

seminarã‚»ãƒŸãƒŠãƒ¼
seminar
ã‚»ãƒŸãƒŠãƒ¼

ãƒˆãƒƒãƒ—/ã‚»ãƒŸãƒŠãƒ¼
/
ã‚»ãƒŸãƒŠãƒ¼















SHARE


































SHARE
































SHARE





























SHARE

























SHARE























SHARE






















SHARE


















				ã‚ã‚‰ã‚†ã‚‹ä¼æ¥­ãŒã€è‡ªç¤¾ã«é©ã—ãŸé“ç­‹ã§
				äº‹æ¥­ã®æˆé•·ã¨è„±ç‚­ç´ åŒ–ã‚’ä¸¡æ–¹å®Ÿç¾ã§ãã‚‹ã‚ˆã†ã«ã€‚



				ã”å¸Œæœ›ã®ãŠå–ã‚Šçµ„ã¿å†…å®¹ã«å¿œã˜ãŸã”ææ¡ˆãŒå¯èƒ½ã§ã™ã€‚è©³ã—ãã¯ãŠå•ã„åˆã‚ã›ãã ã•ã„ã€‚




è³‡æ–™ã‚’è«‹æ±‚ã™ã‚‹


ãƒ‡ãƒ¢ã‚’äºˆç´„ã™ã‚‹


å°‚é–€å®¶ã«ç›¸è«‡ã™ã‚‹







				ã‚ã‚‰ã‚†ã‚‹ä¼æ¥­ãŒã€è‡ªç¤¾ã«é©ã—ãŸé“ç­‹ã§
				äº‹æ¥­ã®æˆé•·ã¨è„±ç‚­ç´ åŒ–ã‚’ä¸¡æ–¹å®Ÿç¾ã§ãã‚‹ã‚ˆã†ã«ã€‚



				ã”å¸Œæœ›ã®ãŠå–ã‚Šçµ„ã¿å†…å®¹ã«å¿œã˜ãŸã”ææ¡ˆãŒå¯èƒ½ã§ã™ã€‚è©³ã—ãã¯ãŠå•ã„åˆã‚ã›ãã ã•ã„ã€‚




è³‡æ–™ã‚’è«‹æ±‚ã™ã‚‹


ãƒ‡ãƒ¢ã‚’äºˆç´„ã™ã‚‹


å°‚é–€å®¶ã«ç›¸è«‡ã™ã‚‹





				ã‚ã‚‰ã‚†ã‚‹ä¼æ¥­ãŒã€è‡ªç¤¾ã«é©ã—ãŸé“ç­‹ã§
				äº‹æ¥­ã®æˆé•·ã¨è„±ç‚­ç´ åŒ–ã‚’ä¸¡æ–¹å®Ÿç¾ã§ãã‚‹ã‚ˆã†ã«ã€‚



				ã”å¸Œæœ›ã®ãŠå–ã‚Šçµ„ã¿å†…å®¹ã«å¿œã˜ãŸã”ææ¡ˆãŒå¯èƒ½ã§ã™ã€‚è©³ã—ãã¯ãŠå•ã„åˆã‚ã›ãã ã•ã„ã€‚



				ã”å¸Œæœ›ã®ãŠå–ã‚Šçµ„ã¿å†…å®¹ã«å¿œã˜ãŸã”ææ¡ˆãŒå¯èƒ½ã§ã™ã€‚è©³ã—ãã¯ãŠå•ã„åˆã‚ã›ãã ã•ã„ã€‚




è³‡æ–™ã‚’è«‹æ±‚ã™ã‚‹


ãƒ‡ãƒ¢ã‚’äºˆç´„ã™ã‚‹


å°‚é–€å®¶ã«ç›¸è«‡ã™ã‚‹









ãƒ‹ãƒ¥ãƒ¼ã‚¹News
ãƒ—ãƒ­ãƒ€ã‚¯ãƒˆProducts
ã‚»ãƒŸãƒŠãƒ¼Seminar
ã‚¹ãƒˆãƒ¼ãƒªãƒ¼Story
ãŠå½¹ç«‹ã¡è³‡æ–™White Paper









ãƒ‹ãƒ¥ãƒ¼ã‚¹News
ãƒ—ãƒ­ãƒ€ã‚¯ãƒˆProducts
ã‚»ãƒŸãƒŠãƒ¼Seminar
ã‚¹ãƒˆãƒ¼ãƒªãƒ¼Story
ãŠå½¹ç«‹ã¡è³‡æ–™White Paper







ãƒ‹ãƒ¥ãƒ¼ã‚¹News
ãƒ—ãƒ­ãƒ€ã‚¯ãƒˆProducts
ã‚»ãƒŸãƒŠãƒ¼Seminar
ã‚¹ãƒˆãƒ¼ãƒªãƒ¼Story
ãŠå½¹ç«‹ã¡è³‡æ–™White Paper

ãƒ‹ãƒ¥ãƒ¼ã‚¹News
ãƒ—ãƒ­ãƒ€ã‚¯ãƒˆProducts
ã‚»ãƒŸãƒŠãƒ¼Seminar
ã‚¹ãƒˆãƒ¼ãƒªãƒ¼Story
ãŠå½¹ç«‹ã¡è³‡æ–™White Paper

ãƒ‹ãƒ¥ãƒ¼ã‚¹News
ãƒ—ãƒ­ãƒ€ã‚¯ãƒˆProducts
ã‚»ãƒŸãƒŠãƒ¼Seminar
ã‚¹ãƒˆãƒ¼ãƒªãƒ¼Story
ãŠå½¹ç«‹ã¡è³‡æ–™White Paper

ãƒ‹ãƒ¥ãƒ¼ã‚¹News
ãƒ‹ãƒ¥ãƒ¼ã‚¹
News
ãƒ—ãƒ­ãƒ€ã‚¯ãƒˆProducts
ãƒ—ãƒ­ãƒ€ã‚¯ãƒˆ
Products
ã‚»ãƒŸãƒŠãƒ¼Seminar
ã‚»ãƒŸãƒŠãƒ¼
Seminar
ã‚¹ãƒˆãƒ¼ãƒªãƒ¼Story
ã‚¹ãƒˆãƒ¼ãƒªãƒ¼
Story
ãŠå½¹ç«‹ã¡è³‡æ–™White Paper
ãŠå½¹ç«‹ã¡è³‡æ–™
White Paper



PRODUCT-SITE
å¤–éƒ¨ã‚µã‚¤ãƒˆã¸é·ç§»ã—ã¾ã™ã€‚



























PRODUCT-SITE
å¤–éƒ¨ã‚µã‚¤ãƒˆã¸é·ç§»ã—ã¾ã™ã€‚

























PRODUCT-SITE
å¤–éƒ¨ã‚µã‚¤ãƒˆã¸é·ç§»ã—ã¾ã™ã€‚

PRODUCT-SITE
å¤–éƒ¨ã‚µã‚¤ãƒˆã¸é·ç§»ã—ã¾ã™ã€‚


















































é‹å–¶ä¼šç¤¾


ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ãƒãƒªã‚·ãƒ¼


accel.


accel DB


Carbon Offset





èªè¨¼ç•ªå·ï¼šJP23/00000419

					ã€’107-0052
					æ±äº¬éƒ½æ¸¯åŒºèµ¤å‚å››ä¸ç›®8ç•ª18å·
					èµ¤å‚JEBL 6éš



				Â© 2023 e-dash Co., Ltd.







é‹å–¶ä¼šç¤¾


ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ãƒãƒªã‚·ãƒ¼


accel.


accel DB


Carbon Offset





èªè¨¼ç•ªå·ï¼šJP23/00000419

					ã€’107-0052
					æ±äº¬éƒ½æ¸¯åŒºèµ¤å‚å››ä¸ç›®8ç•ª18å·
					èµ¤å‚JEBL 6éš



				Â© 2023 e-dash Co., Ltd.





é‹å–¶ä¼šç¤¾


ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ãƒãƒªã‚·ãƒ¼


accel.


accel DB


Carbon Offset





èªè¨¼ç•ªå·ï¼šJP23/00000419

					ã€’107-0052
					æ±äº¬éƒ½æ¸¯åŒºèµ¤å‚å››ä¸ç›®8ç•ª18å·
					èµ¤å‚JEBL 6éš



				Â© 2023 e-dash Co., Ltd.




èªè¨¼ç•ªå·ï¼šJP23/00000419

					ã€’107-0052
					æ±äº¬éƒ½æ¸¯åŒºèµ¤å‚å››ä¸ç›®8ç•ª18å·
					èµ¤å‚JEBL 6éš




					ã€’107-0052
					æ±äº¬éƒ½æ¸¯åŒºèµ¤å‚å››ä¸ç›®8ç•ª18å·
					èµ¤å‚JEBL 6éš


				Â© 2023 e-dash Co., Ltd.

MENU
ãƒ‹ãƒ¥ãƒ¼ã‚¹News
ãƒ—ãƒ­ãƒ€ã‚¯ãƒˆProducts
ã‚»ãƒŸãƒŠãƒ¼Seminar
ã‚¹ãƒˆãƒ¼ãƒªãƒ¼Story
ãŠå½¹ç«‹ã¡è³‡æ–™White Paper
é‹å–¶ä¼šç¤¾Company
å³å´ã«é…ç½®ã™ã‚‹ãƒ¡ãƒ‹ãƒ¥ãƒ¼

è³‡æ–™è«‹æ±‚
ãƒ‡ãƒ¢äºˆç´„
å°‚é–€å®¶ã«ç›¸è«‡
ãƒ­ã‚°ã‚¤ãƒ³



ãƒ‹ãƒ¥ãƒ¼ã‚¹News
ãƒ—ãƒ­ãƒ€ã‚¯ãƒˆProducts
ã‚»ãƒŸãƒŠãƒ¼Seminar
ã‚¹ãƒˆãƒ¼ãƒªãƒ¼Story
ãŠå½¹ç«‹ã¡è³‡æ–™White Paper
é‹å–¶ä¼šç¤¾Company
å³å´ã«é…ç½®ã™ã‚‹ãƒ¡ãƒ‹ãƒ¥ãƒ¼

è³‡æ–™è«‹æ±‚
ãƒ‡ãƒ¢äºˆç´„
å°‚é–€å®¶ã«ç›¸è«‡
ãƒ­ã‚°ã‚¤ãƒ³



ãƒ‹ãƒ¥ãƒ¼ã‚¹News
ãƒ—ãƒ­ãƒ€ã‚¯ãƒˆProducts
ã‚»ãƒŸãƒŠãƒ¼Seminar
ã‚¹ãƒˆãƒ¼ãƒªãƒ¼Story
ãŠå½¹ç«‹ã¡è³‡æ–™White Paper
é‹å–¶ä¼šç¤¾Company
å³å´ã«é…ç½®ã™ã‚‹ãƒ¡ãƒ‹ãƒ¥ãƒ¼

è³‡æ–™è«‹æ±‚
ãƒ‡ãƒ¢äºˆç´„
å°‚é–€å®¶ã«ç›¸è«‡
ãƒ­ã‚°ã‚¤ãƒ³



ãƒ‹ãƒ¥ãƒ¼ã‚¹News
ãƒ‹ãƒ¥ãƒ¼ã‚¹
News
ãƒ—ãƒ­ãƒ€ã‚¯ãƒˆProducts
ãƒ—ãƒ­ãƒ€ã‚¯ãƒˆ
Products
ã‚»ãƒŸãƒŠãƒ¼Seminar
ã‚»ãƒŸãƒŠãƒ¼
Seminar
ã‚¹ãƒˆãƒ¼ãƒªãƒ¼Story
ã‚¹ãƒˆãƒ¼ãƒªãƒ¼
Story
ãŠå½¹ç«‹ã¡è³‡æ–™White Paper
ãŠå½¹ç«‹ã¡è³‡æ–™
White Paper
é‹å–¶ä¼šç¤¾Company
é‹å–¶ä¼šç¤¾
Company
å³å´ã«é…ç½®ã™ã‚‹ãƒ¡ãƒ‹ãƒ¥ãƒ¼

è³‡æ–™è«‹æ±‚
ãƒ‡ãƒ¢äºˆç´„
å°‚é–€å®¶ã«ç›¸è«‡
ãƒ­ã‚°ã‚¤ãƒ³


å³å´ã«é…ç½®ã™ã‚‹ãƒ¡ãƒ‹ãƒ¥ãƒ¼

è³‡æ–™è«‹æ±‚
ãƒ‡ãƒ¢äºˆç´„
å°‚é–€å®¶ã«ç›¸è«‡
ãƒ­ã‚°ã‚¤ãƒ³

è³‡æ–™è«‹æ±‚
ãƒ‡ãƒ¢äºˆç´„
å°‚é–€å®¶ã«ç›¸è«‡
ãƒ­ã‚°ã‚¤ãƒ³

headerZenn
divZenn
divZenn
aZenn
path
path
articleCykinso's Tech BlogCykinso's Tech BlogPublicationã¸ã®æŠ•ç¨¿ğŸ¦œğŸ¦œğŸ”— LangChain v0.2.5 + OpenAI ã§ã® RAG ã‚’ç”¨ã„ãŸ ChatBot å®Ÿè£…ä¾‹yamasaKit2024/06/20ã«å…¬é–‹2024/06/28chatbotOpenAILangChainLLMRAGtech
 èƒŒæ™¯
LangChain ã¯ OpenAI API ã‚’åˆ©ç”¨ã—è‡ªåˆ†ãŸã¡ãŒã‚„ã‚ŠãŸã„ã“ã¨ã‚’å®Ÿç¾ã™ã‚‹ã“ã¨ã«éå¸¸ã«ä¾¿åˆ©ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã§ã™ãŒãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚¢ãƒƒãƒ—ã«ã‚ˆã£ã¦ã‚¯ãƒ©ã‚¹åã‚„ã‚µãƒ–ãƒ©ã‚¤ãƒ–ãƒ©ãƒªåã®å¤‰æ›´ãŒã‚„ã‚„å¤šãå°‘ã—å¤ã„ Web è¨˜äº‹ã‚’å‚è€ƒã«ã—ã¦ã‚‚ã†ã¾ããƒ¯ãƒ¼ã‚¯ã—ãªã„ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚
ã“ã®è¨˜äº‹ã¯ 2024/6/20 ç¾åœ¨ã® LangChain (ãƒãƒ¼ã‚¸ãƒ§ãƒ³ 0.2.5) ã§ OpenAI API ã‚„ Azure OpenAI API ã‚’å‹•ã‹ã™ä¾‹ã¨ã—ã¦æ®‹ã—ã¦ãŠãã¾ã™ã€‚
åŒã˜ã‚ˆã†ãªã“ã¨ã‚’ã—ã‚ˆã†ã¨ã—ã¦ç§ã®ã‚ˆã†ã«è‹¦æˆ¦ã—ã¦ã„ã‚‹æ–¹ã®åŠ©ã‘ã«ãªã‚Œã°å¹¸ã„ã§ã™ã€‚

 ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ãªã©

pyproject.toml
python = ">=3.12,<3.13"
python-dotenv = "^1.0.1"
chromadb = "0.5.2"
langchain = "0.2.5"
langchain-cli = "0.0.25"
langchain-openai = "0.1.8"
langchain-community = "0.2.5"
langchain-chroma = "0.1.1"
langchainhub = "0.1.20"
streamlit = "1.35.0"

ğŸ’¡ Poetry ã§ Python ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’æŒ‡å®šã™ã‚‹æ™‚ã« ^3.12 ã¨ã™ã‚‹ã¨ lancghain-chroma ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã§ããªããªã‚‹ã®ã§ >=3.12,<3.13 ã¨ã—ã¾ã—ãŸã€‚
(langchain-chroma ã¯ >=3.12,<3.13 ã¨ã„ã†æŒ‡å®šãŒã‚ã‚Šã¾ã™)

 æ–¹æ³•
OpenAI API ã‚’ä½¿ã†å ´åˆã¨ AzureOpenAI API ã‚’ä½¿ã†å ´åˆã¯åŸºæœ¬åŒã˜ã“ã¨ã‚’ã™ã‚‹ã®ã§ã¾ãš OpenAI API ã‚’ä½¿ã†å ´åˆã‚’èª¬æ˜ã—ã€è¨˜äº‹ãŒé•·ããªã£ã¦ã—ã¾ã£ãŸã®ã§ã€å¾Œæ—¥åˆ¥è¨˜äº‹ã«ã¦ AzureOpenAI API ã‚’ä½¿ã†å ´åˆã¯ã©ã®éƒ¨åˆ†ã‚’ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆã—ãŸã‚‰ã‚ˆã„ã®ã‹ã‚’èª¬æ˜ã—ãŸã„ã¨æ€ã„ã¾ã™ã€‚
6/28 è¿½è¨˜) AzureOpenAI API ç‰ˆã®è¨˜äº‹ã‚‚æ›¸ãã¾ã—ãŸã®ã§ã‚ˆã‘ã‚Œã°ãœã²ã©ã†ã
https://zenn.dev/cykinso/articles/b055e33734d06b

 .env
ä»¥ä¸‹ã®ã‚ˆã†ã« .env ã‚’ç”¨æ„ã—ã¾ã™ã€‚
OPENAI_API_KEY=sk-XXXXXXXXXXXXXXXX
OPENAI_API_VERSION=2024-02-01
ã‚‚ã— OPENAI_API_KEY ã‚’ã¾ã å–å¾—ã—ã¦ã„ãªã„å ´åˆã¯ä»¥ä¸‹ã®æ–¹æ³•ã§å–å¾—ã—ã¦ãã ã•ã„ã€‚

 OPENAI_API_KEY
OPENAI_API_KEY ã¯ OpenAI ã® Dashboard ã§ä½œæˆã§ãã¾ã™ã€‚
(èª²é‡‘å¯¾è±¡ãªã®ã§ã”è‡ªèº«ã®è²¬ä»»ã®ã‚‚ã¨ã”åˆ©ç”¨ãã ã•ã„)

ã€Œ+ Create new secret keyã€ ã‚’æŠ¼ã™ã¨ãƒ¢ãƒ¼ãƒ€ãƒ«ãŒé–‹ãã®ã§å¾Œã‹ã‚‰åŒºåˆ¥ã§ãã‚‹ã‚ˆã†ãªåå‰ã‚’ã¤ã‘ã¦ ã€ŒCreate secret keyã€ ã‚’æŠ¼ã—ã¾ã™ã€‚

è¡¨ç¤ºã•ã‚Œã‚‹ API ã‚­ãƒ¼ã‚’ .env ã«ãƒ¡ãƒ¢ã—ã¦ãŠãã¾ã™ã€‚ ã€ŒDoneã€ ã‚’æŠ¼ã™ã¨ã‚‚ã†è¡¨ç¤ºã§ãã¾ã›ã‚“ã€‚


 ãƒ‡ãƒ¼ã‚¿
OpenAI ãŒã¾ã å­¦ç¿’ã—ã¦ã„ãªã•ãã†ãªãƒ‡ãƒ¼ã‚¿ã®ä¾‹ã¨ã—ã¦å¼Šç¤¾ Cykinso ã®ãƒ–ãƒ­ã‚°è¨˜äº‹ã®ã€Œä¼šç¤¾ã®ãƒ“ã‚¸ãƒ§ãƒ³ã‚’è©±ã—ã¦ã„ã‚‹ãƒšãƒ¼ã‚¸ã€ã‚’ä»Šå›ã¯ç”¨ã„ãŸã„ã¨æ€ã„ã¾ã™ã€‚
https://note.com/cykinso/n/n432d5ea70783
ğŸ’¡ ãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆã§å®Ÿè£…ã™ã‚‹å ´åˆã¯ã€å¥½ããªãƒãƒ³ã‚¬ãªã©ã®è©³ç´°ã‚’ãƒ†ã‚­ã‚¹ãƒˆã«ã¾ã¨ã‚ã¦ãƒ‡ãƒ¼ã‚¿ã¨ã™ã‚‹ã¨ãƒ¢ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³ã‚‚ä¸ŠãŒã‚‹ã¨æ€ã„ã¾ã™ã€‚
ã–ã£ã¨æ–‡ç« ã‚’ã‚³ãƒ”ãƒ¼ã—ã¦ä»¥ä¸‹ã®ã‚ˆã†ã«æ•´å½¢ã—ã¾ã—ãŸã€‚

note.txt
ç´°èŒå¢ã‹ã‚‰ã®æ–°ãŸãªæ°—ä»˜ãã‚’é€šã˜ã¦ã€æ–°ãƒ“ã‚¸ãƒ§ãƒ³ã‚’ç­–å®šã—ã¾ã—ãŸï¼
2023å¹´11æœˆã«ã‚µã‚¤ã‚­ãƒ³ã‚½ãƒ¼ã¯10æœŸç›®ã«å…¥ã‚Šã¾ã—ãŸã€‚é«˜é½¢åŒ–ç¤¾ä¼šã«ã‚ˆã‚‹ç¤¾ä¼šä¿éšœã¸ã®ä¸å®‰ãŒå‹Ÿã‚‹ç¾åœ¨ã€ç—…æ°—ã‚’æœªç„¶ã«é˜²ã0æ¬¡äºˆé˜²ã®é‡è¦æ€§ãŒé«˜ã¾ã£ã¦ã„ã¾ã™ã€‚ã€Œç´°èŒå¢ã§äººã€…ã‚’å¥åº·ã«ã€ã¨ã„ã†ãƒŸãƒƒã‚·ãƒ§ãƒ³ã«å‘ã‘ã¦ã€ã‚µã‚¤ã‚­ãƒ³ã‚½ãƒ¼ã¯æ–°ãŸãªãƒ“ã‚¸ãƒ§ãƒ³ã‚’åˆ¶å®šã—ã¾ã—ãŸã€‚
æ–°ã—ã„ãƒ“ã‚¸ãƒ§ãƒ³ã«ã¤ã„ã¦
ãƒ¼ãƒ“ã‚¸ãƒ§ãƒ³å¤‰æ›´ã§å…·ä½“çš„ã«ã©ã®å€‹æ‰€ãŒå¤‰æ›´ã—ãŸã‹ã‚’ã¾ãšã”ç´¹ä»‹ã—ã¾ã™ã€‚
ã“ã¡ã‚‰ãŒã‚µã‚¤ã‚­ãƒ³ã‚½ãƒ¼ã®ãƒŸãƒƒã‚·ãƒ§ãƒ³ï¼ˆMISSIONï¼‰ã€ãƒ“ã‚¸ãƒ§ãƒ³(VISION)ã€ãƒãƒªãƒ¥ãƒ¼(VALUE)ã«ãªã‚Šã¾ã™ã€‚
ç§ãŸã¡ãŒç›®æŒ‡ã—ç¶šã‘ã‚‹ã€Œç´°èŒå¢ã§äººã€…ã‚’å¥åº·ã«ã€ã¨ã„ã†ãƒŸãƒƒã‚·ãƒ§ãƒ³ã¯ãã®ã¾ã¾ã«ã€ãƒ“ã‚¸ãƒ§ãƒ³ã‚’æ–°ã—ãå¤‰æ›´è‡´ã—ã¾ã—ãŸã€‚

ï¼œã“ã‚Œã¾ã§ã®ãƒ“ã‚¸ãƒ§ãƒ³ï¼
èŒå¢ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã€Œæ¬¡ä¸–ä»£ã®ãƒ©ã‚¤ãƒ•ã‚¹ã‚¿ã‚¤ãƒ«ã€ã‚’æä¾›ã™ã‚‹ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã«ãªã‚‹

ï¼œæ–°ã—ã„ãƒ“ã‚¸ãƒ§ãƒ³ï¼
ç´°èŒå¢ã‹ã‚‰ã®æ–°ãŸãªæ°—ä»˜ãã‚’é€šã˜ã¦
ãƒ’ãƒˆã€ç¤¾ä¼šã€åœ°çƒç’°å¢ƒã‚’å¥åº·ã«ã™ã‚‹ã‚¨ã‚³ã‚·ã‚¹ãƒ†ãƒ ã‚’å®Ÿç¾ã™ã‚‹
æ–°ã—ã„ãƒ“ã‚¸ãƒ§ãƒ³ã§ã¯ã€ã‚µã‚¤ã‚­ãƒ³ã‚½ãƒ¼ãŒå½±éŸ¿ã‚’ä¸ãˆã¦ã„ããŸã„ç¯„å›²ã‚‚ã“ã‚Œã¾ã§ã‚ˆã‚Šã•ã‚‰ã«å¤§ãããªã£ãŸã“ã¨ãŒåˆ†ã‹ã‚Šã¾ã™ã€‚

ä»Šå›ã®ãƒ“ã‚¸ãƒ§ãƒ³å¤‰æ›´ã‚’é€šã—ã¦ã€ã‚µã‚¤ã‚­ãƒ³ã‚½ãƒ¼ãŒã©ã‚“ãªä¾¡å€¤ç™ºæ®ã‚’ç›®æŒ‡ã—ã¦ã„ãã®ã‹ã€ãã‚Œã«ä¼´ã„äº‹æ¥­é¢ã§ã¯ã©ã‚“ãªæŒ‘æˆ¦ã‚’ã—ã¦ã„ãã®ã‹ã‚’ã€ä»£è¡¨å–ç· å½¹CEOã®æ²¢äº•ã•ã‚“ã«èã„ã¦ãã¾ã—ãŸï¼

...(ä»¥ä¸‹ç•¥)


 ã‚³ãƒ¼ãƒ‰
ç¶šã‘ã¦ã‚³ãƒ¼ãƒ‰ã‚’å®Ÿè£…ã—ã¾ã™ã€‚
ä»Šå›ã¯ RAG ã¨ã—ã¦å¤–éƒ¨ã®æƒ…å ±ã‚’å‚ç…§ã—ã¤ã¤å›ç­”ã™ã‚‹ ChatBot ã‚’å®Ÿè£…ã—ã¦ã¿ã¾ã™ã€‚
ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã¨ã—ã¦ streamlit ã‚’ç”¨ã„ã¾ã™ã€‚
å…ˆã«ã‚³ãƒ¼ãƒ‰å…¨ä½“ã‚’ç¤ºã™ã¨ä»¥ä¸‹ã®ã‚ˆã†ã«ãªã‚Šã¾ã™ã€‚
(streamlit ã®ã‚³ãƒ¼ãƒ‰ã®ãƒ™ãƒ¼ã‚¹ã¨ã—ã¦ä»¥ä¸‹ã®è¨˜äº‹ã‚’å‚è€ƒã«ã•ã›ã¦ã„ãŸã ãã¾ã—ãŸã€‚ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™)
https://tech-lab.sios.jp/archives/41574

chatbot.py
from pathlib import Path

import streamlit as st
from dotenv import load_dotenv
from langchain import hub
from langchain.schema import AIMessage, HumanMessage
from langchain_chroma import Chroma
from langchain_community.document_loaders import TextLoader
from langchain_core.runnables import RunnablePassthrough, RunnableSequence
from langchain_core.vectorstores import VectorStoreRetriever
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_text_splitters import RecursiveCharacterTextSplitter

load_dotenv()


def initialize_vector_store() -> Chroma:
    """VectorStoreã®åˆæœŸåŒ–."""
    embeddings = OpenAIEmbeddings()

    vector_store_path = "./resources/note.db"
    if Path(vector_store_path).exists():
        vector_store = Chroma(embedding_function=embeddings, persist_directory=vector_store_path)
    else:
        loader = TextLoader("resources/note.txt")
        docs = loader.load()

        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
        splits = text_splitter.split_documents(docs)

        vector_store = Chroma.from_documents(
            documents=splits, embedding=embeddings, persist_directory=vector_store_path
        )

    return vector_store


def initialize_retriever() -> VectorStoreRetriever:
    """Retrieverã®åˆæœŸåŒ–."""
    vector_store = initialize_vector_store()
    return vector_store.as_retriever()


def initialize_chain() -> RunnableSequence:
    """Langchainã®åˆæœŸåŒ–."""
    prompt = hub.pull("rlm/rag-prompt")
    llm = ChatOpenAI()
    retriever = initialize_retriever()
    chain = (
        {"context": retriever, "question": RunnablePassthrough()} | prompt | llm
    )
    return chain


def main() -> None:
    """ChatGPTã‚’ä½¿ã£ãŸãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã®ãƒ¡ã‚¤ãƒ³é–¢æ•°."""
    chain = initialize_chain()

    # ãƒšãƒ¼ã‚¸ã®è¨­å®š
    st.set_page_config(page_title="RAG ChatGPT")
    st.header("RAG ChatGPT")

    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®åˆæœŸåŒ–
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ã‚’ç›£è¦–
    if user_input := st.chat_input("èããŸã„ã“ã¨ã‚’å…¥åŠ›ã—ã¦ã­ï¼"):
        st.session_state.messages.append(HumanMessage(content=user_input))
        with st.spinner("GPT is typing ..."):
            response = chain.invoke(user_input)
        st.session_state.messages.append(AIMessage(content=response.content))

    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®è¡¨ç¤º
    messages = st.session_state.get("messages", [])
    for message in messages:
        if isinstance(message, AIMessage):
            with st.chat_message("assistant"):
                st.markdown(message.content)
        elif isinstance(message, HumanMessage):
            with st.chat_message("user"):
                st.markdown(message.content)
        else:
            st.write(f"System message: {message.content}")


if __name__ == "__main__":
    main()

ã‚³ãƒ¼ãƒ‰ã®å„éƒ¨åˆ†ã‚’èª¬æ˜ã—ã¦ã„ãã¾ã™ã€‚

 initialize_vector_store
def initialize_vector_store() -> Chroma:
    """VectorStoreã®åˆæœŸåŒ–."""
    embeddings = OpenAIEmbeddings()

    vector_store_path = "./resources/note.db"
    if Path(vector_store_path).exists():
        vector_store = Chroma(embedding_function=embeddings, persist_directory=vector_store_path)
    else:
        loader = TextLoader("resources/note.txt")
        docs = loader.load()

        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
        splits = text_splitter.split_documents(docs)

        vector_store = Chroma.from_documents(
            documents=splits, embedding=embeddings, persist_directory=vector_store_path
        )

    return vector_store
Vector store ã¨ã¯æƒ…å ±ã¨ã—ã¦èª­ã¿è¾¼ã¾ã›ã¦ã„ã‚‹ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’é©åˆ‡ãªé•·ã•ã«åˆ†å‰²ã—(ãƒãƒ£ãƒ³ã‚¯ã¨å‘¼ã°ã‚Œã¾ã™) ã™ãã«å–ã‚Šå‡ºã›ã‚‹ã‚ˆã†ã«ä¿å­˜ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ã‚ˆã†ãªã‚‚ã®ã§ã™ã€‚
Embeddings ã¨å‘¼ã°ã‚Œã‚‹ãƒ¢ãƒ‡ãƒ«ã§ãƒ†ã‚­ã‚¹ãƒˆã¯æ•°å€¤æƒ…å ±ã®ãƒ™ã‚¯ãƒˆãƒ«ã«ä¿å­˜ã•ã‚Œã¾ã™ã€‚ãã®ä½œæ¥­ã‚’è¡Œã†ãŸã‚ã« OpenAI API ãŒå¿…è¦ã«ãªã£ã¦ã„ã‚‹ãŸã‚é–¢æ•°ã®æœ€åˆã§ OpenAIEmbeddings ã‚’å‘¼ã³å‡ºã—ã¦ã„ã¾ã™ã€‚
ç¶šã‘ã¦ Vector store ã¨ã—ã¦ä¿å­˜ã•ã‚Œã¦ã„ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã™ã§ã«å­˜åœ¨ã—ã¦ã„ãªã„ã‹ã‚’èª¿ã¹ã¦ã„ã¾ã™ã€‚åŸºæœ¬çš„ã«ãƒ‡ãƒ¼ã‚¿ã‚„ãƒ¢ãƒ‡ãƒ«ãŒã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆã•ã‚Œãªã„é™ã‚Š Vector store ã®ãƒ‡ãƒ¼ã‚¿ã¯ã¾ã£ãŸãåŒã˜ã«ãªã‚‹ãŸã‚ã€æ¯å›å®Ÿè¡Œã—ã¦ã—ã¾ã†ã¨æ™‚é–“ã‚‚ API ã®åˆ©ç”¨æ–™é‡‘ã‚‚ç„¡é§„ã«ãªã£ã¦ã—ã¾ã„ã¾ã™ã€‚
ãã“ã§

ã¾ã å­˜åœ¨ã—ã¦ã„ãªã„å ´åˆï¼š æ–°è¦ä½œæˆ
ã™ã§ã«å­˜åœ¨ã—ã¦ã„ã‚‹å ´åˆï¼š ä¿å­˜ã—ã¦ã„ã‚‹ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’èª­ã¿è¾¼ã‚€

ã¨ã—ã¦ã„ã¾ã™ã€‚
ãªãŠå­˜åœ¨ã—ã¦ã„ã‚‹å ´åˆ Chroma ã‚¯ãƒ©ã‚¹ã®å¼•æ•° embedding_function ã« embeddings ã‚’æŒ‡å®šã—ã¦ã„ã¾ã™ãŒã€ã“ã‚Œã¯ã‚¯ã‚¨ãƒªã¨ã—ã¦ã‚ãŸãˆã‚‰ã‚Œã‚‹ãƒ¦ãƒ¼ã‚¶ã®è³ªå•ã¨ Vector store ã«ä¿å­˜ã•ã‚Œã¦ã„ã‚‹ãƒ‡ãƒ¼ã‚¿ã¨ã®é–“ã®é–¢é€£æ€§ã‚’èª¿ã¹ã‚‹ãŸã‚ã«ã€ã‚¯ã‚¨ãƒªã‚‚ Embeddings ã§ãƒ™ã‚¯ãƒˆãƒ«ã«å¤‰æ›ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã‹ã‚‰ã§ã™ã€‚

 initialize_retriver
def initialize_retriever() -> VectorStoreRetriever:
    """Retrieverã®åˆæœŸåŒ–."""
    vector_store = initialize_vector_store()
    return vector_store.as_retriever()
ã“ã¡ã‚‰ã§ã¯ã€å…ˆã»ã©ä½œæˆã—ãŸ(ã‚ã‚‹ã„ã¯ã™ã§ã«ã‚ã‚‹ã‚‚ã®ã‚’èª­ã¿è¾¼ã‚“ã ) vector_store ã‚’ retriever ã«å¤‰æ›ã—ã¦ã„ã¾ã™ã€‚ã“ã¡ã‚‰ã® retriever ã“ã®å¾Œã€ Vectore store ã‹ã‚‰æƒ…å ±ã‚’å–ã‚Šå‡ºã™ã®ã«åˆ©ç”¨ã•ã‚Œã¾ã™ã€‚

 initialize_chain
def initialize_chain() -> RunnableSequence:
    """Langchainã®åˆæœŸåŒ–."""
    prompt = hub.pull("rlm/rag-prompt")
    llm = ChatOpenAI()
    retriever = initialize_retriever()
    chain = (
        {"context": retriever, "question": RunnablePassthrough()} | prompt | llm
    )
    return chain
ã“ã¡ã‚‰ã§ã¯ retriever ã®æƒ…å ±ã‚’ LLM ã§åˆ©ç”¨ã§ãã‚‹ã‚ˆã†ã« chain ã¨å‘¼ã°ã‚Œã‚‹æ¦‚å¿µã‚’åˆ©ç”¨ã—ã¦ãŠã‚Šã¾ã™ã€‚
ã‚ˆããƒ¡ã‚½ãƒƒãƒ‰ãƒã‚§ãƒ¼ãƒ³ã¨ã„ã†è¨€è‘‰ãŒãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°è¨€èªã§ã¯ä½¿ã‚ã‚Œã¦ã„ã¾ã™ã€‚
ä¾‹ãˆã° Python ã® Pandas ã§ã¯
import pandas as pd

# ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
data = {
    'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Edward', 'Frank'],
    'Age': [24, 27, 22, 32, 29, 24],
    'City': ['New York', 'Los Angeles', 'New York', 'Chicago', 'Los Angeles', 'New York'],
    'Score': [85, 90, 88, 92, 95, 70]
}

df = pd.DataFrame(data)

# ãƒ¡ã‚½ãƒƒãƒ‰ãƒã‚§ãƒ¼ãƒ³ã‚’ä½¿ã£ãŸãƒ‡ãƒ¼ã‚¿å¤‰æ›
result = (df
          .query('Age > 25')                     # å¹´é½¢ãŒ25ä»¥ä¸Šã®è¡Œã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
          .groupby('City')                       # éƒ½å¸‚ã”ã¨ã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
          .agg({'Score': 'mean'})                # ã‚¹ã‚³ã‚¢ã®å¹³å‡ã‚’è¨ˆç®—
          .rename(columns={'Score': 'Average Score'})  # åˆ—åã‚’å¤‰æ›´
          .sort_values(by='Average Score', ascending=False)  # å¹³å‡ã‚¹ã‚³ã‚¢ã§ä¸¦ã¹æ›¿ãˆ
          .reset_index()                         # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ãƒªã‚»ãƒƒãƒˆ
         )

print(result)
ã¨ã„ã†ã‚ˆã†ã«ãƒ¡ã‚½ãƒƒãƒ‰ã®è¿”ã‚Šå€¤ã‚’æ¬¡ã®ãƒ¡ã‚½ãƒƒãƒ‰ã¸ã¨ãƒã‚±ãƒ„ãƒªãƒ¬ãƒ¼ã®ã‚ˆã†ã«ã¤ãªã„ã§è¡Œãå‡¦ç†ã•ã›ã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚ã“ã‚Œã‚’ãƒ¡ã‚½ãƒƒãƒ‰ãƒã‚§ãƒ¼ãƒ³ã¨ã„ã„ã¾ã™ã€‚
LangChain ã§ã‚‚ã“ã®ãƒã‚±ãƒ„ãƒªãƒ¬ãƒ¼ã‚’è¡Œã„ã€ã©ã®ã‚ˆã†ã«ãƒ¦ãƒ¼ã‚¶ã®è³ªå•ã«ç­”ãˆã‚‹ã‹ã®ãƒ«ãƒ¼ãƒ«ã‚’æ±ºã‚ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚
LangChain ã®å ´åˆã¯æ˜”ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã§ã¯é–¢æ•°ã®è¿”ã‚Šå€¤ã‚’ã•ã‚‰ã«é–¢æ•°ã®å¼•æ•°ã«ã™ã‚‹ã¨è¨€ã†ã“ã¨ã‚’ç¹°ã‚Šè¿”ã—ã¦ãƒã‚±ãƒ„ãƒªãƒ¬ãƒ¼ã‚’è¡Œã£ã¦ã„ã¾ã—ãŸãŒã€ä»Šã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ 0.2.5 ã§ã¯ä»¥ä¸‹ã®ã‚ˆã†ã« | ã‚’åˆ©ç”¨ã—ãƒã‚§ãƒ¼ãƒ³ã‚’ç¤ºã™ã“ã¨ãŒæ¨å¥¨ã•ã‚Œã¦ã„ã¾ã™ã€‚
    chain = (
        {"context": retriever, "question": RunnablePassthrough()} | prompt | llm
    )
ä»Šå›ã®å ´åˆ

{"context": retriever, "question": RunnablePassthrough()}
prompt
llm

ã¨ã„ã†é †ç•ªã§ãƒã‚§ãƒ¼ãƒ³ãŒã¤ãªãŒã£ã¦ã„ã¾ã™ã€‚
ãƒã‚§ãƒ¼ãƒ³ã®å…ˆé ­ãŒãªãœè¾æ›¸ã§ã‚ã‚‹ã‹ã¯ã€2ç•ªç›®ã® prompt ã®èª¬æ˜ã‚’èã„ã¦ã‚‚ã‚‰ãˆã‚Œã°ã‚ã‹ã‚‹ã¨æ€ã„ã¾ã™ã€‚
    prompt = hub.pull("rlm/rag-prompt")
prompt ã¯ LLM ã«ã©ã®ã‚ˆã†ãªè³ªå•ã‚„ä¾é ¼ã‚’ã™ã‚‹ã®ã‹ã‚’æ±ºã‚ã‚‹éƒ¨åˆ†ã§ã™ã€‚ä»Šå›ã¯ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ(å¤‰æ•°åã‚’æŒ‡ã—ã¦ã„ãªã„å ´åˆã‚«ã‚¿ã‚«ãƒŠè¡¨è¨˜ã¨ã—ã¾ã™)ã‚’æœ‰å¿—ã®æ–¹ãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ä»–ã®äººãŒåˆ©ç”¨ã§ãã‚‹ã‚ˆã†ã«ã—ã¦ãã‚Œã¦ã„ã‚‹ã‚µã‚¤ãƒˆ LangChain Hub ã‹ã‚‰ â­ ãŒå¤šã„ã‚‚ã®ã‚’ãŠå€Ÿã‚Šã—ã¦ãã¾ã—ãŸã€‚ã‚‚ã¡ã‚ã‚“è‡ªä½œã—ã¦ã‚‚ã‚‰ã£ã¦ã‚‚OKã§ã™ã€‚
https://smith.langchain.com/hub/rlm/rag-prompt
ãŠå€Ÿã‚Šã—ãŸ rag-prompt ã§ã¯ä»¥ä¸‹ã®ã‚ˆã†ã«ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒå®šç¾©ã•ã‚Œã¦ã„ã¾ã™ã€‚
You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.
Question: {question} 
Context: {context} 
Answer:
ç°¡å˜ã«æ—¥æœ¬èªã«è¨³ã™ã¨ ã€Œ context ã®æƒ…å ±ã®ã¿ã‚’ä½¿ã£ã¦ question ã«ç­”ãˆã‚‹ã‚ˆã†ã« Answer ã‚’è€ƒãˆãªã•ã„ã€‚ç­”ãˆã‚‰ã‚Œãªã„ãªã‚‰ã‚ã‹ã‚‰ãªã„ã¨ç­”ãˆãªã•ã„ã€‚ã€ ã¨ãªã‚Šã¾ã™ã€‚ context ã®æƒ…å ±ã®ã¿ã‚’ç”¨ã„ã‚‹ã‚ˆã†æŒ‡å®šã™ã‚‹ã“ã¨ã§ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³ã‚’é˜²ãåŠ¹æœãŒã‚ã‚Šã¾ã™ (ãŸã ã—ï¼‘ï¼ï¼ï¼…é˜²ãã¨ã¯æ–­è¨€ã§ããªã„ã§ã™)
ã“ã¡ã‚‰ã® question éƒ¨åˆ†ã«ãƒ¦ãƒ¼ã‚¶ã®ã‚¯ã‚¨ãƒªãŒã€ context éƒ¨åˆ†ã« retriever ã‚’æŒ‡å®šã—ã¦ prompt ã‚’å®Ÿè¡Œã›ã‚ˆã¨ã—ã¦ã„ã‚‹ã®ãŒãƒã‚§ãƒ¼ãƒ³ã® {"context": retriever, "question": RunnablePassthrough()} | prompt ã®éƒ¨åˆ†ã§ã™ã€‚
æœ€å¾Œã«å®Œæˆã—ãŸ prompt ã‚’ llm ã«æ¸¡ã—ãªã•ã„ã¨æŒ‡å®šã—ã¦ã„ã‚‹ã®ãŒ prompt | llm ã®éƒ¨åˆ†ã§ã™ã€‚
ã“ã®ãƒ¡ã‚½ãƒƒãƒ‰ãƒã‚§ãƒ¼ãƒ³ã‚’ã¾ã¨ã‚ãŸ chain ã¨ã„ã†å¤‰æ•°ã¯ invoke ãƒ¡ã‚½ãƒƒãƒ‰ã‚’æŒã£ã¦ãŠã‚Šã€ã“ã®ãƒ¡ã‚½ãƒƒãƒ‰ã«è³ªå•ã‚’æŠ•ã’ã‚‹ã¨ãã‚ŒãŒ question ã«å…¥ã‚Šãƒã‚§ãƒ¼ãƒ³ãŒå‰ã‹ã‚‰é †ç•ªã«å®Ÿè¡Œã•ã‚Œã¾ã™ã€‚
ä»¥ä¸Šã®ã‚ˆã†ã«å®šç¾©ã™ã‚‹ã“ã¨ã§ RAG ã¨ã—ã¦å¤–éƒ¨ã®æƒ…å ±ã‚’å‚ç…§ã—ã¤ã¤å›ç­”ã™ã‚‹ ChatBot ã‚’å®Ÿè£…ã§ãã¾ã—ãŸã€‚

 main
def main() -> None:
    """ChatGPTã‚’ä½¿ã£ãŸãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã®ãƒ¡ã‚¤ãƒ³é–¢æ•°."""
    chain = initialize_chain()

    # ãƒšãƒ¼ã‚¸ã®è¨­å®š
    st.set_page_config(page_title="RAG ChatGPT")
    st.image(img, use_column_width=False)
    st.header("RAG ChatGPT")

    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®åˆæœŸåŒ–
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ã‚’ç›£è¦–
    if user_input := st.chat_input("èããŸã„ã“ã¨ã‚’å…¥åŠ›ã—ã¦ã­ï¼"):
        st.session_state.messages.append(HumanMessage(content=user_input))
        with st.spinner("GPT is typing ..."):
            response = chain.invoke(user_input)
        st.session_state.messages.append(AIMessage(content=response.content))

    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®è¡¨ç¤º
    messages = st.session_state.get("messages", [])
    for message in messages:
        if isinstance(message, AIMessage):
            with st.chat_message("assistant"):
                st.markdown(message.content)
        elif isinstance(message, HumanMessage):
            with st.chat_message("user"):
                st.markdown(message.content)
        else:
            st.write(f"System message: {message.content}")
æœ€å¾Œã« main é–¢æ•°ã§ã™ã€‚ã“ã¡ã‚‰ã¯ LangChain ã®å®Ÿè£…ã¨ã„ã†ã‚ˆã‚Šã¯ Streamlit ã‚’åˆ©ç”¨ã—ãŸãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰éƒ¨åˆ†ã®å®Ÿè£…ã«ãªã‚Šã¾ã™ã€‚
ã‚­ãƒ¼ã¨ãªã‚‹ç‚¹ã ã‘è§£èª¬ã™ã‚‹ã¨

ãƒ¦ãƒ¼ã‚¶ã¨ ChatBot ã®ä¼šè©±ã¯ messages ã«ä¿å­˜ã•ã‚Œã¦ã„ã¾ã™ã€‚ä»¥ä¸‹ã®ã‚³ãƒ¼ãƒ‰ã‚’è¦‹ã‚‹ã¨ã‚ã‹ã‚‹ã‚ˆã†ã«ãƒ¦ãƒ¼ã‚¶ã‹ã‚‰ã®è³ªå•ã¨ ChatBot ã®è¿”ç­”ã¯ã©ã¡ã‚‰ã‚‚ messages ã« append ã•ã‚Œã¦ã„ã¾ã™ã€‚

    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®åˆæœŸåŒ–
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ã‚’ç›£è¦–
    if user_input := st.chat_input("èããŸã„ã“ã¨ã‚’å…¥åŠ›ã—ã¦ã­ï¼"):
        st.session_state.messages.append(HumanMessage(content=user_input))
        with st.spinner("GPT is typing ..."):
            response = chain.invoke(user_input)
        st.session_state.messages.append(AIMessage(content=response.content))

ãƒ¦ãƒ¼ã‚¶ã‹ã‚‰ã®è³ªå•ã¸ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã¯å…ˆã»ã©å®šç¾©ã—ãŸ chain ã® invoke ãƒ¡ã‚½ãƒƒãƒ‰ã‚’ç”¨ã„ã¦ä½œã‚‰ã‚Œã¦ã„ã¾ã™ã€‚

        with st.spinner("GPT is typing ..."):
            response = chain.invoke(user_input)
        st.session_state.messages.append(AIMessage(content=response.content))
ã¨ã„ã†ç‚¹ãŒã‚ã’ã‚‰ã‚Œã¾ã™ã€‚

 ãƒ†ã‚¹ãƒˆ
ãã‚Œã§ã¯å®Ÿè£…ã—ãŸã‚‚ã®ã‚’å‹•ã‹ã—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚
> streamlit run chatbot.py

Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.


  You can now view your Streamlit app in your browser.

  Local URL: http://localhost:8501
  Network URL: http://10.200.0.4:8501
  External URL: http://13.73.233.61:8501
http://localhost:8501 ã¸ãƒ–ãƒ©ã‚¦ã‚¶ã‹ã‚‰ã‚¢ã‚¯ã‚»ã‚¹ã—ã€è³ªå•ã—ã¦ã¿ã¾ã™ã€‚

ç¾æ™‚ç‚¹ã§ã® note.txt ã®å…ˆé ­ã®æ–¹ã«æ›¸ã„ã¦ã‚ã£ãŸæ–°ã—ã„ãƒ“ã‚¸ãƒ§ãƒ³ã‚’ã¡ã‚ƒã‚“ã¨ç­”ãˆã¦ã„ã¾ã™ã€‚ã“ã®æƒ…å ±ã¯ OpenAI ã«ã¯ãªã„ãŸã‚ãã¡ã‚“ã¨ RAG ãŒåƒã„ã¦ã„ã‚‹ã¨è¨€ãˆãã†ã§ã™ã€‚

ã¾ãŸã€Œ100å¹´å¾Œã«ç™ºå£²äºˆå®šã®æ–°å•†å“ã€ã¨ã„ã†æƒ…å ±ã¨ã—ã¦å«ã¾ãªã„ã‚ˆã†ãªè³ªå•ã‚’ã™ã‚‹ã¨ã¡ã‚ƒã‚“ã¨ã€Œæƒ…å ±ã‚’æŒã£ã¦ã„ãªã„ã€ã¨è¿”ç­”ã—ã¦ãã‚Œã¾ã™ã€‚ã“ã¡ã‚‰ã‚‚æœŸå¾…é€šã‚Šã§ã™ã­ã€‚

 ğŸ’¡ ã¾ã¨ã‚

LangChain v0.2.5 æ™‚ç‚¹ã§ã® RAG ã‚’ç”¨ã„ãŸ ChatBot ã®å®Ÿè£…ã‚’è¡Œã„ã¾ã—ãŸ
Streamlit ã‚’ç”¨ã„ã¦ãƒ–ãƒ©ã‚¦ã‚¶ã‹ã‚‰ãƒ¦ãƒ¼ã‚¶ãŒã‚¢ã‚¯ã‚»ã‚¹ã§ãã‚‹ã‚ˆã†ã«ã—ã¾ã—ãŸ

ãœã²å‚è€ƒã«ã—ã¦ã¿ã¦ãã ã•ã„ã€‚
yamasaKitcheminformatics, machine learning, board gameCykinso's Tech BlogPublicationã€Œç´°èŒå¢ã®åŠ›ã§äººã€…ã‚’å¥åº·ã«ã€ã‚’ãƒŸãƒƒã‚·ãƒ§ãƒ³ã«æ²ã’ã‚‹ãƒã‚¤ã‚ªãƒ†ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆã‚¢ãƒƒãƒ—ã€Œã‚µã‚¤ã‚­ãƒ³ã‚½ãƒ¼ã€ã®æŠ€è¡“ãƒ–ãƒ­ã‚°ã€‚ ãƒãƒƒã‚¸ã‚’è´ˆã£ã¦è‘—è€…ã‚’å¿œæ´ã—ã‚ˆã†ãƒãƒƒã‚¸ã‚’å—ã‘å–ã£ãŸè‘—è€…ã«ã¯Zennã‹ã‚‰ç¾é‡‘ã‚„Amazonã‚®ãƒ•ãƒˆã‚«ãƒ¼ãƒ‰ãŒé‚„å…ƒã•ã‚Œã¾ã™ã€‚ãƒãƒƒã‚¸ã‚’è´ˆã‚‹DiscussionyamasaKitcheminformatics, machine learning, board gameãƒãƒƒã‚¸ã‚’è´ˆã‚‹ãƒãƒƒã‚¸ã‚’è´ˆã‚‹ã¨ã¯ç›®æ¬¡èƒŒæ™¯ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ãªã©æ–¹æ³•.envãƒ‡ãƒ¼ã‚¿ã‚³ãƒ¼ãƒ‰initialize_vector_storeinitialize_retriverinitialize_chainmainãƒ†ã‚¹ãƒˆğŸ’¡ ã¾ã¨ã‚
asideCykinso's Tech Blog
divCykinso's Tech Blog
divCykinso's Tech Blog
divCykinso's Tech Blog
aCykinso's Tech Blog
span
img
spanCykinso's Tech Blog
div
div
button
svg
path
path
g
divCykinso's Tech BlogPublicationã¸ã®æŠ•ç¨¿
divCykinso's Tech BlogPublicationã¸ã®æŠ•ç¨¿
divCykinso's Tech BlogPublicationã¸ã®æŠ•ç¨¿
aCykinso's Tech Blog
span
img
spanCykinso's Tech Blog
spanPublicationã¸ã®æŠ•ç¨¿
aPublicationã¸ã®æŠ•ç¨¿
headerğŸ¦œğŸ¦œğŸ”— LangChain v0.2.5 + OpenAI ã§ã® RAG ã‚’ç”¨ã„ãŸ ChatBot å®Ÿè£…ä¾‹yamasaKit2024/06/20ã«å…¬é–‹2024/06/28
divğŸ¦œğŸ¦œğŸ”— LangChain v0.2.5 + OpenAI ã§ã® RAG ã‚’ç”¨ã„ãŸ ChatBot å®Ÿè£…ä¾‹yamasaKit2024/06/20ã«å…¬é–‹2024/06/28
divğŸ¦œğŸ¦œğŸ”— LangChain v0.2.5 + OpenAI ã§ã® RAG ã‚’ç”¨ã„ãŸ ChatBot å®Ÿè£…ä¾‹yamasaKit2024/06/20ã«å…¬é–‹2024/06/28
divğŸ¦œ
span
span
spanğŸ¦œ
h1ğŸ¦œğŸ”— LangChain v0.2.5 + OpenAI ã§ã® RAG ã‚’ç”¨ã„ãŸ ChatBot å®Ÿè£…ä¾‹
divyamasaKit2024/06/20ã«å…¬é–‹2024/06/28
divyamasaKit2024/06/20ã«å…¬é–‹2024/06/28
divyamasaKit
a
img
ayamasaKit
span2024/06/20ã«å…¬é–‹
span2024/06/20
div2024/06/28
div2024/06/28
span2024/06/28
divchatbotOpenAILangChainLLMRAGtech
 èƒŒæ™¯
LangChain ã¯ OpenAI API ã‚’åˆ©ç”¨ã—è‡ªåˆ†ãŸã¡ãŒã‚„ã‚ŠãŸã„ã“ã¨ã‚’å®Ÿç¾ã™ã‚‹ã“ã¨ã«éå¸¸ã«ä¾¿åˆ©ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã§ã™ãŒãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚¢ãƒƒãƒ—ã«ã‚ˆã£ã¦ã‚¯ãƒ©ã‚¹åã‚„ã‚µãƒ–ãƒ©ã‚¤ãƒ–ãƒ©ãƒªåã®å¤‰æ›´ãŒã‚„ã‚„å¤šãå°‘ã—å¤ã„ Web è¨˜äº‹ã‚’å‚è€ƒã«ã—ã¦ã‚‚ã†ã¾ããƒ¯ãƒ¼ã‚¯ã—ãªã„ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚
ã“ã®è¨˜äº‹ã¯ 2024/6/20 ç¾åœ¨ã® LangChain (ãƒãƒ¼ã‚¸ãƒ§ãƒ³ 0.2.5) ã§ OpenAI API ã‚„ Azure OpenAI API ã‚’å‹•ã‹ã™ä¾‹ã¨ã—ã¦æ®‹ã—ã¦ãŠãã¾ã™ã€‚
åŒã˜ã‚ˆã†ãªã“ã¨ã‚’ã—ã‚ˆã†ã¨ã—ã¦ç§ã®ã‚ˆã†ã«è‹¦æˆ¦ã—ã¦ã„ã‚‹æ–¹ã®åŠ©ã‘ã«ãªã‚Œã°å¹¸ã„ã§ã™ã€‚

 ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ãªã©

pyproject.toml
python = ">=3.12,<3.13"
python-dotenv = "^1.0.1"
chromadb = "0.5.2"
langchain = "0.2.5"
langchain-cli = "0.0.25"
langchain-openai = "0.1.8"
langchain-community = "0.2.5"
langchain-chroma = "0.1.1"
langchainhub = "0.1.20"
streamlit = "1.35.0"

ğŸ’¡ Poetry ã§ Python ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’æŒ‡å®šã™ã‚‹æ™‚ã« ^3.12 ã¨ã™ã‚‹ã¨ lancghain-chroma ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã§ããªããªã‚‹ã®ã§ >=3.12,<3.13 ã¨ã—ã¾ã—ãŸã€‚
(langchain-chroma ã¯ >=3.12,<3.13 ã¨ã„ã†æŒ‡å®šãŒã‚ã‚Šã¾ã™)

 æ–¹æ³•
OpenAI API ã‚’ä½¿ã†å ´åˆã¨ AzureOpenAI API ã‚’ä½¿ã†å ´åˆã¯åŸºæœ¬åŒã˜ã“ã¨ã‚’ã™ã‚‹ã®ã§ã¾ãš OpenAI API ã‚’ä½¿ã†å ´åˆã‚’èª¬æ˜ã—ã€è¨˜äº‹ãŒé•·ããªã£ã¦ã—ã¾ã£ãŸã®ã§ã€å¾Œæ—¥åˆ¥è¨˜äº‹ã«ã¦ AzureOpenAI API ã‚’ä½¿ã†å ´åˆã¯ã©ã®éƒ¨åˆ†ã‚’ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆã—ãŸã‚‰ã‚ˆã„ã®ã‹ã‚’èª¬æ˜ã—ãŸã„ã¨æ€ã„ã¾ã™ã€‚
6/28 è¿½è¨˜) AzureOpenAI API ç‰ˆã®è¨˜äº‹ã‚‚æ›¸ãã¾ã—ãŸã®ã§ã‚ˆã‘ã‚Œã°ãœã²ã©ã†ã
https://zenn.dev/cykinso/articles/b055e33734d06b

 .env
ä»¥ä¸‹ã®ã‚ˆã†ã« .env ã‚’ç”¨æ„ã—ã¾ã™ã€‚
OPENAI_API_KEY=sk-XXXXXXXXXXXXXXXX
OPENAI_API_VERSION=2024-02-01
ã‚‚ã— OPENAI_API_KEY ã‚’ã¾ã å–å¾—ã—ã¦ã„ãªã„å ´åˆã¯ä»¥ä¸‹ã®æ–¹æ³•ã§å–å¾—ã—ã¦ãã ã•ã„ã€‚

 OPENAI_API_KEY
OPENAI_API_KEY ã¯ OpenAI ã® Dashboard ã§ä½œæˆã§ãã¾ã™ã€‚
(èª²é‡‘å¯¾è±¡ãªã®ã§ã”è‡ªèº«ã®è²¬ä»»ã®ã‚‚ã¨ã”åˆ©ç”¨ãã ã•ã„)

ã€Œ+ Create new secret keyã€ ã‚’æŠ¼ã™ã¨ãƒ¢ãƒ¼ãƒ€ãƒ«ãŒé–‹ãã®ã§å¾Œã‹ã‚‰åŒºåˆ¥ã§ãã‚‹ã‚ˆã†ãªåå‰ã‚’ã¤ã‘ã¦ ã€ŒCreate secret keyã€ ã‚’æŠ¼ã—ã¾ã™ã€‚

è¡¨ç¤ºã•ã‚Œã‚‹ API ã‚­ãƒ¼ã‚’ .env ã«ãƒ¡ãƒ¢ã—ã¦ãŠãã¾ã™ã€‚ ã€ŒDoneã€ ã‚’æŠ¼ã™ã¨ã‚‚ã†è¡¨ç¤ºã§ãã¾ã›ã‚“ã€‚


 ãƒ‡ãƒ¼ã‚¿
OpenAI ãŒã¾ã å­¦ç¿’ã—ã¦ã„ãªã•ãã†ãªãƒ‡ãƒ¼ã‚¿ã®ä¾‹ã¨ã—ã¦å¼Šç¤¾ Cykinso ã®ãƒ–ãƒ­ã‚°è¨˜äº‹ã®ã€Œä¼šç¤¾ã®ãƒ“ã‚¸ãƒ§ãƒ³ã‚’è©±ã—ã¦ã„ã‚‹ãƒšãƒ¼ã‚¸ã€ã‚’ä»Šå›ã¯ç”¨ã„ãŸã„ã¨æ€ã„ã¾ã™ã€‚
https://note.com/cykinso/n/n432d5ea70783
ğŸ’¡ ãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆã§å®Ÿè£…ã™ã‚‹å ´åˆã¯ã€å¥½ããªãƒãƒ³ã‚¬ãªã©ã®è©³ç´°ã‚’ãƒ†ã‚­ã‚¹ãƒˆã«ã¾ã¨ã‚ã¦ãƒ‡ãƒ¼ã‚¿ã¨ã™ã‚‹ã¨ãƒ¢ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³ã‚‚ä¸ŠãŒã‚‹ã¨æ€ã„ã¾ã™ã€‚
ã–ã£ã¨æ–‡ç« ã‚’ã‚³ãƒ”ãƒ¼ã—ã¦ä»¥ä¸‹ã®ã‚ˆã†ã«æ•´å½¢ã—ã¾ã—ãŸã€‚

note.txt
ç´°èŒå¢ã‹ã‚‰ã®æ–°ãŸãªæ°—ä»˜ãã‚’é€šã˜ã¦ã€æ–°ãƒ“ã‚¸ãƒ§ãƒ³ã‚’ç­–å®šã—ã¾ã—ãŸï¼
2023å¹´11æœˆã«ã‚µã‚¤ã‚­ãƒ³ã‚½ãƒ¼ã¯10æœŸç›®ã«å…¥ã‚Šã¾ã—ãŸã€‚é«˜é½¢åŒ–ç¤¾ä¼šã«ã‚ˆã‚‹ç¤¾ä¼šä¿éšœã¸ã®ä¸å®‰ãŒå‹Ÿã‚‹ç¾åœ¨ã€ç—…æ°—ã‚’æœªç„¶ã«é˜²ã0æ¬¡äºˆé˜²ã®é‡è¦æ€§ãŒé«˜ã¾ã£ã¦ã„ã¾ã™ã€‚ã€Œç´°èŒå¢ã§äººã€…ã‚’å¥åº·ã«ã€ã¨ã„ã†ãƒŸãƒƒã‚·ãƒ§ãƒ³ã«å‘ã‘ã¦ã€ã‚µã‚¤ã‚­ãƒ³ã‚½ãƒ¼ã¯æ–°ãŸãªãƒ“ã‚¸ãƒ§ãƒ³ã‚’åˆ¶å®šã—ã¾ã—ãŸã€‚
æ–°ã—ã„ãƒ“ã‚¸ãƒ§ãƒ³ã«ã¤ã„ã¦
ãƒ¼ãƒ“ã‚¸ãƒ§ãƒ³å¤‰æ›´ã§å…·ä½“çš„ã«ã©ã®å€‹æ‰€ãŒå¤‰æ›´ã—ãŸã‹ã‚’ã¾ãšã”ç´¹ä»‹ã—ã¾ã™ã€‚
ã“ã¡ã‚‰ãŒã‚µã‚¤ã‚­ãƒ³ã‚½ãƒ¼ã®ãƒŸãƒƒã‚·ãƒ§ãƒ³ï¼ˆMISSIONï¼‰ã€ãƒ“ã‚¸ãƒ§ãƒ³(VISION)ã€ãƒãƒªãƒ¥ãƒ¼(VALUE)ã«ãªã‚Šã¾ã™ã€‚
ç§ãŸã¡ãŒç›®æŒ‡ã—ç¶šã‘ã‚‹ã€Œç´°èŒå¢ã§äººã€…ã‚’å¥åº·ã«ã€ã¨ã„ã†ãƒŸãƒƒã‚·ãƒ§ãƒ³ã¯ãã®ã¾ã¾ã«ã€ãƒ“ã‚¸ãƒ§ãƒ³ã‚’æ–°ã—ãå¤‰æ›´è‡´ã—ã¾ã—ãŸã€‚

ï¼œã“ã‚Œã¾ã§ã®ãƒ“ã‚¸ãƒ§ãƒ³ï¼
èŒå¢ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã€Œæ¬¡ä¸–ä»£ã®ãƒ©ã‚¤ãƒ•ã‚¹ã‚¿ã‚¤ãƒ«ã€ã‚’æä¾›ã™ã‚‹ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã«ãªã‚‹

ï¼œæ–°ã—ã„ãƒ“ã‚¸ãƒ§ãƒ³ï¼
ç´°èŒå¢ã‹ã‚‰ã®æ–°ãŸãªæ°—ä»˜ãã‚’é€šã˜ã¦
ãƒ’ãƒˆã€ç¤¾ä¼šã€åœ°çƒç’°å¢ƒã‚’å¥åº·ã«ã™ã‚‹ã‚¨ã‚³ã‚·ã‚¹ãƒ†ãƒ ã‚’å®Ÿç¾ã™ã‚‹
æ–°ã—ã„ãƒ“ã‚¸ãƒ§ãƒ³ã§ã¯ã€ã‚µã‚¤ã‚­ãƒ³ã‚½ãƒ¼ãŒå½±éŸ¿ã‚’ä¸ãˆã¦ã„ããŸã„ç¯„å›²ã‚‚ã“ã‚Œã¾ã§ã‚ˆã‚Šã•ã‚‰ã«å¤§ãããªã£ãŸã“ã¨ãŒåˆ†ã‹ã‚Šã¾ã™ã€‚

ä»Šå›ã®ãƒ“ã‚¸ãƒ§ãƒ³å¤‰æ›´ã‚’é€šã—ã¦ã€ã‚µã‚¤ã‚­ãƒ³ã‚½ãƒ¼ãŒã©ã‚“ãªä¾¡å€¤ç™ºæ®ã‚’ç›®æŒ‡ã—ã¦ã„ãã®ã‹ã€ãã‚Œã«ä¼´ã„äº‹æ¥­é¢ã§ã¯ã©ã‚“ãªæŒ‘æˆ¦ã‚’ã—ã¦ã„ãã®ã‹ã‚’ã€ä»£è¡¨å–ç· å½¹CEOã®æ²¢äº•ã•ã‚“ã«èã„ã¦ãã¾ã—ãŸï¼

...(ä»¥ä¸‹ç•¥)


 ã‚³ãƒ¼ãƒ‰
ç¶šã‘ã¦ã‚³ãƒ¼ãƒ‰ã‚’å®Ÿè£…ã—ã¾ã™ã€‚
ä»Šå›ã¯ RAG ã¨ã—ã¦å¤–éƒ¨ã®æƒ…å ±ã‚’å‚ç…§ã—ã¤ã¤å›ç­”ã™ã‚‹ ChatBot ã‚’å®Ÿè£…ã—ã¦ã¿ã¾ã™ã€‚
ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã¨ã—ã¦ streamlit ã‚’ç”¨ã„ã¾ã™ã€‚
å…ˆã«ã‚³ãƒ¼ãƒ‰å…¨ä½“ã‚’ç¤ºã™ã¨ä»¥ä¸‹ã®ã‚ˆã†ã«ãªã‚Šã¾ã™ã€‚
(streamlit ã®ã‚³ãƒ¼ãƒ‰ã®ãƒ™ãƒ¼ã‚¹ã¨ã—ã¦ä»¥ä¸‹ã®è¨˜äº‹ã‚’å‚è€ƒã«ã•ã›ã¦ã„ãŸã ãã¾ã—ãŸã€‚ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™)
https://tech-lab.sios.jp/archives/41574

chatbot.py
from pathlib import Path

import streamlit as st
from dotenv import load_dotenv
from langchain import hub
from langchain.schema import AIMessage, HumanMessage
from langchain_chroma import Chroma
from langchain_community.document_loaders import TextLoader
from langchain_core.runnables import RunnablePassthrough, RunnableSequence
from langchain_core.vectorstores import VectorStoreRetriever
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_text_splitters import RecursiveCharacterTextSplitter

load_dotenv()


def initialize_vector_store() -> Chroma:
    """VectorStoreã®åˆæœŸåŒ–."""
    embeddings = OpenAIEmbeddings()

    vector_store_path = "./resources/note.db"
    if Path(vector_store_path).exists():
        vector_store = Chroma(embedding_function=embeddings, persist_directory=vector_store_path)
    else:
        loader = TextLoader("resources/note.txt")
        docs = loader.load()

        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
        splits = text_splitter.split_documents(docs)

        vector_store = Chroma.from_documents(
            documents=splits, embedding=embeddings, persist_directory=vector_store_path
        )

    return vector_store


def initialize_retriever() -> VectorStoreRetriever:
    """Retrieverã®åˆæœŸåŒ–."""
    vector_store = initialize_vector_store()
    return vector_store.as_retriever()


def initialize_chain() -> RunnableSequence:
    """Langchainã®åˆæœŸåŒ–."""
    prompt = hub.pull("rlm/rag-prompt")
    llm = ChatOpenAI()
    retriever = initialize_retriever()
    chain = (
        {"context": retriever, "question": RunnablePassthrough()} | prompt | llm
    )
    return chain


def main() -> None:
    """ChatGPTã‚’ä½¿ã£ãŸãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã®ãƒ¡ã‚¤ãƒ³é–¢æ•°."""
    chain = initialize_chain()

    # ãƒšãƒ¼ã‚¸ã®è¨­å®š
    st.set_page_config(page_title="RAG ChatGPT")
    st.header("RAG ChatGPT")

    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®åˆæœŸåŒ–
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ã‚’ç›£è¦–
    if user_input := st.chat_input("èããŸã„ã“ã¨ã‚’å…¥åŠ›ã—ã¦ã­ï¼"):
        st.session_state.messages.append(HumanMessage(content=user_input))
        with st.spinner("GPT is typing ..."):
            response = chain.invoke(user_input)
        st.session_state.messages.append(AIMessage(content=response.content))

    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®è¡¨ç¤º
    messages = st.session_state.get("messages", [])
    for message in messages:
        if isinstance(message, AIMessage):
            with st.chat_message("assistant"):
                st.markdown(message.content)
        elif isinstance(message, HumanMessage):
            with st.chat_message("user"):
                st.markdown(message.content)
        else:
            st.write(f"System message: {message.content}")


if __name__ == "__main__":
    main()

ã‚³ãƒ¼ãƒ‰ã®å„éƒ¨åˆ†ã‚’èª¬æ˜ã—ã¦ã„ãã¾ã™ã€‚

 initialize_vector_store
def initialize_vector_store() -> Chroma:
    """VectorStoreã®åˆæœŸåŒ–."""
    embeddings = OpenAIEmbeddings()

    vector_store_path = "./resources/note.db"
    if Path(vector_store_path).exists():
        vector_store = Chroma(embedding_function=embeddings, persist_directory=vector_store_path)
    else:
        loader = TextLoader("resources/note.txt")
        docs = loader.load()

        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
        splits = text_splitter.split_documents(docs)

        vector_store = Chroma.from_documents(
            documents=splits, embedding=embeddings, persist_directory=vector_store_path
        )

    return vector_store
Vector store ã¨ã¯æƒ…å ±ã¨ã—ã¦èª­ã¿è¾¼ã¾ã›ã¦ã„ã‚‹ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’é©åˆ‡ãªé•·ã•ã«åˆ†å‰²ã—(ãƒãƒ£ãƒ³ã‚¯ã¨å‘¼ã°ã‚Œã¾ã™) ã™ãã«å–ã‚Šå‡ºã›ã‚‹ã‚ˆã†ã«ä¿å­˜ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ã‚ˆã†ãªã‚‚ã®ã§ã™ã€‚
Embeddings ã¨å‘¼ã°ã‚Œã‚‹ãƒ¢ãƒ‡ãƒ«ã§ãƒ†ã‚­ã‚¹ãƒˆã¯æ•°å€¤æƒ…å ±ã®ãƒ™ã‚¯ãƒˆãƒ«ã«ä¿å­˜ã•ã‚Œã¾ã™ã€‚ãã®ä½œæ¥­ã‚’è¡Œã†ãŸã‚ã« OpenAI API ãŒå¿…è¦ã«ãªã£ã¦ã„ã‚‹ãŸã‚é–¢æ•°ã®æœ€åˆã§ OpenAIEmbeddings ã‚’å‘¼ã³å‡ºã—ã¦ã„ã¾ã™ã€‚
ç¶šã‘ã¦ Vector store ã¨ã—ã¦ä¿å­˜ã•ã‚Œã¦ã„ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã™ã§ã«å­˜åœ¨ã—ã¦ã„ãªã„ã‹ã‚’èª¿ã¹ã¦ã„ã¾ã™ã€‚åŸºæœ¬çš„ã«ãƒ‡ãƒ¼ã‚¿ã‚„ãƒ¢ãƒ‡ãƒ«ãŒã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆã•ã‚Œãªã„é™ã‚Š Vector store ã®ãƒ‡ãƒ¼ã‚¿ã¯ã¾ã£ãŸãåŒã˜ã«ãªã‚‹ãŸã‚ã€æ¯å›å®Ÿè¡Œã—ã¦ã—ã¾ã†ã¨æ™‚é–“ã‚‚ API ã®åˆ©ç”¨æ–™é‡‘ã‚‚ç„¡é§„ã«ãªã£ã¦ã—ã¾ã„ã¾ã™ã€‚
ãã“ã§

ã¾ã å­˜åœ¨ã—ã¦ã„ãªã„å ´åˆï¼š æ–°è¦ä½œæˆ
ã™ã§ã«å­˜åœ¨ã—ã¦ã„ã‚‹å ´åˆï¼š ä¿å­˜ã—ã¦ã„ã‚‹ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’èª­ã¿è¾¼ã‚€

ã¨ã—ã¦ã„ã¾ã™ã€‚
ãªãŠå­˜åœ¨ã—ã¦ã„ã‚‹å ´åˆ Chroma ã‚¯ãƒ©ã‚¹ã®å¼•æ•° embedding_function ã« embeddings ã‚’æŒ‡å®šã—ã¦ã„ã¾ã™ãŒã€ã“ã‚Œã¯ã‚¯ã‚¨ãƒªã¨ã—ã¦ã‚ãŸãˆã‚‰ã‚Œã‚‹ãƒ¦ãƒ¼ã‚¶ã®è³ªå•ã¨ Vector store ã«ä¿å­˜ã•ã‚Œã¦ã„ã‚‹ãƒ‡ãƒ¼ã‚¿ã¨ã®é–“ã®é–¢é€£æ€§ã‚’èª¿ã¹ã‚‹ãŸã‚ã«ã€ã‚¯ã‚¨ãƒªã‚‚ Embeddings ã§ãƒ™ã‚¯ãƒˆãƒ«ã«å¤‰æ›ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã‹ã‚‰ã§ã™ã€‚

 initialize_retriver
def initialize_retriever() -> VectorStoreRetriever:
    """Retrieverã®åˆæœŸåŒ–."""
    vector_store = initialize_vector_store()
    return vector_store.as_retriever()
ã“ã¡ã‚‰ã§ã¯ã€å…ˆã»ã©ä½œæˆã—ãŸ(ã‚ã‚‹ã„ã¯ã™ã§ã«ã‚ã‚‹ã‚‚ã®ã‚’èª­ã¿è¾¼ã‚“ã ) vector_store ã‚’ retriever ã«å¤‰æ›ã—ã¦ã„ã¾ã™ã€‚ã“ã¡ã‚‰ã® retriever ã“ã®å¾Œã€ Vectore store ã‹ã‚‰æƒ…å ±ã‚’å–ã‚Šå‡ºã™ã®ã«åˆ©ç”¨ã•ã‚Œã¾ã™ã€‚

 initialize_chain
def initialize_chain() -> RunnableSequence:
    """Langchainã®åˆæœŸåŒ–."""
    prompt = hub.pull("rlm/rag-prompt")
    llm = ChatOpenAI()
    retriever = initialize_retriever()
    chain = (
        {"context": retriever, "question": RunnablePassthrough()} | prompt | llm
    )
    return chain
ã“ã¡ã‚‰ã§ã¯ retriever ã®æƒ…å ±ã‚’ LLM ã§åˆ©ç”¨ã§ãã‚‹ã‚ˆã†ã« chain ã¨å‘¼ã°ã‚Œã‚‹æ¦‚å¿µã‚’åˆ©ç”¨ã—ã¦ãŠã‚Šã¾ã™ã€‚
ã‚ˆããƒ¡ã‚½ãƒƒãƒ‰ãƒã‚§ãƒ¼ãƒ³ã¨ã„ã†è¨€è‘‰ãŒãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°è¨€èªã§ã¯ä½¿ã‚ã‚Œã¦ã„ã¾ã™ã€‚
ä¾‹ãˆã° Python ã® Pandas ã§ã¯
import pandas as pd

# ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
data = {
    'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Edward', 'Frank'],
    'Age': [24, 27, 22, 32, 29, 24],
    'City': ['New York', 'Los Angeles', 'New York', 'Chicago', 'Los Angeles', 'New York'],
    'Score': [85, 90, 88, 92, 95, 70]
}

df = pd.DataFrame(data)

# ãƒ¡ã‚½ãƒƒãƒ‰ãƒã‚§ãƒ¼ãƒ³ã‚’ä½¿ã£ãŸãƒ‡ãƒ¼ã‚¿å¤‰æ›
result = (df
          .query('Age > 25')                     # å¹´é½¢ãŒ25ä»¥ä¸Šã®è¡Œã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
          .groupby('City')                       # éƒ½å¸‚ã”ã¨ã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
          .agg({'Score': 'mean'})                # ã‚¹ã‚³ã‚¢ã®å¹³å‡ã‚’è¨ˆç®—
          .rename(columns={'Score': 'Average Score'})  # åˆ—åã‚’å¤‰æ›´
          .sort_values(by='Average Score', ascending=False)  # å¹³å‡ã‚¹ã‚³ã‚¢ã§ä¸¦ã¹æ›¿ãˆ
          .reset_index()                         # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ãƒªã‚»ãƒƒãƒˆ
         )

print(result)
ã¨ã„ã†ã‚ˆã†ã«ãƒ¡ã‚½ãƒƒãƒ‰ã®è¿”ã‚Šå€¤ã‚’æ¬¡ã®ãƒ¡ã‚½ãƒƒãƒ‰ã¸ã¨ãƒã‚±ãƒ„ãƒªãƒ¬ãƒ¼ã®ã‚ˆã†ã«ã¤ãªã„ã§è¡Œãå‡¦ç†ã•ã›ã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚ã“ã‚Œã‚’ãƒ¡ã‚½ãƒƒãƒ‰ãƒã‚§ãƒ¼ãƒ³ã¨ã„ã„ã¾ã™ã€‚
LangChain ã§ã‚‚ã“ã®ãƒã‚±ãƒ„ãƒªãƒ¬ãƒ¼ã‚’è¡Œã„ã€ã©ã®ã‚ˆã†ã«ãƒ¦ãƒ¼ã‚¶ã®è³ªå•ã«ç­”ãˆã‚‹ã‹ã®ãƒ«ãƒ¼ãƒ«ã‚’æ±ºã‚ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚
LangChain ã®å ´åˆã¯æ˜”ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã§ã¯é–¢æ•°ã®è¿”ã‚Šå€¤ã‚’ã•ã‚‰ã«é–¢æ•°ã®å¼•æ•°ã«ã™ã‚‹ã¨è¨€ã†ã“ã¨ã‚’ç¹°ã‚Šè¿”ã—ã¦ãƒã‚±ãƒ„ãƒªãƒ¬ãƒ¼ã‚’è¡Œã£ã¦ã„ã¾ã—ãŸãŒã€ä»Šã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ 0.2.5 ã§ã¯ä»¥ä¸‹ã®ã‚ˆã†ã« | ã‚’åˆ©ç”¨ã—ãƒã‚§ãƒ¼ãƒ³ã‚’ç¤ºã™ã“ã¨ãŒæ¨å¥¨ã•ã‚Œã¦ã„ã¾ã™ã€‚
    chain = (
        {"context": retriever, "question": RunnablePassthrough()} | prompt | llm
    )
ä»Šå›ã®å ´åˆ

{"context": retriever, "question": RunnablePassthrough()}
prompt
llm

ã¨ã„ã†é †ç•ªã§ãƒã‚§ãƒ¼ãƒ³ãŒã¤ãªãŒã£ã¦ã„ã¾ã™ã€‚
ãƒã‚§ãƒ¼ãƒ³ã®å…ˆé ­ãŒãªãœè¾æ›¸ã§ã‚ã‚‹ã‹ã¯ã€2ç•ªç›®ã® prompt ã®èª¬æ˜ã‚’èã„ã¦ã‚‚ã‚‰ãˆã‚Œã°ã‚ã‹ã‚‹ã¨æ€ã„ã¾ã™ã€‚
    prompt = hub.pull("rlm/rag-prompt")
prompt ã¯ LLM ã«ã©ã®ã‚ˆã†ãªè³ªå•ã‚„ä¾é ¼ã‚’ã™ã‚‹ã®ã‹ã‚’æ±ºã‚ã‚‹éƒ¨åˆ†ã§ã™ã€‚ä»Šå›ã¯ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ(å¤‰æ•°åã‚’æŒ‡ã—ã¦ã„ãªã„å ´åˆã‚«ã‚¿ã‚«ãƒŠè¡¨è¨˜ã¨ã—ã¾ã™)ã‚’æœ‰å¿—ã®æ–¹ãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ä»–ã®äººãŒåˆ©ç”¨ã§ãã‚‹ã‚ˆã†ã«ã—ã¦ãã‚Œã¦ã„ã‚‹ã‚µã‚¤ãƒˆ LangChain Hub ã‹ã‚‰ â­ ãŒå¤šã„ã‚‚ã®ã‚’ãŠå€Ÿã‚Šã—ã¦ãã¾ã—ãŸã€‚ã‚‚ã¡ã‚ã‚“è‡ªä½œã—ã¦ã‚‚ã‚‰ã£ã¦ã‚‚OKã§ã™ã€‚
https://smith.langchain.com/hub/rlm/rag-prompt
ãŠå€Ÿã‚Šã—ãŸ rag-prompt ã§ã¯ä»¥ä¸‹ã®ã‚ˆã†ã«ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒå®šç¾©ã•ã‚Œã¦ã„ã¾ã™ã€‚
You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.
Question: {question} 
Context: {context} 
Answer:
ç°¡å˜ã«æ—¥æœ¬èªã«è¨³ã™ã¨ ã€Œ context ã®æƒ…å ±ã®ã¿ã‚’ä½¿ã£ã¦ question ã«ç­”ãˆã‚‹ã‚ˆã†ã« Answer ã‚’è€ƒãˆãªã•ã„ã€‚ç­”ãˆã‚‰ã‚Œãªã„ãªã‚‰ã‚ã‹ã‚‰ãªã„ã¨ç­”ãˆãªã•ã„ã€‚ã€ ã¨ãªã‚Šã¾ã™ã€‚ context ã®æƒ…å ±ã®ã¿ã‚’ç”¨ã„ã‚‹ã‚ˆã†æŒ‡å®šã™ã‚‹ã“ã¨ã§ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³ã‚’é˜²ãåŠ¹æœãŒã‚ã‚Šã¾ã™ (ãŸã ã—ï¼‘ï¼ï¼ï¼…é˜²ãã¨ã¯æ–­è¨€ã§ããªã„ã§ã™)
ã“ã¡ã‚‰ã® question éƒ¨åˆ†ã«ãƒ¦ãƒ¼ã‚¶ã®ã‚¯ã‚¨ãƒªãŒã€ context éƒ¨åˆ†ã« retriever ã‚’æŒ‡å®šã—ã¦ prompt ã‚’å®Ÿè¡Œã›ã‚ˆã¨ã—ã¦ã„ã‚‹ã®ãŒãƒã‚§ãƒ¼ãƒ³ã® {"context": retriever, "question": RunnablePassthrough()} | prompt ã®éƒ¨åˆ†ã§ã™ã€‚
æœ€å¾Œã«å®Œæˆã—ãŸ prompt ã‚’ llm ã«æ¸¡ã—ãªã•ã„ã¨æŒ‡å®šã—ã¦ã„ã‚‹ã®ãŒ prompt | llm ã®éƒ¨åˆ†ã§ã™ã€‚
ã“ã®ãƒ¡ã‚½ãƒƒãƒ‰ãƒã‚§ãƒ¼ãƒ³ã‚’ã¾ã¨ã‚ãŸ chain ã¨ã„ã†å¤‰æ•°ã¯ invoke ãƒ¡ã‚½ãƒƒãƒ‰ã‚’æŒã£ã¦ãŠã‚Šã€ã“ã®ãƒ¡ã‚½ãƒƒãƒ‰ã«è³ªå•ã‚’æŠ•ã’ã‚‹ã¨ãã‚ŒãŒ question ã«å…¥ã‚Šãƒã‚§ãƒ¼ãƒ³ãŒå‰ã‹ã‚‰é †ç•ªã«å®Ÿè¡Œã•ã‚Œã¾ã™ã€‚
ä»¥ä¸Šã®ã‚ˆã†ã«å®šç¾©ã™ã‚‹ã“ã¨ã§ RAG ã¨ã—ã¦å¤–éƒ¨ã®æƒ…å ±ã‚’å‚ç…§ã—ã¤ã¤å›ç­”ã™ã‚‹ ChatBot ã‚’å®Ÿè£…ã§ãã¾ã—ãŸã€‚

 main
def main() -> None:
    """ChatGPTã‚’ä½¿ã£ãŸãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã®ãƒ¡ã‚¤ãƒ³é–¢æ•°."""
    chain = initialize_chain()

    # ãƒšãƒ¼ã‚¸ã®è¨­å®š
    st.set_page_config(page_title="RAG ChatGPT")
    st.image(img, use_column_width=False)
    st.header("RAG ChatGPT")

    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®åˆæœŸåŒ–
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ã‚’ç›£è¦–
    if user_input := st.chat_input("èããŸã„ã“ã¨ã‚’å…¥åŠ›ã—ã¦ã­ï¼"):
        st.session_state.messages.append(HumanMessage(content=user_input))
        with st.spinner("GPT is typing ..."):
            response = chain.invoke(user_input)
        st.session_state.messages.append(AIMessage(content=response.content))

    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®è¡¨ç¤º
    messages = st.session_state.get("messages", [])
    for message in messages:
        if isinstance(message, AIMessage):
            with st.chat_message("assistant"):
                st.markdown(message.content)
        elif isinstance(message, HumanMessage):
            with st.chat_message("user"):
                st.markdown(message.content)
        else:
            st.write(f"System message: {message.content}")
æœ€å¾Œã« main é–¢æ•°ã§ã™ã€‚ã“ã¡ã‚‰ã¯ LangChain ã®å®Ÿè£…ã¨ã„ã†ã‚ˆã‚Šã¯ Streamlit ã‚’åˆ©ç”¨ã—ãŸãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰éƒ¨åˆ†ã®å®Ÿè£…ã«ãªã‚Šã¾ã™ã€‚
ã‚­ãƒ¼ã¨ãªã‚‹ç‚¹ã ã‘è§£èª¬ã™ã‚‹ã¨

ãƒ¦ãƒ¼ã‚¶ã¨ ChatBot ã®ä¼šè©±ã¯ messages ã«ä¿å­˜ã•ã‚Œã¦ã„ã¾ã™ã€‚ä»¥ä¸‹ã®ã‚³ãƒ¼ãƒ‰ã‚’è¦‹ã‚‹ã¨ã‚ã‹ã‚‹ã‚ˆã†ã«ãƒ¦ãƒ¼ã‚¶ã‹ã‚‰ã®è³ªå•ã¨ ChatBot ã®è¿”ç­”ã¯ã©ã¡ã‚‰ã‚‚ messages ã« append ã•ã‚Œã¦ã„ã¾ã™ã€‚

    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®åˆæœŸåŒ–
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ã‚’ç›£è¦–
    if user_input := st.chat_input("èããŸã„ã“ã¨ã‚’å…¥åŠ›ã—ã¦ã­ï¼"):
        st.session_state.messages.append(HumanMessage(content=user_input))
        with st.spinner("GPT is typing ..."):
            response = chain.invoke(user_input)
        st.session_state.messages.append(AIMessage(content=response.content))

ãƒ¦ãƒ¼ã‚¶ã‹ã‚‰ã®è³ªå•ã¸ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã¯å…ˆã»ã©å®šç¾©ã—ãŸ chain ã® invoke ãƒ¡ã‚½ãƒƒãƒ‰ã‚’ç”¨ã„ã¦ä½œã‚‰ã‚Œã¦ã„ã¾ã™ã€‚

        with st.spinner("GPT is typing ..."):
            response = chain.invoke(user_input)
        st.session_state.messages.append(AIMessage(content=response.content))
ã¨ã„ã†ç‚¹ãŒã‚ã’ã‚‰ã‚Œã¾ã™ã€‚

 ãƒ†ã‚¹ãƒˆ
ãã‚Œã§ã¯å®Ÿè£…ã—ãŸã‚‚ã®ã‚’å‹•ã‹ã—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚
> streamlit run chatbot.py

Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.


  You can now view your Streamlit app in your browser.

  Local URL: http://localhost:8501
  Network URL: http://10.200.0.4:8501
  External URL: http://13.73.233.61:8501
http://localhost:8501 ã¸ãƒ–ãƒ©ã‚¦ã‚¶ã‹ã‚‰ã‚¢ã‚¯ã‚»ã‚¹ã—ã€è³ªå•ã—ã¦ã¿ã¾ã™ã€‚

ç¾æ™‚ç‚¹ã§ã® note.txt ã®å…ˆé ­ã®æ–¹ã«æ›¸ã„ã¦ã‚ã£ãŸæ–°ã—ã„ãƒ“ã‚¸ãƒ§ãƒ³ã‚’ã¡ã‚ƒã‚“ã¨ç­”ãˆã¦ã„ã¾ã™ã€‚ã“ã®æƒ…å ±ã¯ OpenAI ã«ã¯ãªã„ãŸã‚ãã¡ã‚“ã¨ RAG ãŒåƒã„ã¦ã„ã‚‹ã¨è¨€ãˆãã†ã§ã™ã€‚

ã¾ãŸã€Œ100å¹´å¾Œã«ç™ºå£²äºˆå®šã®æ–°å•†å“ã€ã¨ã„ã†æƒ…å ±ã¨ã—ã¦å«ã¾ãªã„ã‚ˆã†ãªè³ªå•ã‚’ã™ã‚‹ã¨ã¡ã‚ƒã‚“ã¨ã€Œæƒ…å ±ã‚’æŒã£ã¦ã„ãªã„ã€ã¨è¿”ç­”ã—ã¦ãã‚Œã¾ã™ã€‚ã“ã¡ã‚‰ã‚‚æœŸå¾…é€šã‚Šã§ã™ã­ã€‚

 ğŸ’¡ ã¾ã¨ã‚

LangChain v0.2.5 æ™‚ç‚¹ã§ã® RAG ã‚’ç”¨ã„ãŸ ChatBot ã®å®Ÿè£…ã‚’è¡Œã„ã¾ã—ãŸ
Streamlit ã‚’ç”¨ã„ã¦ãƒ–ãƒ©ã‚¦ã‚¶ã‹ã‚‰ãƒ¦ãƒ¼ã‚¶ãŒã‚¢ã‚¯ã‚»ã‚¹ã§ãã‚‹ã‚ˆã†ã«ã—ã¾ã—ãŸ

ãœã²å‚è€ƒã«ã—ã¦ã¿ã¦ãã ã•ã„ã€‚
yamasaKitcheminformatics, machine learning, board gameCykinso's Tech BlogPublicationã€Œç´°èŒå¢ã®åŠ›ã§äººã€…ã‚’å¥åº·ã«ã€ã‚’ãƒŸãƒƒã‚·ãƒ§ãƒ³ã«æ²ã’ã‚‹ãƒã‚¤ã‚ªãƒ†ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆã‚¢ãƒƒãƒ—ã€Œã‚µã‚¤ã‚­ãƒ³ã‚½ãƒ¼ã€ã®æŠ€è¡“ãƒ–ãƒ­ã‚°ã€‚ ãƒãƒƒã‚¸ã‚’è´ˆã£ã¦è‘—è€…ã‚’å¿œæ´ã—ã‚ˆã†ãƒãƒƒã‚¸ã‚’å—ã‘å–ã£ãŸè‘—è€…ã«ã¯Zennã‹ã‚‰ç¾é‡‘ã‚„Amazonã‚®ãƒ•ãƒˆã‚«ãƒ¼ãƒ‰ãŒé‚„å…ƒã•ã‚Œã¾ã™ã€‚ãƒãƒƒã‚¸ã‚’è´ˆã‚‹DiscussionyamasaKitcheminformatics, machine learning, board gameãƒãƒƒã‚¸ã‚’è´ˆã‚‹ãƒãƒƒã‚¸ã‚’è´ˆã‚‹ã¨ã¯ç›®æ¬¡èƒŒæ™¯ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ãªã©æ–¹æ³•.envãƒ‡ãƒ¼ã‚¿ã‚³ãƒ¼ãƒ‰initialize_vector_storeinitialize_retriverinitialize_chainmainãƒ†ã‚¹ãƒˆğŸ’¡ ã¾ã¨ã‚
divchatbotOpenAILangChainLLMRAGtech
 èƒŒæ™¯
LangChain ã¯ OpenAI API ã‚’åˆ©ç”¨ã—è‡ªåˆ†ãŸã¡ãŒã‚„ã‚ŠãŸã„ã“ã¨ã‚’å®Ÿç¾ã™ã‚‹ã“ã¨ã«éå¸¸ã«ä¾¿åˆ©ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã§ã™ãŒãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚¢ãƒƒãƒ—ã«ã‚ˆã£ã¦ã‚¯ãƒ©ã‚¹åã‚„ã‚µãƒ–ãƒ©ã‚¤ãƒ–ãƒ©ãƒªåã®å¤‰æ›´ãŒã‚„ã‚„å¤šãå°‘ã—å¤ã„ Web è¨˜äº‹ã‚’å‚è€ƒã«ã—ã¦ã‚‚ã†ã¾ããƒ¯ãƒ¼ã‚¯ã—ãªã„ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚
ã“ã®è¨˜äº‹ã¯ 2024/6/20 ç¾åœ¨ã® LangChain (ãƒãƒ¼ã‚¸ãƒ§ãƒ³ 0.2.5) ã§ OpenAI API ã‚„ Azure OpenAI API ã‚’å‹•ã‹ã™ä¾‹ã¨ã—ã¦æ®‹ã—ã¦ãŠãã¾ã™ã€‚
åŒã˜ã‚ˆã†ãªã“ã¨ã‚’ã—ã‚ˆã†ã¨ã—ã¦ç§ã®ã‚ˆã†ã«è‹¦æˆ¦ã—ã¦ã„ã‚‹æ–¹ã®åŠ©ã‘ã«ãªã‚Œã°å¹¸ã„ã§ã™ã€‚

 ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ãªã©

pyproject.toml
python = ">=3.12,<3.13"
python-dotenv = "^1.0.1"
chromadb = "0.5.2"
langchain = "0.2.5"
langchain-cli = "0.0.25"
langchain-openai = "0.1.8"
langchain-community = "0.2.5"
langchain-chroma = "0.1.1"
langchainhub = "0.1.20"
streamlit = "1.35.0"

ğŸ’¡ Poetry ã§ Python ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’æŒ‡å®šã™ã‚‹æ™‚ã« ^3.12 ã¨ã™ã‚‹ã¨ lancghain-chroma ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã§ããªããªã‚‹ã®ã§ >=3.12,<3.13 ã¨ã—ã¾ã—ãŸã€‚
(langchain-chroma ã¯ >=3.12,<3.13 ã¨ã„ã†æŒ‡å®šãŒã‚ã‚Šã¾ã™)

 æ–¹æ³•
OpenAI API ã‚’ä½¿ã†å ´åˆã¨ AzureOpenAI API ã‚’ä½¿ã†å ´åˆã¯åŸºæœ¬åŒã˜ã“ã¨ã‚’ã™ã‚‹ã®ã§ã¾ãš OpenAI API ã‚’ä½¿ã†å ´åˆã‚’èª¬æ˜ã—ã€è¨˜äº‹ãŒé•·ããªã£ã¦ã—ã¾ã£ãŸã®ã§ã€å¾Œæ—¥åˆ¥è¨˜äº‹ã«ã¦ AzureOpenAI API ã‚’ä½¿ã†å ´åˆã¯ã©ã®éƒ¨åˆ†ã‚’ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆã—ãŸã‚‰ã‚ˆã„ã®ã‹ã‚’èª¬æ˜ã—ãŸã„ã¨æ€ã„ã¾ã™ã€‚
6/28 è¿½è¨˜) AzureOpenAI API ç‰ˆã®è¨˜äº‹ã‚‚æ›¸ãã¾ã—ãŸã®ã§ã‚ˆã‘ã‚Œã°ãœã²ã©ã†ã
https://zenn.dev/cykinso/articles/b055e33734d06b

 .env
ä»¥ä¸‹ã®ã‚ˆã†ã« .env ã‚’ç”¨æ„ã—ã¾ã™ã€‚
OPENAI_API_KEY=sk-XXXXXXXXXXXXXXXX
OPENAI_API_VERSION=2024-02-01
ã‚‚ã— OPENAI_API_KEY ã‚’ã¾ã å–å¾—ã—ã¦ã„ãªã„å ´åˆã¯ä»¥ä¸‹ã®æ–¹æ³•ã§å–å¾—ã—ã¦ãã ã•ã„ã€‚

 OPENAI_API_KEY
OPENAI_API_KEY ã¯ OpenAI ã® Dashboard ã§ä½œæˆã§ãã¾ã™ã€‚
(èª²é‡‘å¯¾è±¡ãªã®ã§ã”è‡ªèº«ã®è²¬ä»»ã®ã‚‚ã¨ã”åˆ©ç”¨ãã ã•ã„)

ã€Œ+ Create new secret keyã€ ã‚’æŠ¼ã™ã¨ãƒ¢ãƒ¼ãƒ€ãƒ«ãŒé–‹ãã®ã§å¾Œã‹ã‚‰åŒºåˆ¥ã§ãã‚‹ã‚ˆã†ãªåå‰ã‚’ã¤ã‘ã¦ ã€ŒCreate secret keyã€ ã‚’æŠ¼ã—ã¾ã™ã€‚

è¡¨ç¤ºã•ã‚Œã‚‹ API ã‚­ãƒ¼ã‚’ .env ã«ãƒ¡ãƒ¢ã—ã¦ãŠãã¾ã™ã€‚ ã€ŒDoneã€ ã‚’æŠ¼ã™ã¨ã‚‚ã†è¡¨ç¤ºã§ãã¾ã›ã‚“ã€‚


 ãƒ‡ãƒ¼ã‚¿
OpenAI ãŒã¾ã å­¦ç¿’ã—ã¦ã„ãªã•ãã†ãªãƒ‡ãƒ¼ã‚¿ã®ä¾‹ã¨ã—ã¦å¼Šç¤¾ Cykinso ã®ãƒ–ãƒ­ã‚°è¨˜äº‹ã®ã€Œä¼šç¤¾ã®ãƒ“ã‚¸ãƒ§ãƒ³ã‚’è©±ã—ã¦ã„ã‚‹ãƒšãƒ¼ã‚¸ã€ã‚’ä»Šå›ã¯ç”¨ã„ãŸã„ã¨æ€ã„ã¾ã™ã€‚
https://note.com/cykinso/n/n432d5ea70783
ğŸ’¡ ãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆã§å®Ÿè£…ã™ã‚‹å ´åˆã¯ã€å¥½ããªãƒãƒ³ã‚¬ãªã©ã®è©³ç´°ã‚’ãƒ†ã‚­ã‚¹ãƒˆã«ã¾ã¨ã‚ã¦ãƒ‡ãƒ¼ã‚¿ã¨ã™ã‚‹ã¨ãƒ¢ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³ã‚‚ä¸ŠãŒã‚‹ã¨æ€ã„ã¾ã™ã€‚
ã–ã£ã¨æ–‡ç« ã‚’ã‚³ãƒ”ãƒ¼ã—ã¦ä»¥ä¸‹ã®ã‚ˆã†ã«æ•´å½¢ã—ã¾ã—ãŸã€‚

note.txt
ç´°èŒå¢ã‹ã‚‰ã®æ–°ãŸãªæ°—ä»˜ãã‚’é€šã˜ã¦ã€æ–°ãƒ“ã‚¸ãƒ§ãƒ³ã‚’ç­–å®šã—ã¾ã—ãŸï¼
2023å¹´11æœˆã«ã‚µã‚¤ã‚­ãƒ³ã‚½ãƒ¼ã¯10æœŸç›®ã«å…¥ã‚Šã¾ã—ãŸã€‚é«˜é½¢åŒ–ç¤¾ä¼šã«ã‚ˆã‚‹ç¤¾ä¼šä¿éšœã¸ã®ä¸å®‰ãŒå‹Ÿã‚‹ç¾åœ¨ã€ç—…æ°—ã‚’æœªç„¶ã«é˜²ã0æ¬¡äºˆé˜²ã®é‡è¦æ€§ãŒé«˜ã¾ã£ã¦ã„ã¾ã™ã€‚ã€Œç´°èŒå¢ã§äººã€…ã‚’å¥åº·ã«ã€ã¨ã„ã†ãƒŸãƒƒã‚·ãƒ§ãƒ³ã«å‘ã‘ã¦ã€ã‚µã‚¤ã‚­ãƒ³ã‚½ãƒ¼ã¯æ–°ãŸãªãƒ“ã‚¸ãƒ§ãƒ³ã‚’åˆ¶å®šã—ã¾ã—ãŸã€‚
æ–°ã—ã„ãƒ“ã‚¸ãƒ§ãƒ³ã«ã¤ã„ã¦
ãƒ¼ãƒ“ã‚¸ãƒ§ãƒ³å¤‰æ›´ã§å…·ä½“çš„ã«ã©ã®å€‹æ‰€ãŒå¤‰æ›´ã—ãŸã‹ã‚’ã¾ãšã”ç´¹ä»‹ã—ã¾ã™ã€‚
ã“ã¡ã‚‰ãŒã‚µã‚¤ã‚­ãƒ³ã‚½ãƒ¼ã®ãƒŸãƒƒã‚·ãƒ§ãƒ³ï¼ˆMISSIONï¼‰ã€ãƒ“ã‚¸ãƒ§ãƒ³(VISION)ã€ãƒãƒªãƒ¥ãƒ¼(VALUE)ã«ãªã‚Šã¾ã™ã€‚
ç§ãŸã¡ãŒç›®æŒ‡ã—ç¶šã‘ã‚‹ã€Œç´°èŒå¢ã§äººã€…ã‚’å¥åº·ã«ã€ã¨ã„ã†ãƒŸãƒƒã‚·ãƒ§ãƒ³ã¯ãã®ã¾ã¾ã«ã€ãƒ“ã‚¸ãƒ§ãƒ³ã‚’æ–°ã—ãå¤‰æ›´è‡´ã—ã¾ã—ãŸã€‚

ï¼œã“ã‚Œã¾ã§ã®ãƒ“ã‚¸ãƒ§ãƒ³ï¼
èŒå¢ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã€Œæ¬¡ä¸–ä»£ã®ãƒ©ã‚¤ãƒ•ã‚¹ã‚¿ã‚¤ãƒ«ã€ã‚’æä¾›ã™ã‚‹ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã«ãªã‚‹

ï¼œæ–°ã—ã„ãƒ“ã‚¸ãƒ§ãƒ³ï¼
ç´°èŒå¢ã‹ã‚‰ã®æ–°ãŸãªæ°—ä»˜ãã‚’é€šã˜ã¦
ãƒ’ãƒˆã€ç¤¾ä¼šã€åœ°çƒç’°å¢ƒã‚’å¥åº·ã«ã™ã‚‹ã‚¨ã‚³ã‚·ã‚¹ãƒ†ãƒ ã‚’å®Ÿç¾ã™ã‚‹
æ–°ã—ã„ãƒ“ã‚¸ãƒ§ãƒ³ã§ã¯ã€ã‚µã‚¤ã‚­ãƒ³ã‚½ãƒ¼ãŒå½±éŸ¿ã‚’ä¸ãˆã¦ã„ããŸã„ç¯„å›²ã‚‚ã“ã‚Œã¾ã§ã‚ˆã‚Šã•ã‚‰ã«å¤§ãããªã£ãŸã“ã¨ãŒåˆ†ã‹ã‚Šã¾ã™ã€‚

ä»Šå›ã®ãƒ“ã‚¸ãƒ§ãƒ³å¤‰æ›´ã‚’é€šã—ã¦ã€ã‚µã‚¤ã‚­ãƒ³ã‚½ãƒ¼ãŒã©ã‚“ãªä¾¡å€¤ç™ºæ®ã‚’ç›®æŒ‡ã—ã¦ã„ãã®ã‹ã€ãã‚Œã«ä¼´ã„äº‹æ¥­é¢ã§ã¯ã©ã‚“ãªæŒ‘æˆ¦ã‚’ã—ã¦ã„ãã®ã‹ã‚’ã€ä»£è¡¨å–ç· å½¹CEOã®æ²¢äº•ã•ã‚“ã«èã„ã¦ãã¾ã—ãŸï¼

...(ä»¥ä¸‹ç•¥)


 ã‚³ãƒ¼ãƒ‰
ç¶šã‘ã¦ã‚³ãƒ¼ãƒ‰ã‚’å®Ÿè£…ã—ã¾ã™ã€‚
ä»Šå›ã¯ RAG ã¨ã—ã¦å¤–éƒ¨ã®æƒ…å ±ã‚’å‚ç…§ã—ã¤ã¤å›ç­”ã™ã‚‹ ChatBot ã‚’å®Ÿè£…ã—ã¦ã¿ã¾ã™ã€‚
ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã¨ã—ã¦ streamlit ã‚’ç”¨ã„ã¾ã™ã€‚
å…ˆã«ã‚³ãƒ¼ãƒ‰å…¨ä½“ã‚’ç¤ºã™ã¨ä»¥ä¸‹ã®ã‚ˆã†ã«ãªã‚Šã¾ã™ã€‚
(streamlit ã®ã‚³ãƒ¼ãƒ‰ã®ãƒ™ãƒ¼ã‚¹ã¨ã—ã¦ä»¥ä¸‹ã®è¨˜äº‹ã‚’å‚è€ƒã«ã•ã›ã¦ã„ãŸã ãã¾ã—ãŸã€‚ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™)
https://tech-lab.sios.jp/archives/41574

chatbot.py
from pathlib import Path

import streamlit as st
from dotenv import load_dotenv
from langchain import hub
from langchain.schema import AIMessage, HumanMessage
from langchain_chroma import Chroma
from langchain_community.document_loaders import TextLoader
from langchain_core.runnables import RunnablePassthrough, RunnableSequence
from langchain_core.vectorstores import VectorStoreRetriever
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_text_splitters import RecursiveCharacterTextSplitter

load_dotenv()


def initialize_vector_store() -> Chroma:
    """VectorStoreã®åˆæœŸåŒ–."""
    embeddings = OpenAIEmbeddings()

    vector_store_path = "./resources/note.db"
    if Path(vector_store_path).exists():
        vector_store = Chroma(embedding_function=embeddings, persist_directory=vector_store_path)
    else:
        loader = TextLoader("resources/note.txt")
        docs = loader.load()

        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
        splits = text_splitter.split_documents(docs)

        vector_store = Chroma.from_documents(
            documents=splits, embedding=embeddings, persist_directory=vector_store_path
        )

    return vector_store


def initialize_retriever() -> VectorStoreRetriever:
    """Retrieverã®åˆæœŸåŒ–."""
    vector_store = initialize_vector_store()
    return vector_store.as_retriever()


def initialize_chain() -> RunnableSequence:
    """Langchainã®åˆæœŸåŒ–."""
    prompt = hub.pull("rlm/rag-prompt")
    llm = ChatOpenAI()
    retriever = initialize_retriever()
    chain = (
        {"context": retriever, "question": RunnablePassthrough()} | prompt | llm
    )
    return chain


def main() -> None:
    """ChatGPTã‚’ä½¿ã£ãŸãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã®ãƒ¡ã‚¤ãƒ³é–¢æ•°."""
    chain = initialize_chain()

    # ãƒšãƒ¼ã‚¸ã®è¨­å®š
    st.set_page_config(page_title="RAG ChatGPT")
    st.header("RAG ChatGPT")

    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®åˆæœŸåŒ–
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ã‚’ç›£è¦–
    if user_input := st.chat_input("èããŸã„ã“ã¨ã‚’å…¥åŠ›ã—ã¦ã­ï¼"):
        st.session_state.messages.append(HumanMessage(content=user_input))
        with st.spinner("GPT is typing ..."):
            response = chain.invoke(user_input)
        st.session_state.messages.append(AIMessage(content=response.content))

    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®è¡¨ç¤º
    messages = st.session_state.get("messages", [])
    for message in messages:
        if isinstance(message, AIMessage):
            with st.chat_message("assistant"):
                st.markdown(message.content)
        elif isinstance(message, HumanMessage):
            with st.chat_message("user"):
                st.markdown(message.content)
        else:
            st.write(f"System message: {message.content}")


if __name__ == "__main__":
    main()

ã‚³ãƒ¼ãƒ‰ã®å„éƒ¨åˆ†ã‚’èª¬æ˜ã—ã¦ã„ãã¾ã™ã€‚

 initialize_vector_store
def initialize_vector_store() -> Chroma:
    """VectorStoreã®åˆæœŸåŒ–."""
    embeddings = OpenAIEmbeddings()

    vector_store_path = "./resources/note.db"
    if Path(vector_store_path).exists():
        vector_store = Chroma(embedding_function=embeddings, persist_directory=vector_store_path)
    else:
        loader = TextLoader("resources/note.txt")
        docs = loader.load()

        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
        splits = text_splitter.split_documents(docs)

        vector_store = Chroma.from_documents(
            documents=splits, embedding=embeddings, persist_directory=vector_store_path
        )

    return vector_store
Vector store ã¨ã¯æƒ…å ±ã¨ã—ã¦èª­ã¿è¾¼ã¾ã›ã¦ã„ã‚‹ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’é©åˆ‡ãªé•·ã•ã«åˆ†å‰²ã—(ãƒãƒ£ãƒ³ã‚¯ã¨å‘¼ã°ã‚Œã¾ã™) ã™ãã«å–ã‚Šå‡ºã›ã‚‹ã‚ˆã†ã«ä¿å­˜ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ã‚ˆã†ãªã‚‚ã®ã§ã™ã€‚
Embeddings ã¨å‘¼ã°ã‚Œã‚‹ãƒ¢ãƒ‡ãƒ«ã§ãƒ†ã‚­ã‚¹ãƒˆã¯æ•°å€¤æƒ…å ±ã®ãƒ™ã‚¯ãƒˆãƒ«ã«ä¿å­˜ã•ã‚Œã¾ã™ã€‚ãã®ä½œæ¥­ã‚’è¡Œã†ãŸã‚ã« OpenAI API ãŒå¿…è¦ã«ãªã£ã¦ã„ã‚‹ãŸã‚é–¢æ•°ã®æœ€åˆã§ OpenAIEmbeddings ã‚’å‘¼ã³å‡ºã—ã¦ã„ã¾ã™ã€‚
ç¶šã‘ã¦ Vector store ã¨ã—ã¦ä¿å­˜ã•ã‚Œã¦ã„ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã™ã§ã«å­˜åœ¨ã—ã¦ã„ãªã„ã‹ã‚’èª¿ã¹ã¦ã„ã¾ã™ã€‚åŸºæœ¬çš„ã«ãƒ‡ãƒ¼ã‚¿ã‚„ãƒ¢ãƒ‡ãƒ«ãŒã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆã•ã‚Œãªã„é™ã‚Š Vector store ã®ãƒ‡ãƒ¼ã‚¿ã¯ã¾ã£ãŸãåŒã˜ã«ãªã‚‹ãŸã‚ã€æ¯å›å®Ÿè¡Œã—ã¦ã—ã¾ã†ã¨æ™‚é–“ã‚‚ API ã®åˆ©ç”¨æ–™é‡‘ã‚‚ç„¡é§„ã«ãªã£ã¦ã—ã¾ã„ã¾ã™ã€‚
ãã“ã§

ã¾ã å­˜åœ¨ã—ã¦ã„ãªã„å ´åˆï¼š æ–°è¦ä½œæˆ
ã™ã§ã«å­˜åœ¨ã—ã¦ã„ã‚‹å ´åˆï¼š ä¿å­˜ã—ã¦ã„ã‚‹ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’èª­ã¿è¾¼ã‚€

ã¨ã—ã¦ã„ã¾ã™ã€‚
ãªãŠå­˜åœ¨ã—ã¦ã„ã‚‹å ´åˆ Chroma ã‚¯ãƒ©ã‚¹ã®å¼•æ•° embedding_function ã« embeddings ã‚’æŒ‡å®šã—ã¦ã„ã¾ã™ãŒã€ã“ã‚Œã¯ã‚¯ã‚¨ãƒªã¨ã—ã¦ã‚ãŸãˆã‚‰ã‚Œã‚‹ãƒ¦ãƒ¼ã‚¶ã®è³ªå•ã¨ Vector store ã«ä¿å­˜ã•ã‚Œã¦ã„ã‚‹ãƒ‡ãƒ¼ã‚¿ã¨ã®é–“ã®é–¢é€£æ€§ã‚’èª¿ã¹ã‚‹ãŸã‚ã«ã€ã‚¯ã‚¨ãƒªã‚‚ Embeddings ã§ãƒ™ã‚¯ãƒˆãƒ«ã«å¤‰æ›ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã‹ã‚‰ã§ã™ã€‚

 initialize_retriver
def initialize_retriever() -> VectorStoreRetriever:
    """Retrieverã®åˆæœŸåŒ–."""
    vector_store = initialize_vector_store()
    return vector_store.as_retriever()
ã“ã¡ã‚‰ã§ã¯ã€å…ˆã»ã©ä½œæˆã—ãŸ(ã‚ã‚‹ã„ã¯ã™ã§ã«ã‚ã‚‹ã‚‚ã®ã‚’èª­ã¿è¾¼ã‚“ã ) vector_store ã‚’ retriever ã«å¤‰æ›ã—ã¦ã„ã¾ã™ã€‚ã“ã¡ã‚‰ã® retriever ã“ã®å¾Œã€ Vectore store ã‹ã‚‰æƒ…å ±ã‚’å–ã‚Šå‡ºã™ã®ã«åˆ©ç”¨ã•ã‚Œã¾ã™ã€‚

 initialize_chain
def initialize_chain() -> RunnableSequence:
    """Langchainã®åˆæœŸåŒ–."""
    prompt = hub.pull("rlm/rag-prompt")
    llm = ChatOpenAI()
    retriever = initialize_retriever()
    chain = (
        {"context": retriever, "question": RunnablePassthrough()} | prompt | llm
    )
    return chain
ã“ã¡ã‚‰ã§ã¯ retriever ã®æƒ…å ±ã‚’ LLM ã§åˆ©ç”¨ã§ãã‚‹ã‚ˆã†ã« chain ã¨å‘¼ã°ã‚Œã‚‹æ¦‚å¿µã‚’åˆ©ç”¨ã—ã¦ãŠã‚Šã¾ã™ã€‚
ã‚ˆããƒ¡ã‚½ãƒƒãƒ‰ãƒã‚§ãƒ¼ãƒ³ã¨ã„ã†è¨€è‘‰ãŒãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°è¨€èªã§ã¯ä½¿ã‚ã‚Œã¦ã„ã¾ã™ã€‚
ä¾‹ãˆã° Python ã® Pandas ã§ã¯
import pandas as pd

# ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
data = {
    'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Edward', 'Frank'],
    'Age': [24, 27, 22, 32, 29, 24],
    'City': ['New York', 'Los Angeles', 'New York', 'Chicago', 'Los Angeles', 'New York'],
    'Score': [85, 90, 88, 92, 95, 70]
}

df = pd.DataFrame(data)

# ãƒ¡ã‚½ãƒƒãƒ‰ãƒã‚§ãƒ¼ãƒ³ã‚’ä½¿ã£ãŸãƒ‡ãƒ¼ã‚¿å¤‰æ›
result = (df
          .query('Age > 25')                     # å¹´é½¢ãŒ25ä»¥ä¸Šã®è¡Œã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
          .groupby('City')                       # éƒ½å¸‚ã”ã¨ã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
          .agg({'Score': 'mean'})                # ã‚¹ã‚³ã‚¢ã®å¹³å‡ã‚’è¨ˆç®—
          .rename(columns={'Score': 'Average Score'})  # åˆ—åã‚’å¤‰æ›´
          .sort_values(by='Average Score', ascending=False)  # å¹³å‡ã‚¹ã‚³ã‚¢ã§ä¸¦ã¹æ›¿ãˆ
          .reset_index()                         # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ãƒªã‚»ãƒƒãƒˆ
         )

print(result)
ã¨ã„ã†ã‚ˆã†ã«ãƒ¡ã‚½ãƒƒãƒ‰ã®è¿”ã‚Šå€¤ã‚’æ¬¡ã®ãƒ¡ã‚½ãƒƒãƒ‰ã¸ã¨ãƒã‚±ãƒ„ãƒªãƒ¬ãƒ¼ã®ã‚ˆã†ã«ã¤ãªã„ã§è¡Œãå‡¦ç†ã•ã›ã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚ã“ã‚Œã‚’ãƒ¡ã‚½ãƒƒãƒ‰ãƒã‚§ãƒ¼ãƒ³ã¨ã„ã„ã¾ã™ã€‚
LangChain ã§ã‚‚ã“ã®ãƒã‚±ãƒ„ãƒªãƒ¬ãƒ¼ã‚’è¡Œã„ã€ã©ã®ã‚ˆã†ã«ãƒ¦ãƒ¼ã‚¶ã®è³ªå•ã«ç­”ãˆã‚‹ã‹ã®ãƒ«ãƒ¼ãƒ«ã‚’æ±ºã‚ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚
LangChain ã®å ´åˆã¯æ˜”ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã§ã¯é–¢æ•°ã®è¿”ã‚Šå€¤ã‚’ã•ã‚‰ã«é–¢æ•°ã®å¼•æ•°ã«ã™ã‚‹ã¨è¨€ã†ã“ã¨ã‚’ç¹°ã‚Šè¿”ã—ã¦ãƒã‚±ãƒ„ãƒªãƒ¬ãƒ¼ã‚’è¡Œã£ã¦ã„ã¾ã—ãŸãŒã€ä»Šã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ 0.2.5 ã§ã¯ä»¥ä¸‹ã®ã‚ˆã†ã« | ã‚’åˆ©ç”¨ã—ãƒã‚§ãƒ¼ãƒ³ã‚’ç¤ºã™ã“ã¨ãŒæ¨å¥¨ã•ã‚Œã¦ã„ã¾ã™ã€‚
    chain = (
        {"context": retriever, "question": RunnablePassthrough()} | prompt | llm
    )
ä»Šå›ã®å ´åˆ

{"context": retriever, "question": RunnablePassthrough()}
prompt
llm

ã¨ã„ã†é †ç•ªã§ãƒã‚§ãƒ¼ãƒ³ãŒã¤ãªãŒã£ã¦ã„ã¾ã™ã€‚
ãƒã‚§ãƒ¼ãƒ³ã®å…ˆé ­ãŒãªãœè¾æ›¸ã§ã‚ã‚‹ã‹ã¯ã€2ç•ªç›®ã® prompt ã®èª¬æ˜ã‚’èã„ã¦ã‚‚ã‚‰ãˆã‚Œã°ã‚ã‹ã‚‹ã¨æ€ã„ã¾ã™ã€‚
    prompt = hub.pull("rlm/rag-prompt")
prompt ã¯ LLM ã«ã©ã®ã‚ˆã†ãªè³ªå•ã‚„ä¾é ¼ã‚’ã™ã‚‹ã®ã‹ã‚’æ±ºã‚ã‚‹éƒ¨åˆ†ã§ã™ã€‚ä»Šå›ã¯ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ(å¤‰æ•°åã‚’æŒ‡ã—ã¦ã„ãªã„å ´åˆã‚«ã‚¿ã‚«ãƒŠè¡¨è¨˜ã¨ã—ã¾ã™)ã‚’æœ‰å¿—ã®æ–¹ãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ä»–ã®äººãŒåˆ©ç”¨ã§ãã‚‹ã‚ˆã†ã«ã—ã¦ãã‚Œã¦ã„ã‚‹ã‚µã‚¤ãƒˆ LangChain Hub ã‹ã‚‰ â­ ãŒå¤šã„ã‚‚ã®ã‚’ãŠå€Ÿã‚Šã—ã¦ãã¾ã—ãŸã€‚ã‚‚ã¡ã‚ã‚“è‡ªä½œã—ã¦ã‚‚ã‚‰ã£ã¦ã‚‚OKã§ã™ã€‚
https://smith.langchain.com/hub/rlm/rag-prompt
ãŠå€Ÿã‚Šã—ãŸ rag-prompt ã§ã¯ä»¥ä¸‹ã®ã‚ˆã†ã«ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒå®šç¾©ã•ã‚Œã¦ã„ã¾ã™ã€‚
You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.
Question: {question} 
Context: {context} 
Answer:
ç°¡å˜ã«æ—¥æœ¬èªã«è¨³ã™ã¨ ã€Œ context ã®æƒ…å ±ã®ã¿ã‚’ä½¿ã£ã¦ question ã«ç­”ãˆã‚‹ã‚ˆã†ã« Answer ã‚’è€ƒãˆãªã•ã„ã€‚ç­”ãˆã‚‰ã‚Œãªã„ãªã‚‰ã‚ã‹ã‚‰ãªã„ã¨ç­”ãˆãªã•ã„ã€‚ã€ ã¨ãªã‚Šã¾ã™ã€‚ context ã®æƒ…å ±ã®ã¿ã‚’ç”¨ã„ã‚‹ã‚ˆã†æŒ‡å®šã™ã‚‹ã“ã¨ã§ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³ã‚’é˜²ãåŠ¹æœãŒã‚ã‚Šã¾ã™ (ãŸã ã—ï¼‘ï¼ï¼ï¼…é˜²ãã¨ã¯æ–­è¨€ã§ããªã„ã§ã™)
ã“ã¡ã‚‰ã® question éƒ¨åˆ†ã«ãƒ¦ãƒ¼ã‚¶ã®ã‚¯ã‚¨ãƒªãŒã€ context éƒ¨åˆ†ã« retriever ã‚’æŒ‡å®šã—ã¦ prompt ã‚’å®Ÿè¡Œã›ã‚ˆã¨ã—ã¦ã„ã‚‹ã®ãŒãƒã‚§ãƒ¼ãƒ³ã® {"context": retriever, "question": RunnablePassthrough()} | prompt ã®éƒ¨åˆ†ã§ã™ã€‚
æœ€å¾Œã«å®Œæˆã—ãŸ prompt ã‚’ llm ã«æ¸¡ã—ãªã•ã„ã¨æŒ‡å®šã—ã¦ã„ã‚‹ã®ãŒ prompt | llm ã®éƒ¨åˆ†ã§ã™ã€‚
ã“ã®ãƒ¡ã‚½ãƒƒãƒ‰ãƒã‚§ãƒ¼ãƒ³ã‚’ã¾ã¨ã‚ãŸ chain ã¨ã„ã†å¤‰æ•°ã¯ invoke ãƒ¡ã‚½ãƒƒãƒ‰ã‚’æŒã£ã¦ãŠã‚Šã€ã“ã®ãƒ¡ã‚½ãƒƒãƒ‰ã«è³ªå•ã‚’æŠ•ã’ã‚‹ã¨ãã‚ŒãŒ question ã«å…¥ã‚Šãƒã‚§ãƒ¼ãƒ³ãŒå‰ã‹ã‚‰é †ç•ªã«å®Ÿè¡Œã•ã‚Œã¾ã™ã€‚
ä»¥ä¸Šã®ã‚ˆã†ã«å®šç¾©ã™ã‚‹ã“ã¨ã§ RAG ã¨ã—ã¦å¤–éƒ¨ã®æƒ…å ±ã‚’å‚ç…§ã—ã¤ã¤å›ç­”ã™ã‚‹ ChatBot ã‚’å®Ÿè£…ã§ãã¾ã—ãŸã€‚

 main
def main() -> None:
    """ChatGPTã‚’ä½¿ã£ãŸãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã®ãƒ¡ã‚¤ãƒ³é–¢æ•°."""
    chain = initialize_chain()

    # ãƒšãƒ¼ã‚¸ã®è¨­å®š
    st.set_page_config(page_title="RAG ChatGPT")
    st.image(img, use_column_width=False)
    st.header("RAG ChatGPT")

    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®åˆæœŸåŒ–
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ã‚’ç›£è¦–
    if user_input := st.chat_input("èããŸã„ã“ã¨ã‚’å…¥åŠ›ã—ã¦ã­ï¼"):
        st.session_state.messages.append(HumanMessage(content=user_input))
        with st.spinner("GPT is typing ..."):
            response = chain.invoke(user_input)
        st.session_state.messages.append(AIMessage(content=response.content))

    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®è¡¨ç¤º
    messages = st.session_state.get("messages", [])
    for message in messages:
        if isinstance(message, AIMessage):
            with st.chat_message("assistant"):
                st.markdown(message.content)
        elif isinstance(message, HumanMessage):
            with st.chat_message("user"):
                st.markdown(message.content)
        else:
            st.write(f"System message: {message.content}")
æœ€å¾Œã« main é–¢æ•°ã§ã™ã€‚ã“ã¡ã‚‰ã¯ LangChain ã®å®Ÿè£…ã¨ã„ã†ã‚ˆã‚Šã¯ Streamlit ã‚’åˆ©ç”¨ã—ãŸãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰éƒ¨åˆ†ã®å®Ÿè£…ã«ãªã‚Šã¾ã™ã€‚
ã‚­ãƒ¼ã¨ãªã‚‹ç‚¹ã ã‘è§£èª¬ã™ã‚‹ã¨

ãƒ¦ãƒ¼ã‚¶ã¨ ChatBot ã®ä¼šè©±ã¯ messages ã«ä¿å­˜ã•ã‚Œã¦ã„ã¾ã™ã€‚ä»¥ä¸‹ã®ã‚³ãƒ¼ãƒ‰ã‚’è¦‹ã‚‹ã¨ã‚ã‹ã‚‹ã‚ˆã†ã«ãƒ¦ãƒ¼ã‚¶ã‹ã‚‰ã®è³ªå•ã¨ ChatBot ã®è¿”ç­”ã¯ã©ã¡ã‚‰ã‚‚ messages ã« append ã•ã‚Œã¦ã„ã¾ã™ã€‚

    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®åˆæœŸåŒ–
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ã‚’ç›£è¦–
    if user_input := st.chat_input("èããŸã„ã“ã¨ã‚’å…¥åŠ›ã—ã¦ã­ï¼"):
        st.session_state.messages.append(HumanMessage(content=user_input))
        with st.spinner("GPT is typing ..."):
            response = chain.invoke(user_input)
        st.session_state.messages.append(AIMessage(content=response.content))

ãƒ¦ãƒ¼ã‚¶ã‹ã‚‰ã®è³ªå•ã¸ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã¯å…ˆã»ã©å®šç¾©ã—ãŸ chain ã® invoke ãƒ¡ã‚½ãƒƒãƒ‰ã‚’ç”¨ã„ã¦ä½œã‚‰ã‚Œã¦ã„ã¾ã™ã€‚

        with st.spinner("GPT is typing ..."):
            response = chain.invoke(user_input)
        st.session_state.messages.append(AIMessage(content=response.content))
ã¨ã„ã†ç‚¹ãŒã‚ã’ã‚‰ã‚Œã¾ã™ã€‚

 ãƒ†ã‚¹ãƒˆ
ãã‚Œã§ã¯å®Ÿè£…ã—ãŸã‚‚ã®ã‚’å‹•ã‹ã—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚
> streamlit run chatbot.py

Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.


  You can now view your Streamlit app in your browser.

  Local URL: http://localhost:8501
  Network URL: http://10.200.0.4:8501
  External URL: http://13.73.233.61:8501
http://localhost:8501 ã¸ãƒ–ãƒ©ã‚¦ã‚¶ã‹ã‚‰ã‚¢ã‚¯ã‚»ã‚¹ã—ã€è³ªå•ã—ã¦ã¿ã¾ã™ã€‚

ç¾æ™‚ç‚¹ã§ã® note.txt ã®å…ˆé ­ã®æ–¹ã«æ›¸ã„ã¦ã‚ã£ãŸæ–°ã—ã„ãƒ“ã‚¸ãƒ§ãƒ³ã‚’ã¡ã‚ƒã‚“ã¨ç­”ãˆã¦ã„ã¾ã™ã€‚ã“ã®æƒ…å ±ã¯ OpenAI ã«ã¯ãªã„ãŸã‚ãã¡ã‚“ã¨ RAG ãŒåƒã„ã¦ã„ã‚‹ã¨è¨€ãˆãã†ã§ã™ã€‚

ã¾ãŸã€Œ100å¹´å¾Œã«ç™ºå£²äºˆå®šã®æ–°å•†å“ã€ã¨ã„ã†æƒ…å ±ã¨ã—ã¦å«ã¾ãªã„ã‚ˆã†ãªè³ªå•ã‚’ã™ã‚‹ã¨ã¡ã‚ƒã‚“ã¨ã€Œæƒ…å ±ã‚’æŒã£ã¦ã„ãªã„ã€ã¨è¿”ç­”ã—ã¦ãã‚Œã¾ã™ã€‚ã“ã¡ã‚‰ã‚‚æœŸå¾…é€šã‚Šã§ã™ã­ã€‚

 ğŸ’¡ ã¾ã¨ã‚

LangChain v0.2.5 æ™‚ç‚¹ã§ã® RAG ã‚’ç”¨ã„ãŸ ChatBot ã®å®Ÿè£…ã‚’è¡Œã„ã¾ã—ãŸ
Streamlit ã‚’ç”¨ã„ã¦ãƒ–ãƒ©ã‚¦ã‚¶ã‹ã‚‰ãƒ¦ãƒ¼ã‚¶ãŒã‚¢ã‚¯ã‚»ã‚¹ã§ãã‚‹ã‚ˆã†ã«ã—ã¾ã—ãŸ

ãœã²å‚è€ƒã«ã—ã¦ã¿ã¦ãã ã•ã„ã€‚
yamasaKitcheminformatics, machine learning, board gameCykinso's Tech BlogPublicationã€Œç´°èŒå¢ã®åŠ›ã§äººã€…ã‚’å¥åº·ã«ã€ã‚’ãƒŸãƒƒã‚·ãƒ§ãƒ³ã«æ²ã’ã‚‹ãƒã‚¤ã‚ªãƒ†ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆã‚¢ãƒƒãƒ—ã€Œã‚µã‚¤ã‚­ãƒ³ã‚½ãƒ¼ã€ã®æŠ€è¡“ãƒ–ãƒ­ã‚°ã€‚ ãƒãƒƒã‚¸ã‚’è´ˆã£ã¦è‘—è€…ã‚’å¿œæ´ã—ã‚ˆã†ãƒãƒƒã‚¸ã‚’å—ã‘å–ã£ãŸè‘—è€…ã«ã¯Zennã‹ã‚‰ç¾é‡‘ã‚„Amazonã‚®ãƒ•ãƒˆã‚«ãƒ¼ãƒ‰ãŒé‚„å…ƒã•ã‚Œã¾ã™ã€‚ãƒãƒƒã‚¸ã‚’è´ˆã‚‹DiscussionyamasaKitcheminformatics, machine learning, board gameãƒãƒƒã‚¸ã‚’è´ˆã‚‹ãƒãƒƒã‚¸ã‚’è´ˆã‚‹ã¨ã¯ç›®æ¬¡èƒŒæ™¯ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ãªã©æ–¹æ³•.envãƒ‡ãƒ¼ã‚¿ã‚³ãƒ¼ãƒ‰initialize_vector_storeinitialize_retriverinitialize_chainmainãƒ†ã‚¹ãƒˆğŸ’¡ ã¾ã¨ã‚
divchatbotOpenAILangChainLLMRAGtech
 èƒŒæ™¯
LangChain ã¯ OpenAI API ã‚’åˆ©ç”¨ã—è‡ªåˆ†ãŸã¡ãŒã‚„ã‚ŠãŸã„ã“ã¨ã‚’å®Ÿç¾ã™ã‚‹ã“ã¨ã«éå¸¸ã«ä¾¿åˆ©ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã§ã™ãŒãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚¢ãƒƒãƒ—ã«ã‚ˆã£ã¦ã‚¯ãƒ©ã‚¹åã‚„ã‚µãƒ–ãƒ©ã‚¤ãƒ–ãƒ©ãƒªåã®å¤‰æ›´ãŒã‚„ã‚„å¤šãå°‘ã—å¤ã„ Web è¨˜äº‹ã‚’å‚è€ƒã«ã—ã¦ã‚‚ã†ã¾ããƒ¯ãƒ¼ã‚¯ã—ãªã„ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚
ã“ã®è¨˜äº‹ã¯ 2024/6/20 ç¾åœ¨ã® LangChain (ãƒãƒ¼ã‚¸ãƒ§ãƒ³ 0.2.5) ã§ OpenAI API ã‚„ Azure OpenAI API ã‚’å‹•ã‹ã™ä¾‹ã¨ã—ã¦æ®‹ã—ã¦ãŠãã¾ã™ã€‚
åŒã˜ã‚ˆã†ãªã“ã¨ã‚’ã—ã‚ˆã†ã¨ã—ã¦ç§ã®ã‚ˆã†ã«è‹¦æˆ¦ã—ã¦ã„ã‚‹æ–¹ã®åŠ©ã‘ã«ãªã‚Œã°å¹¸ã„ã§ã™ã€‚

 ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ãªã©

pyproject.toml
python = ">=3.12,<3.13"
python-dotenv = "^1.0.1"
chromadb = "0.5.2"
langchain = "0.2.5"
langchain-cli = "0.0.25"
langchain-openai = "0.1.8"
langchain-community = "0.2.5"
langchain-chroma = "0.1.1"
langchainhub = "0.1.20"
streamlit = "1.35.0"

ğŸ’¡ Poetry ã§ Python ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’æŒ‡å®šã™ã‚‹æ™‚ã« ^3.12 ã¨ã™ã‚‹ã¨ lancghain-chroma ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã§ããªããªã‚‹ã®ã§ >=3.12,<3.13 ã¨ã—ã¾ã—ãŸã€‚
(langchain-chroma ã¯ >=3.12,<3.13 ã¨ã„ã†æŒ‡å®šãŒã‚ã‚Šã¾ã™)

 æ–¹æ³•
OpenAI API ã‚’ä½¿ã†å ´åˆã¨ AzureOpenAI API ã‚’ä½¿ã†å ´åˆã¯åŸºæœ¬åŒã˜ã“ã¨ã‚’ã™ã‚‹ã®ã§ã¾ãš OpenAI API ã‚’ä½¿ã†å ´åˆã‚’èª¬æ˜ã—ã€è¨˜äº‹ãŒé•·ããªã£ã¦ã—ã¾ã£ãŸã®ã§ã€å¾Œæ—¥åˆ¥è¨˜äº‹ã«ã¦ AzureOpenAI API ã‚’ä½¿ã†å ´åˆã¯ã©ã®éƒ¨åˆ†ã‚’ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆã—ãŸã‚‰ã‚ˆã„ã®ã‹ã‚’èª¬æ˜ã—ãŸã„ã¨æ€ã„ã¾ã™ã€‚
6/28 è¿½è¨˜) AzureOpenAI API ç‰ˆã®è¨˜äº‹ã‚‚æ›¸ãã¾ã—ãŸã®ã§ã‚ˆã‘ã‚Œã°ãœã²ã©ã†ã
https://zenn.dev/cykinso/articles/b055e33734d06b

 .env
ä»¥ä¸‹ã®ã‚ˆã†ã« .env ã‚’ç”¨æ„ã—ã¾ã™ã€‚
OPENAI_API_KEY=sk-XXXXXXXXXXXXXXXX
OPENAI_API_VERSION=2024-02-01
ã‚‚ã— OPENAI_API_KEY ã‚’ã¾ã å–å¾—ã—ã¦ã„ãªã„å ´åˆã¯ä»¥ä¸‹ã®æ–¹æ³•ã§å–å¾—ã—ã¦ãã ã•ã„ã€‚

 OPENAI_API_KEY
OPENAI_API_KEY ã¯ OpenAI ã® Dashboard ã§ä½œæˆã§ãã¾ã™ã€‚
(èª²é‡‘å¯¾è±¡ãªã®ã§ã”è‡ªèº«ã®è²¬ä»»ã®ã‚‚ã¨ã”åˆ©ç”¨ãã ã•ã„)

ã€Œ+ Create new secret keyã€ ã‚’æŠ¼ã™ã¨ãƒ¢ãƒ¼ãƒ€ãƒ«ãŒé–‹ãã®ã§å¾Œã‹ã‚‰åŒºåˆ¥ã§ãã‚‹ã‚ˆã†ãªåå‰ã‚’ã¤ã‘ã¦ ã€ŒCreate secret keyã€ ã‚’æŠ¼ã—ã¾ã™ã€‚

è¡¨ç¤ºã•ã‚Œã‚‹ API ã‚­ãƒ¼ã‚’ .env ã«ãƒ¡ãƒ¢ã—ã¦ãŠãã¾ã™ã€‚ ã€ŒDoneã€ ã‚’æŠ¼ã™ã¨ã‚‚ã†è¡¨ç¤ºã§ãã¾ã›ã‚“ã€‚


 ãƒ‡ãƒ¼ã‚¿
OpenAI ãŒã¾ã å­¦ç¿’ã—ã¦ã„ãªã•ãã†ãªãƒ‡ãƒ¼ã‚¿ã®ä¾‹ã¨ã—ã¦å¼Šç¤¾ Cykinso ã®ãƒ–ãƒ­ã‚°è¨˜äº‹ã®ã€Œä¼šç¤¾ã®ãƒ“ã‚¸ãƒ§ãƒ³ã‚’è©±ã—ã¦ã„ã‚‹ãƒšãƒ¼ã‚¸ã€ã‚’ä»Šå›ã¯ç”¨ã„ãŸã„ã¨æ€ã„ã¾ã™ã€‚
https://note.com/cykinso/n/n432d5ea70783
ğŸ’¡ ãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆã§å®Ÿè£…ã™ã‚‹å ´åˆã¯ã€å¥½ããªãƒãƒ³ã‚¬ãªã©ã®è©³ç´°ã‚’ãƒ†ã‚­ã‚¹ãƒˆã«ã¾ã¨ã‚ã¦ãƒ‡ãƒ¼ã‚¿ã¨ã™ã‚‹ã¨ãƒ¢ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³ã‚‚ä¸ŠãŒã‚‹ã¨æ€ã„ã¾ã™ã€‚
ã–ã£ã¨æ–‡ç« ã‚’ã‚³ãƒ”ãƒ¼ã—ã¦ä»¥ä¸‹ã®ã‚ˆã†ã«æ•´å½¢ã—ã¾ã—ãŸã€‚

note.txt
ç´°èŒå¢ã‹ã‚‰ã®æ–°ãŸãªæ°—ä»˜ãã‚’é€šã˜ã¦ã€æ–°ãƒ“ã‚¸ãƒ§ãƒ³ã‚’ç­–å®šã—ã¾ã—ãŸï¼
2023å¹´11æœˆã«ã‚µã‚¤ã‚­ãƒ³ã‚½ãƒ¼ã¯10æœŸç›®ã«å…¥ã‚Šã¾ã—ãŸã€‚é«˜é½¢åŒ–ç¤¾ä¼šã«ã‚ˆã‚‹ç¤¾ä¼šä¿éšœã¸ã®ä¸å®‰ãŒå‹Ÿã‚‹ç¾åœ¨ã€ç—…æ°—ã‚’æœªç„¶ã«é˜²ã0æ¬¡äºˆé˜²ã®é‡è¦æ€§ãŒé«˜ã¾ã£ã¦ã„ã¾ã™ã€‚ã€Œç´°èŒå¢ã§äººã€…ã‚’å¥åº·ã«ã€ã¨ã„ã†ãƒŸãƒƒã‚·ãƒ§ãƒ³ã«å‘ã‘ã¦ã€ã‚µã‚¤ã‚­ãƒ³ã‚½ãƒ¼ã¯æ–°ãŸãªãƒ“ã‚¸ãƒ§ãƒ³ã‚’åˆ¶å®šã—ã¾ã—ãŸã€‚
æ–°ã—ã„ãƒ“ã‚¸ãƒ§ãƒ³ã«ã¤ã„ã¦
ãƒ¼ãƒ“ã‚¸ãƒ§ãƒ³å¤‰æ›´ã§å…·ä½“çš„ã«ã©ã®å€‹æ‰€ãŒå¤‰æ›´ã—ãŸã‹ã‚’ã¾ãšã”ç´¹ä»‹ã—ã¾ã™ã€‚
ã“ã¡ã‚‰ãŒã‚µã‚¤ã‚­ãƒ³ã‚½ãƒ¼ã®ãƒŸãƒƒã‚·ãƒ§ãƒ³ï¼ˆMISSIONï¼‰ã€ãƒ“ã‚¸ãƒ§ãƒ³(VISION)ã€ãƒãƒªãƒ¥ãƒ¼(VALUE)ã«ãªã‚Šã¾ã™ã€‚
ç§ãŸã¡ãŒç›®æŒ‡ã—ç¶šã‘ã‚‹ã€Œç´°èŒå¢ã§äººã€…ã‚’å¥åº·ã«ã€ã¨ã„ã†ãƒŸãƒƒã‚·ãƒ§ãƒ³ã¯ãã®ã¾ã¾ã«ã€ãƒ“ã‚¸ãƒ§ãƒ³ã‚’æ–°ã—ãå¤‰æ›´è‡´ã—ã¾ã—ãŸã€‚

ï¼œã“ã‚Œã¾ã§ã®ãƒ“ã‚¸ãƒ§ãƒ³ï¼
èŒå¢ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã€Œæ¬¡ä¸–ä»£ã®ãƒ©ã‚¤ãƒ•ã‚¹ã‚¿ã‚¤ãƒ«ã€ã‚’æä¾›ã™ã‚‹ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã«ãªã‚‹

ï¼œæ–°ã—ã„ãƒ“ã‚¸ãƒ§ãƒ³ï¼
ç´°èŒå¢ã‹ã‚‰ã®æ–°ãŸãªæ°—ä»˜ãã‚’é€šã˜ã¦
ãƒ’ãƒˆã€ç¤¾ä¼šã€åœ°çƒç’°å¢ƒã‚’å¥åº·ã«ã™ã‚‹ã‚¨ã‚³ã‚·ã‚¹ãƒ†ãƒ ã‚’å®Ÿç¾ã™ã‚‹
æ–°ã—ã„ãƒ“ã‚¸ãƒ§ãƒ³ã§ã¯ã€ã‚µã‚¤ã‚­ãƒ³ã‚½ãƒ¼ãŒå½±éŸ¿ã‚’ä¸ãˆã¦ã„ããŸã„ç¯„å›²ã‚‚ã“ã‚Œã¾ã§ã‚ˆã‚Šã•ã‚‰ã«å¤§ãããªã£ãŸã“ã¨ãŒåˆ†ã‹ã‚Šã¾ã™ã€‚

ä»Šå›ã®ãƒ“ã‚¸ãƒ§ãƒ³å¤‰æ›´ã‚’é€šã—ã¦ã€ã‚µã‚¤ã‚­ãƒ³ã‚½ãƒ¼ãŒã©ã‚“ãªä¾¡å€¤ç™ºæ®ã‚’ç›®æŒ‡ã—ã¦ã„ãã®ã‹ã€ãã‚Œã«ä¼´ã„äº‹æ¥­é¢ã§ã¯ã©ã‚“ãªæŒ‘æˆ¦ã‚’ã—ã¦ã„ãã®ã‹ã‚’ã€ä»£è¡¨å–ç· å½¹CEOã®æ²¢äº•ã•ã‚“ã«èã„ã¦ãã¾ã—ãŸï¼

...(ä»¥ä¸‹ç•¥)


 ã‚³ãƒ¼ãƒ‰
ç¶šã‘ã¦ã‚³ãƒ¼ãƒ‰ã‚’å®Ÿè£…ã—ã¾ã™ã€‚
ä»Šå›ã¯ RAG ã¨ã—ã¦å¤–éƒ¨ã®æƒ…å ±ã‚’å‚ç…§ã—ã¤ã¤å›ç­”ã™ã‚‹ ChatBot ã‚’å®Ÿè£…ã—ã¦ã¿ã¾ã™ã€‚
ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã¨ã—ã¦ streamlit ã‚’ç”¨ã„ã¾ã™ã€‚
å…ˆã«ã‚³ãƒ¼ãƒ‰å…¨ä½“ã‚’ç¤ºã™ã¨ä»¥ä¸‹ã®ã‚ˆã†ã«ãªã‚Šã¾ã™ã€‚
(streamlit ã®ã‚³ãƒ¼ãƒ‰ã®ãƒ™ãƒ¼ã‚¹ã¨ã—ã¦ä»¥ä¸‹ã®è¨˜äº‹ã‚’å‚è€ƒã«ã•ã›ã¦ã„ãŸã ãã¾ã—ãŸã€‚ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™)
https://tech-lab.sios.jp/archives/41574

chatbot.py
from pathlib import Path

import streamlit as st
from dotenv import load_dotenv
from langchain import hub
from langchain.schema import AIMessage, HumanMessage
from langchain_chroma import Chroma
from langchain_community.document_loaders import TextLoader
from langchain_core.runnables import RunnablePassthrough, RunnableSequence
from langchain_core.vectorstores import VectorStoreRetriever
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_text_splitters import RecursiveCharacterTextSplitter

load_dotenv()


def initialize_vector_store() -> Chroma:
    """VectorStoreã®åˆæœŸåŒ–."""
    embeddings = OpenAIEmbeddings()

    vector_store_path = "./resources/note.db"
    if Path(vector_store_path).exists():
        vector_store = Chroma(embedding_function=embeddings, persist_directory=vector_store_path)
    else:
        loader = TextLoader("resources/note.txt")
        docs = loader.load()

        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
        splits = text_splitter.split_documents(docs)

        vector_store = Chroma.from_documents(
            documents=splits, embedding=embeddings, persist_directory=vector_store_path
        )

    return vector_store


def initialize_retriever() -> VectorStoreRetriever:
    """Retrieverã®åˆæœŸåŒ–."""
    vector_store = initialize_vector_store()
    return vector_store.as_retriever()


def initialize_chain() -> RunnableSequence:
    """Langchainã®åˆæœŸåŒ–."""
    prompt = hub.pull("rlm/rag-prompt")
    llm = ChatOpenAI()
    retriever = initialize_retriever()
    chain = (
        {"context": retriever, "question": RunnablePassthrough()} | prompt | llm
    )
    return chain


def main() -> None:
    """ChatGPTã‚’ä½¿ã£ãŸãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã®ãƒ¡ã‚¤ãƒ³é–¢æ•°."""
    chain = initialize_chain()

    # ãƒšãƒ¼ã‚¸ã®è¨­å®š
    st.set_page_config(page_title="RAG ChatGPT")
    st.header("RAG ChatGPT")

    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®åˆæœŸåŒ–
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ã‚’ç›£è¦–
    if user_input := st.chat_input("èããŸã„ã“ã¨ã‚’å…¥åŠ›ã—ã¦ã­ï¼"):
        st.session_state.messages.append(HumanMessage(content=user_input))
        with st.spinner("GPT is typing ..."):
            response = chain.invoke(user_input)
        st.session_state.messages.append(AIMessage(content=response.content))

    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®è¡¨ç¤º
    messages = st.session_state.get("messages", [])
    for message in messages:
        if isinstance(message, AIMessage):
            with st.chat_message("assistant"):
                st.markdown(message.content)
        elif isinstance(message, HumanMessage):
            with st.chat_message("user"):
                st.markdown(message.content)
        else:
            st.write(f"System message: {message.content}")


if __name__ == "__main__":
    main()

ã‚³ãƒ¼ãƒ‰ã®å„éƒ¨åˆ†ã‚’èª¬æ˜ã—ã¦ã„ãã¾ã™ã€‚

 initialize_vector_store
def initialize_vector_store() -> Chroma:
    """VectorStoreã®åˆæœŸåŒ–."""
    embeddings = OpenAIEmbeddings()

    vector_store_path = "./resources/note.db"
    if Path(vector_store_path).exists():
        vector_store = Chroma(embedding_function=embeddings, persist_directory=vector_store_path)
    else:
        loader = TextLoader("resources/note.txt")
        docs = loader.load()

        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
        splits = text_splitter.split_documents(docs)

        vector_store = Chroma.from_documents(
            documents=splits, embedding=embeddings, persist_directory=vector_store_path
        )

    return vector_store
Vector store ã¨ã¯æƒ…å ±ã¨ã—ã¦èª­ã¿è¾¼ã¾ã›ã¦ã„ã‚‹ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’é©åˆ‡ãªé•·ã•ã«åˆ†å‰²ã—(ãƒãƒ£ãƒ³ã‚¯ã¨å‘¼ã°ã‚Œã¾ã™) ã™ãã«å–ã‚Šå‡ºã›ã‚‹ã‚ˆã†ã«ä¿å­˜ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ã‚ˆã†ãªã‚‚ã®ã§ã™ã€‚
Embeddings ã¨å‘¼ã°ã‚Œã‚‹ãƒ¢ãƒ‡ãƒ«ã§ãƒ†ã‚­ã‚¹ãƒˆã¯æ•°å€¤æƒ…å ±ã®ãƒ™ã‚¯ãƒˆãƒ«ã«ä¿å­˜ã•ã‚Œã¾ã™ã€‚ãã®ä½œæ¥­ã‚’è¡Œã†ãŸã‚ã« OpenAI API ãŒå¿…è¦ã«ãªã£ã¦ã„ã‚‹ãŸã‚é–¢æ•°ã®æœ€åˆã§ OpenAIEmbeddings ã‚’å‘¼ã³å‡ºã—ã¦ã„ã¾ã™ã€‚
ç¶šã‘ã¦ Vector store ã¨ã—ã¦ä¿å­˜ã•ã‚Œã¦ã„ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã™ã§ã«å­˜åœ¨ã—ã¦ã„ãªã„ã‹ã‚’èª¿ã¹ã¦ã„ã¾ã™ã€‚åŸºæœ¬çš„ã«ãƒ‡ãƒ¼ã‚¿ã‚„ãƒ¢ãƒ‡ãƒ«ãŒã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆã•ã‚Œãªã„é™ã‚Š Vector store ã®ãƒ‡ãƒ¼ã‚¿ã¯ã¾ã£ãŸãåŒã˜ã«ãªã‚‹ãŸã‚ã€æ¯å›å®Ÿè¡Œã—ã¦ã—ã¾ã†ã¨æ™‚é–“ã‚‚ API ã®åˆ©ç”¨æ–™é‡‘ã‚‚ç„¡é§„ã«ãªã£ã¦ã—ã¾ã„ã¾ã™ã€‚
ãã“ã§

ã¾ã å­˜åœ¨ã—ã¦ã„ãªã„å ´åˆï¼š æ–°è¦ä½œæˆ
ã™ã§ã«å­˜åœ¨ã—ã¦ã„ã‚‹å ´åˆï¼š ä¿å­˜ã—ã¦ã„ã‚‹ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’èª­ã¿è¾¼ã‚€

ã¨ã—ã¦ã„ã¾ã™ã€‚
ãªãŠå­˜åœ¨ã—ã¦ã„ã‚‹å ´åˆ Chroma ã‚¯ãƒ©ã‚¹ã®å¼•æ•° embedding_function ã« embeddings ã‚’æŒ‡å®šã—ã¦ã„ã¾ã™ãŒã€ã“ã‚Œã¯ã‚¯ã‚¨ãƒªã¨ã—ã¦ã‚ãŸãˆã‚‰ã‚Œã‚‹ãƒ¦ãƒ¼ã‚¶ã®è³ªå•ã¨ Vector store ã«ä¿å­˜ã•ã‚Œã¦ã„ã‚‹ãƒ‡ãƒ¼ã‚¿ã¨ã®é–“ã®é–¢é€£æ€§ã‚’èª¿ã¹ã‚‹ãŸã‚ã«ã€ã‚¯ã‚¨ãƒªã‚‚ Embeddings ã§ãƒ™ã‚¯ãƒˆãƒ«ã«å¤‰æ›ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã‹ã‚‰ã§ã™ã€‚

 initialize_retriver
def initialize_retriever() -> VectorStoreRetriever:
    """Retrieverã®åˆæœŸåŒ–."""
    vector_store = initialize_vector_store()
    return vector_store.as_retriever()
ã“ã¡ã‚‰ã§ã¯ã€å…ˆã»ã©ä½œæˆã—ãŸ(ã‚ã‚‹ã„ã¯ã™ã§ã«ã‚ã‚‹ã‚‚ã®ã‚’èª­ã¿è¾¼ã‚“ã ) vector_store ã‚’ retriever ã«å¤‰æ›ã—ã¦ã„ã¾ã™ã€‚ã“ã¡ã‚‰ã® retriever ã“ã®å¾Œã€ Vectore store ã‹ã‚‰æƒ…å ±ã‚’å–ã‚Šå‡ºã™ã®ã«åˆ©ç”¨ã•ã‚Œã¾ã™ã€‚

 initialize_chain
def initialize_chain() -> RunnableSequence:
    """Langchainã®åˆæœŸåŒ–."""
    prompt = hub.pull("rlm/rag-prompt")
    llm = ChatOpenAI()
    retriever = initialize_retriever()
    chain = (
        {"context": retriever, "question": RunnablePassthrough()} | prompt | llm
    )
    return chain
ã“ã¡ã‚‰ã§ã¯ retriever ã®æƒ…å ±ã‚’ LLM ã§åˆ©ç”¨ã§ãã‚‹ã‚ˆã†ã« chain ã¨å‘¼ã°ã‚Œã‚‹æ¦‚å¿µã‚’åˆ©ç”¨ã—ã¦ãŠã‚Šã¾ã™ã€‚
ã‚ˆããƒ¡ã‚½ãƒƒãƒ‰ãƒã‚§ãƒ¼ãƒ³ã¨ã„ã†è¨€è‘‰ãŒãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°è¨€èªã§ã¯ä½¿ã‚ã‚Œã¦ã„ã¾ã™ã€‚
ä¾‹ãˆã° Python ã® Pandas ã§ã¯
import pandas as pd

# ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
data = {
    'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Edward', 'Frank'],
    'Age': [24, 27, 22, 32, 29, 24],
    'City': ['New York', 'Los Angeles', 'New York', 'Chicago', 'Los Angeles', 'New York'],
    'Score': [85, 90, 88, 92, 95, 70]
}

df = pd.DataFrame(data)

# ãƒ¡ã‚½ãƒƒãƒ‰ãƒã‚§ãƒ¼ãƒ³ã‚’ä½¿ã£ãŸãƒ‡ãƒ¼ã‚¿å¤‰æ›
result = (df
          .query('Age > 25')                     # å¹´é½¢ãŒ25ä»¥ä¸Šã®è¡Œã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
          .groupby('City')                       # éƒ½å¸‚ã”ã¨ã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
          .agg({'Score': 'mean'})                # ã‚¹ã‚³ã‚¢ã®å¹³å‡ã‚’è¨ˆç®—
          .rename(columns={'Score': 'Average Score'})  # åˆ—åã‚’å¤‰æ›´
          .sort_values(by='Average Score', ascending=False)  # å¹³å‡ã‚¹ã‚³ã‚¢ã§ä¸¦ã¹æ›¿ãˆ
          .reset_index()                         # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ãƒªã‚»ãƒƒãƒˆ
         )

print(result)
ã¨ã„ã†ã‚ˆã†ã«ãƒ¡ã‚½ãƒƒãƒ‰ã®è¿”ã‚Šå€¤ã‚’æ¬¡ã®ãƒ¡ã‚½ãƒƒãƒ‰ã¸ã¨ãƒã‚±ãƒ„ãƒªãƒ¬ãƒ¼ã®ã‚ˆã†ã«ã¤ãªã„ã§è¡Œãå‡¦ç†ã•ã›ã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚ã“ã‚Œã‚’ãƒ¡ã‚½ãƒƒãƒ‰ãƒã‚§ãƒ¼ãƒ³ã¨ã„ã„ã¾ã™ã€‚
LangChain ã§ã‚‚ã“ã®ãƒã‚±ãƒ„ãƒªãƒ¬ãƒ¼ã‚’è¡Œã„ã€ã©ã®ã‚ˆã†ã«ãƒ¦ãƒ¼ã‚¶ã®è³ªå•ã«ç­”ãˆã‚‹ã‹ã®ãƒ«ãƒ¼ãƒ«ã‚’æ±ºã‚ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚
LangChain ã®å ´åˆã¯æ˜”ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã§ã¯é–¢æ•°ã®è¿”ã‚Šå€¤ã‚’ã•ã‚‰ã«é–¢æ•°ã®å¼•æ•°ã«ã™ã‚‹ã¨è¨€ã†ã“ã¨ã‚’ç¹°ã‚Šè¿”ã—ã¦ãƒã‚±ãƒ„ãƒªãƒ¬ãƒ¼ã‚’è¡Œã£ã¦ã„ã¾ã—ãŸãŒã€ä»Šã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ 0.2.5 ã§ã¯ä»¥ä¸‹ã®ã‚ˆã†ã« | ã‚’åˆ©ç”¨ã—ãƒã‚§ãƒ¼ãƒ³ã‚’ç¤ºã™ã“ã¨ãŒæ¨å¥¨ã•ã‚Œã¦ã„ã¾ã™ã€‚
    chain = (
        {"context": retriever, "question": RunnablePassthrough()} | prompt | llm
    )
ä»Šå›ã®å ´åˆ

{"context": retriever, "question": RunnablePassthrough()}
prompt
llm

ã¨ã„ã†é †ç•ªã§ãƒã‚§ãƒ¼ãƒ³ãŒã¤ãªãŒã£ã¦ã„ã¾ã™ã€‚
ãƒã‚§ãƒ¼ãƒ³ã®å…ˆé ­ãŒãªãœè¾æ›¸ã§ã‚ã‚‹ã‹ã¯ã€2ç•ªç›®ã® prompt ã®èª¬æ˜ã‚’èã„ã¦ã‚‚ã‚‰ãˆã‚Œã°ã‚ã‹ã‚‹ã¨æ€ã„ã¾ã™ã€‚
    prompt = hub.pull("rlm/rag-prompt")
prompt ã¯ LLM ã«ã©ã®ã‚ˆã†ãªè³ªå•ã‚„ä¾é ¼ã‚’ã™ã‚‹ã®ã‹ã‚’æ±ºã‚ã‚‹éƒ¨åˆ†ã§ã™ã€‚ä»Šå›ã¯ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ(å¤‰æ•°åã‚’æŒ‡ã—ã¦ã„ãªã„å ´åˆã‚«ã‚¿ã‚«ãƒŠè¡¨è¨˜ã¨ã—ã¾ã™)ã‚’æœ‰å¿—ã®æ–¹ãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ä»–ã®äººãŒåˆ©ç”¨ã§ãã‚‹ã‚ˆã†ã«ã—ã¦ãã‚Œã¦ã„ã‚‹ã‚µã‚¤ãƒˆ LangChain Hub ã‹ã‚‰ â­ ãŒå¤šã„ã‚‚ã®ã‚’ãŠå€Ÿã‚Šã—ã¦ãã¾ã—ãŸã€‚ã‚‚ã¡ã‚ã‚“è‡ªä½œã—ã¦ã‚‚ã‚‰ã£ã¦ã‚‚OKã§ã™ã€‚
https://smith.langchain.com/hub/rlm/rag-prompt
ãŠå€Ÿã‚Šã—ãŸ rag-prompt ã§ã¯ä»¥ä¸‹ã®ã‚ˆã†ã«ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒå®šç¾©ã•ã‚Œã¦ã„ã¾ã™ã€‚
You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.
Question: {question} 
Context: {context} 
Answer:
ç°¡å˜ã«æ—¥æœ¬èªã«è¨³ã™ã¨ ã€Œ context ã®æƒ…å ±ã®ã¿ã‚’ä½¿ã£ã¦ question ã«ç­”ãˆã‚‹ã‚ˆã†ã« Answer ã‚’è€ƒãˆãªã•ã„ã€‚ç­”ãˆã‚‰ã‚Œãªã„ãªã‚‰ã‚ã‹ã‚‰ãªã„ã¨ç­”ãˆãªã•ã„ã€‚ã€ ã¨ãªã‚Šã¾ã™ã€‚ context ã®æƒ…å ±ã®ã¿ã‚’ç”¨ã„ã‚‹ã‚ˆã†æŒ‡å®šã™ã‚‹ã“ã¨ã§ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³ã‚’é˜²ãåŠ¹æœãŒã‚ã‚Šã¾ã™ (ãŸã ã—ï¼‘ï¼ï¼ï¼…é˜²ãã¨ã¯æ–­è¨€ã§ããªã„ã§ã™)
ã“ã¡ã‚‰ã® question éƒ¨åˆ†ã«ãƒ¦ãƒ¼ã‚¶ã®ã‚¯ã‚¨ãƒªãŒã€ context éƒ¨åˆ†ã« retriever ã‚’æŒ‡å®šã—ã¦ prompt ã‚’å®Ÿè¡Œã›ã‚ˆã¨ã—ã¦ã„ã‚‹ã®ãŒãƒã‚§ãƒ¼ãƒ³ã® {"context": retriever, "question": RunnablePassthrough()} | prompt ã®éƒ¨åˆ†ã§ã™ã€‚
æœ€å¾Œã«å®Œæˆã—ãŸ prompt ã‚’ llm ã«æ¸¡ã—ãªã•ã„ã¨æŒ‡å®šã—ã¦ã„ã‚‹ã®ãŒ prompt | llm ã®éƒ¨åˆ†ã§ã™ã€‚
ã“ã®ãƒ¡ã‚½ãƒƒãƒ‰ãƒã‚§ãƒ¼ãƒ³ã‚’ã¾ã¨ã‚ãŸ chain ã¨ã„ã†å¤‰æ•°ã¯ invoke ãƒ¡ã‚½ãƒƒãƒ‰ã‚’æŒã£ã¦ãŠã‚Šã€ã“ã®ãƒ¡ã‚½ãƒƒãƒ‰ã«è³ªå•ã‚’æŠ•ã’ã‚‹ã¨ãã‚ŒãŒ question ã«å…¥ã‚Šãƒã‚§ãƒ¼ãƒ³ãŒå‰ã‹ã‚‰é †ç•ªã«å®Ÿè¡Œã•ã‚Œã¾ã™ã€‚
ä»¥ä¸Šã®ã‚ˆã†ã«å®šç¾©ã™ã‚‹ã“ã¨ã§ RAG ã¨ã—ã¦å¤–éƒ¨ã®æƒ…å ±ã‚’å‚ç…§ã—ã¤ã¤å›ç­”ã™ã‚‹ ChatBot ã‚’å®Ÿè£…ã§ãã¾ã—ãŸã€‚

 main
def main() -> None:
    """ChatGPTã‚’ä½¿ã£ãŸãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã®ãƒ¡ã‚¤ãƒ³é–¢æ•°."""
    chain = initialize_chain()

    # ãƒšãƒ¼ã‚¸ã®è¨­å®š
    st.set_page_config(page_title="RAG ChatGPT")
    st.image(img, use_column_width=False)
    st.header("RAG ChatGPT")

    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®åˆæœŸåŒ–
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ã‚’ç›£è¦–
    if user_input := st.chat_input("èããŸã„ã“ã¨ã‚’å…¥åŠ›ã—ã¦ã­ï¼"):
        st.session_state.messages.append(HumanMessage(content=user_input))
        with st.spinner("GPT is typing ..."):
            response = chain.invoke(user_input)
        st.session_state.messages.append(AIMessage(content=response.content))

    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®è¡¨ç¤º
    messages = st.session_state.get("messages", [])
    for message in messages:
        if isinstance(message, AIMessage):
            with st.chat_message("assistant"):
                st.markdown(message.content)
        elif isinstance(message, HumanMessage):
            with st.chat_message("user"):
                st.markdown(message.content)
        else:
            st.write(f"System message: {message.content}")
æœ€å¾Œã« main é–¢æ•°ã§ã™ã€‚ã“ã¡ã‚‰ã¯ LangChain ã®å®Ÿè£…ã¨ã„ã†ã‚ˆã‚Šã¯ Streamlit ã‚’åˆ©ç”¨ã—ãŸãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰éƒ¨åˆ†ã®å®Ÿè£…ã«ãªã‚Šã¾ã™ã€‚
ã‚­ãƒ¼ã¨ãªã‚‹ç‚¹ã ã‘è§£èª¬ã™ã‚‹ã¨

ãƒ¦ãƒ¼ã‚¶ã¨ ChatBot ã®ä¼šè©±ã¯ messages ã«ä¿å­˜ã•ã‚Œã¦ã„ã¾ã™ã€‚ä»¥ä¸‹ã®ã‚³ãƒ¼ãƒ‰ã‚’è¦‹ã‚‹ã¨ã‚ã‹ã‚‹ã‚ˆã†ã«ãƒ¦ãƒ¼ã‚¶ã‹ã‚‰ã®è³ªå•ã¨ ChatBot ã®è¿”ç­”ã¯ã©ã¡ã‚‰ã‚‚ messages ã« append ã•ã‚Œã¦ã„ã¾ã™ã€‚

    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®åˆæœŸåŒ–
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ã‚’ç›£è¦–
    if user_input := st.chat_input("èããŸã„ã“ã¨ã‚’å…¥åŠ›ã—ã¦ã­ï¼"):
        st.session_state.messages.append(HumanMessage(content=user_input))
        with st.spinner("GPT is typing ..."):
            response = chain.invoke(user_input)
        st.session_state.messages.append(AIMessage(content=response.content))

ãƒ¦ãƒ¼ã‚¶ã‹ã‚‰ã®è³ªå•ã¸ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã¯å…ˆã»ã©å®šç¾©ã—ãŸ chain ã® invoke ãƒ¡ã‚½ãƒƒãƒ‰ã‚’ç”¨ã„ã¦ä½œã‚‰ã‚Œã¦ã„ã¾ã™ã€‚

        with st.spinner("GPT is typing ..."):
            response = chain.invoke(user_input)
        st.session_state.messages.append(AIMessage(content=response.content))
ã¨ã„ã†ç‚¹ãŒã‚ã’ã‚‰ã‚Œã¾ã™ã€‚

 ãƒ†ã‚¹ãƒˆ
ãã‚Œã§ã¯å®Ÿè£…ã—ãŸã‚‚ã®ã‚’å‹•ã‹ã—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚
> streamlit run chatbot.py

Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.


  You can now view your Streamlit app in your browser.

  Local URL: http://localhost:8501
  Network URL: http://10.200.0.4:8501
  External URL: http://13.73.233.61:8501
http://localhost:8501 ã¸ãƒ–ãƒ©ã‚¦ã‚¶ã‹ã‚‰ã‚¢ã‚¯ã‚»ã‚¹ã—ã€è³ªå•ã—ã¦ã¿ã¾ã™ã€‚

ç¾æ™‚ç‚¹ã§ã® note.txt ã®å…ˆé ­ã®æ–¹ã«æ›¸ã„ã¦ã‚ã£ãŸæ–°ã—ã„ãƒ“ã‚¸ãƒ§ãƒ³ã‚’ã¡ã‚ƒã‚“ã¨ç­”ãˆã¦ã„ã¾ã™ã€‚ã“ã®æƒ…å ±ã¯ OpenAI ã«ã¯ãªã„ãŸã‚ãã¡ã‚“ã¨ RAG ãŒåƒã„ã¦ã„ã‚‹ã¨è¨€ãˆãã†ã§ã™ã€‚

ã¾ãŸã€Œ100å¹´å¾Œã«ç™ºå£²äºˆå®šã®æ–°å•†å“ã€ã¨ã„ã†æƒ…å ±ã¨ã—ã¦å«ã¾ãªã„ã‚ˆã†ãªè³ªå•ã‚’ã™ã‚‹ã¨ã¡ã‚ƒã‚“ã¨ã€Œæƒ…å ±ã‚’æŒã£ã¦ã„ãªã„ã€ã¨è¿”ç­”ã—ã¦ãã‚Œã¾ã™ã€‚ã“ã¡ã‚‰ã‚‚æœŸå¾…é€šã‚Šã§ã™ã­ã€‚

 ğŸ’¡ ã¾ã¨ã‚

LangChain v0.2.5 æ™‚ç‚¹ã§ã® RAG ã‚’ç”¨ã„ãŸ ChatBot ã®å®Ÿè£…ã‚’è¡Œã„ã¾ã—ãŸ
Streamlit ã‚’ç”¨ã„ã¦ãƒ–ãƒ©ã‚¦ã‚¶ã‹ã‚‰ãƒ¦ãƒ¼ã‚¶ãŒã‚¢ã‚¯ã‚»ã‚¹ã§ãã‚‹ã‚ˆã†ã«ã—ã¾ã—ãŸ

ãœã²å‚è€ƒã«ã—ã¦ã¿ã¦ãã ã•ã„ã€‚
yamasaKitcheminformatics, machine learning, board gameCykinso's Tech BlogPublicationã€Œç´°èŒå¢ã®åŠ›ã§äººã€…ã‚’å¥åº·ã«ã€ã‚’ãƒŸãƒƒã‚·ãƒ§ãƒ³ã«æ²ã’ã‚‹ãƒã‚¤ã‚ªãƒ†ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆã‚¢ãƒƒãƒ—ã€Œã‚µã‚¤ã‚­ãƒ³ã‚½ãƒ¼ã€ã®æŠ€è¡“ãƒ–ãƒ­ã‚°ã€‚ ãƒãƒƒã‚¸ã‚’è´ˆã£ã¦è‘—è€…ã‚’å¿œæ´ã—ã‚ˆã†ãƒãƒƒã‚¸ã‚’å—ã‘å–ã£ãŸè‘—è€…ã«ã¯Zennã‹ã‚‰ç¾é‡‘ã‚„Amazonã‚®ãƒ•ãƒˆã‚«ãƒ¼ãƒ‰ãŒé‚„å…ƒã•ã‚Œã¾ã™ã€‚ãƒãƒƒã‚¸ã‚’è´ˆã‚‹DiscussionyamasaKitcheminformatics, machine learning, board gameãƒãƒƒã‚¸ã‚’è´ˆã‚‹ãƒãƒƒã‚¸ã‚’è´ˆã‚‹ã¨ã¯ç›®æ¬¡èƒŒæ™¯ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ãªã©æ–¹æ³•.envãƒ‡ãƒ¼ã‚¿ã‚³ãƒ¼ãƒ‰initialize_vector_storeinitialize_retriverinitialize_chainmainãƒ†ã‚¹ãƒˆğŸ’¡ ã¾ã¨ã‚
div
div
div
button
svg
path
path
g
a
a
a
divchatbotOpenAILangChainLLMRAGtech
 èƒŒæ™¯
LangChain ã¯ OpenAI API ã‚’åˆ©ç”¨ã—è‡ªåˆ†ãŸã¡ãŒã‚„ã‚ŠãŸã„ã“ã¨ã‚’å®Ÿç¾ã™ã‚‹ã“ã¨ã«éå¸¸ã«ä¾¿åˆ©ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã§ã™ãŒãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚¢ãƒƒãƒ—ã«ã‚ˆã£ã¦ã‚¯ãƒ©ã‚¹åã‚„ã‚µãƒ–ãƒ©ã‚¤ãƒ–ãƒ©ãƒªåã®å¤‰æ›´ãŒã‚„ã‚„å¤šãå°‘ã—å¤ã„ Web è¨˜äº‹ã‚’å‚è€ƒã«ã—ã¦ã‚‚ã†ã¾ããƒ¯ãƒ¼ã‚¯ã—ãªã„ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚
ã“ã®è¨˜äº‹ã¯ 2024/6/20 ç¾åœ¨ã® LangChain (ãƒãƒ¼ã‚¸ãƒ§ãƒ³ 0.2.5) ã§ OpenAI API ã‚„ Azure OpenAI API ã‚’å‹•ã‹ã™ä¾‹ã¨ã—ã¦æ®‹ã—ã¦ãŠãã¾ã™ã€‚
åŒã˜ã‚ˆã†ãªã“ã¨ã‚’ã—ã‚ˆã†ã¨ã—ã¦ç§ã®ã‚ˆã†ã«è‹¦æˆ¦ã—ã¦ã„ã‚‹æ–¹ã®åŠ©ã‘ã«ãªã‚Œã°å¹¸ã„ã§ã™ã€‚

 ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ãªã©

pyproject.toml
python = ">=3.12,<3.13"
python-dotenv = "^1.0.1"
chromadb = "0.5.2"
langchain = "0.2.5"
langchain-cli = "0.0.25"
langchain-openai = "0.1.8"
langchain-community = "0.2.5"
langchain-chroma = "0.1.1"
langchainhub = "0.1.20"
streamlit = "1.35.0"

ğŸ’¡ Poetry ã§ Python ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’æŒ‡å®šã™ã‚‹æ™‚ã« ^3.12 ã¨ã™ã‚‹ã¨ lancghain-chroma ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã§ããªããªã‚‹ã®ã§ >=3.12,<3.13 ã¨ã—ã¾ã—ãŸã€‚
(langchain-chroma ã¯ >=3.12,<3.13 ã¨ã„ã†æŒ‡å®šãŒã‚ã‚Šã¾ã™)

 æ–¹æ³•
OpenAI API ã‚’ä½¿ã†å ´åˆã¨ AzureOpenAI API ã‚’ä½¿ã†å ´åˆã¯åŸºæœ¬åŒã˜ã“ã¨ã‚’ã™ã‚‹ã®ã§ã¾ãš OpenAI API ã‚’ä½¿ã†å ´åˆã‚’èª¬æ˜ã—ã€è¨˜äº‹ãŒé•·ããªã£ã¦ã—ã¾ã£ãŸã®ã§ã€å¾Œæ—¥åˆ¥è¨˜äº‹ã«ã¦ AzureOpenAI API ã‚’ä½¿ã†å ´åˆã¯ã©ã®éƒ¨åˆ†ã‚’ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆã—ãŸã‚‰ã‚ˆã„ã®ã‹ã‚’èª¬æ˜ã—ãŸã„ã¨æ€ã„ã¾ã™ã€‚
6/28 è¿½è¨˜) AzureOpenAI API ç‰ˆã®è¨˜äº‹ã‚‚æ›¸ãã¾ã—ãŸã®ã§ã‚ˆã‘ã‚Œã°ãœã²ã©ã†ã
https://zenn.dev/cykinso/articles/b055e33734d06b

 .env
ä»¥ä¸‹ã®ã‚ˆã†ã« .env ã‚’ç”¨æ„ã—ã¾ã™ã€‚
OPENAI_API_KEY=sk-XXXXXXXXXXXXXXXX
OPENAI_API_VERSION=2024-02-01
ã‚‚ã— OPENAI_API_KEY ã‚’ã¾ã å–å¾—ã—ã¦ã„ãªã„å ´åˆã¯ä»¥ä¸‹ã®æ–¹æ³•ã§å–å¾—ã—ã¦ãã ã•ã„ã€‚

 OPENAI_API_KEY
OPENAI_API_KEY ã¯ OpenAI ã® Dashboard ã§ä½œæˆã§ãã¾ã™ã€‚
(èª²é‡‘å¯¾è±¡ãªã®ã§ã”è‡ªèº«ã®è²¬ä»»ã®ã‚‚ã¨ã”åˆ©ç”¨ãã ã•ã„)

ã€Œ+ Create new secret keyã€ ã‚’æŠ¼ã™ã¨ãƒ¢ãƒ¼ãƒ€ãƒ«ãŒé–‹ãã®ã§å¾Œã‹ã‚‰åŒºåˆ¥ã§ãã‚‹ã‚ˆã†ãªåå‰ã‚’ã¤ã‘ã¦ ã€ŒCreate secret keyã€ ã‚’æŠ¼ã—ã¾ã™ã€‚

è¡¨ç¤ºã•ã‚Œã‚‹ API ã‚­ãƒ¼ã‚’ .env ã«ãƒ¡ãƒ¢ã—ã¦ãŠãã¾ã™ã€‚ ã€ŒDoneã€ ã‚’æŠ¼ã™ã¨ã‚‚ã†è¡¨ç¤ºã§ãã¾ã›ã‚“ã€‚


 ãƒ‡ãƒ¼ã‚¿
OpenAI ãŒã¾ã å­¦ç¿’ã—ã¦ã„ãªã•ãã†ãªãƒ‡ãƒ¼ã‚¿ã®ä¾‹ã¨ã—ã¦å¼Šç¤¾ Cykinso ã®ãƒ–ãƒ­ã‚°è¨˜äº‹ã®ã€Œä¼šç¤¾ã®ãƒ“ã‚¸ãƒ§ãƒ³ã‚’è©±ã—ã¦ã„ã‚‹ãƒšãƒ¼ã‚¸ã€ã‚’ä»Šå›ã¯ç”¨ã„ãŸã„ã¨æ€ã„ã¾ã™ã€‚
https://note.com/cykinso/n/n432d5ea70783
ğŸ’¡ ãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆã§å®Ÿè£…ã™ã‚‹å ´åˆã¯ã€å¥½ããªãƒãƒ³ã‚¬ãªã©ã®è©³ç´°ã‚’ãƒ†ã‚­ã‚¹ãƒˆã«ã¾ã¨ã‚ã¦ãƒ‡ãƒ¼ã‚¿ã¨ã™ã‚‹ã¨ãƒ¢ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³ã‚‚ä¸ŠãŒã‚‹ã¨æ€ã„ã¾ã™ã€‚
ã–ã£ã¨æ–‡ç« ã‚’ã‚³ãƒ”ãƒ¼ã—ã¦ä»¥ä¸‹ã®ã‚ˆã†ã«æ•´å½¢ã—ã¾ã—ãŸã€‚

note.txt
ç´°èŒå¢ã‹ã‚‰ã®æ–°ãŸãªæ°—ä»˜ãã‚’é€šã˜ã¦ã€æ–°ãƒ“ã‚¸ãƒ§ãƒ³ã‚’ç­–å®šã—ã¾ã—ãŸï¼
2023å¹´11æœˆã«ã‚µã‚¤ã‚­ãƒ³ã‚½ãƒ¼ã¯10æœŸç›®ã«å…¥ã‚Šã¾ã—ãŸã€‚é«˜é½¢åŒ–ç¤¾ä¼šã«ã‚ˆã‚‹ç¤¾ä¼šä¿éšœã¸ã®ä¸å®‰ãŒå‹Ÿã‚‹ç¾åœ¨ã€ç—…æ°—ã‚’æœªç„¶ã«é˜²ã0æ¬¡äºˆé˜²ã®é‡è¦æ€§ãŒé«˜ã¾ã£ã¦ã„ã¾ã™ã€‚ã€Œç´°èŒå¢ã§äººã€…ã‚’å¥åº·ã«ã€ã¨ã„ã†ãƒŸãƒƒã‚·ãƒ§ãƒ³ã«å‘ã‘ã¦ã€ã‚µã‚¤ã‚­ãƒ³ã‚½ãƒ¼ã¯æ–°ãŸãªãƒ“ã‚¸ãƒ§ãƒ³ã‚’åˆ¶å®šã—ã¾ã—ãŸã€‚
æ–°ã—ã„ãƒ“ã‚¸ãƒ§ãƒ³ã«ã¤ã„ã¦
ãƒ¼ãƒ“ã‚¸ãƒ§ãƒ³å¤‰æ›´ã§å…·ä½“çš„ã«ã©ã®å€‹æ‰€ãŒå¤‰æ›´ã—ãŸã‹ã‚’ã¾ãšã”ç´¹ä»‹ã—ã¾ã™ã€‚
ã“ã¡ã‚‰ãŒã‚µã‚¤ã‚­ãƒ³ã‚½ãƒ¼ã®ãƒŸãƒƒã‚·ãƒ§ãƒ³ï¼ˆMISSIONï¼‰ã€ãƒ“ã‚¸ãƒ§ãƒ³(VISION)ã€ãƒãƒªãƒ¥ãƒ¼(VALUE)ã«ãªã‚Šã¾ã™ã€‚
ç§ãŸã¡ãŒç›®æŒ‡ã—ç¶šã‘ã‚‹ã€Œç´°èŒå¢ã§äººã€…ã‚’å¥åº·ã«ã€ã¨ã„ã†ãƒŸãƒƒã‚·ãƒ§ãƒ³ã¯ãã®ã¾ã¾ã«ã€ãƒ“ã‚¸ãƒ§ãƒ³ã‚’æ–°ã—ãå¤‰æ›´è‡´ã—ã¾ã—ãŸã€‚

ï¼œã“ã‚Œã¾ã§ã®ãƒ“ã‚¸ãƒ§ãƒ³ï¼
èŒå¢ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã€Œæ¬¡ä¸–ä»£ã®ãƒ©ã‚¤ãƒ•ã‚¹ã‚¿ã‚¤ãƒ«ã€ã‚’æä¾›ã™ã‚‹ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã«ãªã‚‹

ï¼œæ–°ã—ã„ãƒ“ã‚¸ãƒ§ãƒ³ï¼
ç´°èŒå¢ã‹ã‚‰ã®æ–°ãŸãªæ°—ä»˜ãã‚’é€šã˜ã¦
ãƒ’ãƒˆã€ç¤¾ä¼šã€åœ°çƒç’°å¢ƒã‚’å¥åº·ã«ã™ã‚‹ã‚¨ã‚³ã‚·ã‚¹ãƒ†ãƒ ã‚’å®Ÿç¾ã™ã‚‹
æ–°ã—ã„ãƒ“ã‚¸ãƒ§ãƒ³ã§ã¯ã€ã‚µã‚¤ã‚­ãƒ³ã‚½ãƒ¼ãŒå½±éŸ¿ã‚’ä¸ãˆã¦ã„ããŸã„ç¯„å›²ã‚‚ã“ã‚Œã¾ã§ã‚ˆã‚Šã•ã‚‰ã«å¤§ãããªã£ãŸã“ã¨ãŒåˆ†ã‹ã‚Šã¾ã™ã€‚

ä»Šå›ã®ãƒ“ã‚¸ãƒ§ãƒ³å¤‰æ›´ã‚’é€šã—ã¦ã€ã‚µã‚¤ã‚­ãƒ³ã‚½ãƒ¼ãŒã©ã‚“ãªä¾¡å€¤ç™ºæ®ã‚’ç›®æŒ‡ã—ã¦ã„ãã®ã‹ã€ãã‚Œã«ä¼´ã„äº‹æ¥­é¢ã§ã¯ã©ã‚“ãªæŒ‘æˆ¦ã‚’ã—ã¦ã„ãã®ã‹ã‚’ã€ä»£è¡¨å–ç· å½¹CEOã®æ²¢äº•ã•ã‚“ã«èã„ã¦ãã¾ã—ãŸï¼

...(ä»¥ä¸‹ç•¥)


 ã‚³ãƒ¼ãƒ‰
ç¶šã‘ã¦ã‚³ãƒ¼ãƒ‰ã‚’å®Ÿè£…ã—ã¾ã™ã€‚
ä»Šå›ã¯ RAG ã¨ã—ã¦å¤–éƒ¨ã®æƒ…å ±ã‚’å‚ç…§ã—ã¤ã¤å›ç­”ã™ã‚‹ ChatBot ã‚’å®Ÿè£…ã—ã¦ã¿ã¾ã™ã€‚
ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã¨ã—ã¦ streamlit ã‚’ç”¨ã„ã¾ã™ã€‚
å…ˆã«ã‚³ãƒ¼ãƒ‰å…¨ä½“ã‚’ç¤ºã™ã¨ä»¥ä¸‹ã®ã‚ˆã†ã«ãªã‚Šã¾ã™ã€‚
(streamlit ã®ã‚³ãƒ¼ãƒ‰ã®ãƒ™ãƒ¼ã‚¹ã¨ã—ã¦ä»¥ä¸‹ã®è¨˜äº‹ã‚’å‚è€ƒã«ã•ã›ã¦ã„ãŸã ãã¾ã—ãŸã€‚ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™)
https://tech-lab.sios.jp/archives/41574

chatbot.py
from pathlib import Path

import streamlit as st
from dotenv import load_dotenv
from langchain import hub
from langchain.schema import AIMessage, HumanMessage
from langchain_chroma import Chroma
from langchain_community.document_loaders import TextLoader
from langchain_core.runnables import RunnablePassthrough, RunnableSequence
from langchain_core.vectorstores import VectorStoreRetriever
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_text_splitters import RecursiveCharacterTextSplitter

load_dotenv()


def initialize_vector_store() -> Chroma:
    """VectorStoreã®åˆæœŸåŒ–."""
    embeddings = OpenAIEmbeddings()

    vector_store_path = "./resources/note.db"
    if Path(vector_store_path).exists():
        vector_store = Chroma(embedding_function=embeddings, persist_directory=vector_store_path)
    else:
        loader = TextLoader("resources/note.txt")
        docs = loader.load()

        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
        splits = text_splitter.split_documents(docs)

        vector_store = Chroma.from_documents(
            documents=splits, embedding=embeddings, persist_directory=vector_store_path
        )

    return vector_store


def initialize_retriever() -> VectorStoreRetriever:
    """Retrieverã®åˆæœŸåŒ–."""
    vector_store = initialize_vector_store()
    return vector_store.as_retriever()


def initialize_chain() -> RunnableSequence:
    """Langchainã®åˆæœŸåŒ–."""
    prompt = hub.pull("rlm/rag-prompt")
    llm = ChatOpenAI()
    retriever = initialize_retriever()
    chain = (
        {"context": retriever, "question": RunnablePassthrough()} | prompt | llm
    )
    return chain


def main() -> None:
    """ChatGPTã‚’ä½¿ã£ãŸãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã®ãƒ¡ã‚¤ãƒ³é–¢æ•°."""
    chain = initialize_chain()

    # ãƒšãƒ¼ã‚¸ã®è¨­å®š
    st.set_page_config(page_title="RAG ChatGPT")
    st.header("RAG ChatGPT")

    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®åˆæœŸåŒ–
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ã‚’ç›£è¦–
    if user_input := st.chat_input("èããŸã„ã“ã¨ã‚’å…¥åŠ›ã—ã¦ã­ï¼"):
        st.session_state.messages.append(HumanMessage(content=user_input))
        with st.spinner("GPT is typing ..."):
            response = chain.invoke(user_input)
        st.session_state.messages.append(AIMessage(content=response.content))

    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®è¡¨ç¤º
    messages = st.session_state.get("messages", [])
    for message in messages:
        if isinstance(message, AIMessage):
            with st.chat_message("assistant"):
                st.markdown(message.content)
        elif isinstance(message, HumanMessage):
            with st.chat_message("user"):
                st.markdown(message.content)
        else:
            st.write(f"System message: {message.content}")


if __name__ == "__main__":
    main()

ã‚³ãƒ¼ãƒ‰ã®å„éƒ¨åˆ†ã‚’èª¬æ˜ã—ã¦ã„ãã¾ã™ã€‚

 initialize_vector_store
def initialize_vector_store() -> Chroma:
    """VectorStoreã®åˆæœŸåŒ–."""
    embeddings = OpenAIEmbeddings()

    vector_store_path = "./resources/note.db"
    if Path(vector_store_path).exists():
        vector_store = Chroma(embedding_function=embeddings, persist_directory=vector_store_path)
    else:
        loader = TextLoader("resources/note.txt")
        docs = loader.load()

        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
        splits = text_splitter.split_documents(docs)

        vector_store = Chroma.from_documents(
            documents=splits, embedding=embeddings, persist_directory=vector_store_path
        )

    return vector_store
Vector store ã¨ã¯æƒ…å ±ã¨ã—ã¦èª­ã¿è¾¼ã¾ã›ã¦ã„ã‚‹ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’é©åˆ‡ãªé•·ã•ã«åˆ†å‰²ã—(ãƒãƒ£ãƒ³ã‚¯ã¨å‘¼ã°ã‚Œã¾ã™) ã™ãã«å–ã‚Šå‡ºã›ã‚‹ã‚ˆã†ã«ä¿å­˜ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ã‚ˆã†ãªã‚‚ã®ã§ã™ã€‚
Embeddings ã¨å‘¼ã°ã‚Œã‚‹ãƒ¢ãƒ‡ãƒ«ã§ãƒ†ã‚­ã‚¹ãƒˆã¯æ•°å€¤æƒ…å ±ã®ãƒ™ã‚¯ãƒˆãƒ«ã«ä¿å­˜ã•ã‚Œã¾ã™ã€‚ãã®ä½œæ¥­ã‚’è¡Œã†ãŸã‚ã« OpenAI API ãŒå¿…è¦ã«ãªã£ã¦ã„ã‚‹ãŸã‚é–¢æ•°ã®æœ€åˆã§ OpenAIEmbeddings ã‚’å‘¼ã³å‡ºã—ã¦ã„ã¾ã™ã€‚
ç¶šã‘ã¦ Vector store ã¨ã—ã¦ä¿å­˜ã•ã‚Œã¦ã„ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã™ã§ã«å­˜åœ¨ã—ã¦ã„ãªã„ã‹ã‚’èª¿ã¹ã¦ã„ã¾ã™ã€‚åŸºæœ¬çš„ã«ãƒ‡ãƒ¼ã‚¿ã‚„ãƒ¢ãƒ‡ãƒ«ãŒã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆã•ã‚Œãªã„é™ã‚Š Vector store ã®ãƒ‡ãƒ¼ã‚¿ã¯ã¾ã£ãŸãåŒã˜ã«ãªã‚‹ãŸã‚ã€æ¯å›å®Ÿè¡Œã—ã¦ã—ã¾ã†ã¨æ™‚é–“ã‚‚ API ã®åˆ©ç”¨æ–™é‡‘ã‚‚ç„¡é§„ã«ãªã£ã¦ã—ã¾ã„ã¾ã™ã€‚
ãã“ã§

ã¾ã å­˜åœ¨ã—ã¦ã„ãªã„å ´åˆï¼š æ–°è¦ä½œæˆ
ã™ã§ã«å­˜åœ¨ã—ã¦ã„ã‚‹å ´åˆï¼š ä¿å­˜ã—ã¦ã„ã‚‹ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’èª­ã¿è¾¼ã‚€

ã¨ã—ã¦ã„ã¾ã™ã€‚
ãªãŠå­˜åœ¨ã—ã¦ã„ã‚‹å ´åˆ Chroma ã‚¯ãƒ©ã‚¹ã®å¼•æ•° embedding_function ã« embeddings ã‚’æŒ‡å®šã—ã¦ã„ã¾ã™ãŒã€ã“ã‚Œã¯ã‚¯ã‚¨ãƒªã¨ã—ã¦ã‚ãŸãˆã‚‰ã‚Œã‚‹ãƒ¦ãƒ¼ã‚¶ã®è³ªå•ã¨ Vector store ã«ä¿å­˜ã•ã‚Œã¦ã„ã‚‹ãƒ‡ãƒ¼ã‚¿ã¨ã®é–“ã®é–¢é€£æ€§ã‚’èª¿ã¹ã‚‹ãŸã‚ã«ã€ã‚¯ã‚¨ãƒªã‚‚ Embeddings ã§ãƒ™ã‚¯ãƒˆãƒ«ã«å¤‰æ›ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã‹ã‚‰ã§ã™ã€‚

 initialize_retriver
def initialize_retriever() -> VectorStoreRetriever:
    """Retrieverã®åˆæœŸåŒ–."""
    vector_store = initialize_vector_store()
    return vector_store.as_retriever()
ã“ã¡ã‚‰ã§ã¯ã€å…ˆã»ã©ä½œæˆã—ãŸ(ã‚ã‚‹ã„ã¯ã™ã§ã«ã‚ã‚‹ã‚‚ã®ã‚’èª­ã¿è¾¼ã‚“ã ) vector_store ã‚’ retriever ã«å¤‰æ›ã—ã¦ã„ã¾ã™ã€‚ã“ã¡ã‚‰ã® retriever ã“ã®å¾Œã€ Vectore store ã‹ã‚‰æƒ…å ±ã‚’å–ã‚Šå‡ºã™ã®ã«åˆ©ç”¨ã•ã‚Œã¾ã™ã€‚

 initialize_chain
def initialize_chain() -> RunnableSequence:
    """Langchainã®åˆæœŸåŒ–."""
    prompt = hub.pull("rlm/rag-prompt")
    llm = ChatOpenAI()
    retriever = initialize_retriever()
    chain = (
        {"context": retriever, "question": RunnablePassthrough()} | prompt | llm
    )
    return chain
ã“ã¡ã‚‰ã§ã¯ retriever ã®æƒ…å ±ã‚’ LLM ã§åˆ©ç”¨ã§ãã‚‹ã‚ˆã†ã« chain ã¨å‘¼ã°ã‚Œã‚‹æ¦‚å¿µã‚’åˆ©ç”¨ã—ã¦ãŠã‚Šã¾ã™ã€‚
ã‚ˆããƒ¡ã‚½ãƒƒãƒ‰ãƒã‚§ãƒ¼ãƒ³ã¨ã„ã†è¨€è‘‰ãŒãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°è¨€èªã§ã¯ä½¿ã‚ã‚Œã¦ã„ã¾ã™ã€‚
ä¾‹ãˆã° Python ã® Pandas ã§ã¯
import pandas as pd

# ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
data = {
    'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Edward', 'Frank'],
    'Age': [24, 27, 22, 32, 29, 24],
    'City': ['New York', 'Los Angeles', 'New York', 'Chicago', 'Los Angeles', 'New York'],
    'Score': [85, 90, 88, 92, 95, 70]
}

df = pd.DataFrame(data)

# ãƒ¡ã‚½ãƒƒãƒ‰ãƒã‚§ãƒ¼ãƒ³ã‚’ä½¿ã£ãŸãƒ‡ãƒ¼ã‚¿å¤‰æ›
result = (df
          .query('Age > 25')                     # å¹´é½¢ãŒ25ä»¥ä¸Šã®è¡Œã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
          .groupby('City')                       # éƒ½å¸‚ã”ã¨ã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
          .agg({'Score': 'mean'})                # ã‚¹ã‚³ã‚¢ã®å¹³å‡ã‚’è¨ˆç®—
          .rename(columns={'Score': 'Average Score'})  # åˆ—åã‚’å¤‰æ›´
          .sort_values(by='Average Score', ascending=False)  # å¹³å‡ã‚¹ã‚³ã‚¢ã§ä¸¦ã¹æ›¿ãˆ
          .reset_index()                         # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ãƒªã‚»ãƒƒãƒˆ
         )

print(result)
ã¨ã„ã†ã‚ˆã†ã«ãƒ¡ã‚½ãƒƒãƒ‰ã®è¿”ã‚Šå€¤ã‚’æ¬¡ã®ãƒ¡ã‚½ãƒƒãƒ‰ã¸ã¨ãƒã‚±ãƒ„ãƒªãƒ¬ãƒ¼ã®ã‚ˆã†ã«ã¤ãªã„ã§è¡Œãå‡¦ç†ã•ã›ã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚ã“ã‚Œã‚’ãƒ¡ã‚½ãƒƒãƒ‰ãƒã‚§ãƒ¼ãƒ³ã¨ã„ã„ã¾ã™ã€‚
LangChain ã§ã‚‚ã“ã®ãƒã‚±ãƒ„ãƒªãƒ¬ãƒ¼ã‚’è¡Œã„ã€ã©ã®ã‚ˆã†ã«ãƒ¦ãƒ¼ã‚¶ã®è³ªå•ã«ç­”ãˆã‚‹ã‹ã®ãƒ«ãƒ¼ãƒ«ã‚’æ±ºã‚ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚
LangChain ã®å ´åˆã¯æ˜”ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã§ã¯é–¢æ•°ã®è¿”ã‚Šå€¤ã‚’ã•ã‚‰ã«é–¢æ•°ã®å¼•æ•°ã«ã™ã‚‹ã¨è¨€ã†ã“ã¨ã‚’ç¹°ã‚Šè¿”ã—ã¦ãƒã‚±ãƒ„ãƒªãƒ¬ãƒ¼ã‚’è¡Œã£ã¦ã„ã¾ã—ãŸãŒã€ä»Šã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ 0.2.5 ã§ã¯ä»¥ä¸‹ã®ã‚ˆã†ã« | ã‚’åˆ©ç”¨ã—ãƒã‚§ãƒ¼ãƒ³ã‚’ç¤ºã™ã“ã¨ãŒæ¨å¥¨ã•ã‚Œã¦ã„ã¾ã™ã€‚
    chain = (
        {"context": retriever, "question": RunnablePassthrough()} | prompt | llm
    )
ä»Šå›ã®å ´åˆ

{"context": retriever, "question": RunnablePassthrough()}
prompt
llm

ã¨ã„ã†é †ç•ªã§ãƒã‚§ãƒ¼ãƒ³ãŒã¤ãªãŒã£ã¦ã„ã¾ã™ã€‚
ãƒã‚§ãƒ¼ãƒ³ã®å…ˆé ­ãŒãªãœè¾æ›¸ã§ã‚ã‚‹ã‹ã¯ã€2ç•ªç›®ã® prompt ã®èª¬æ˜ã‚’èã„ã¦ã‚‚ã‚‰ãˆã‚Œã°ã‚ã‹ã‚‹ã¨æ€ã„ã¾ã™ã€‚
    prompt = hub.pull("rlm/rag-prompt")
prompt ã¯ LLM ã«ã©ã®ã‚ˆã†ãªè³ªå•ã‚„ä¾é ¼ã‚’ã™ã‚‹ã®ã‹ã‚’æ±ºã‚ã‚‹éƒ¨åˆ†ã§ã™ã€‚ä»Šå›ã¯ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ(å¤‰æ•°åã‚’æŒ‡ã—ã¦ã„ãªã„å ´åˆã‚«ã‚¿ã‚«ãƒŠè¡¨è¨˜ã¨ã—ã¾ã™)ã‚’æœ‰å¿—ã®æ–¹ãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ä»–ã®äººãŒåˆ©ç”¨ã§ãã‚‹ã‚ˆã†ã«ã—ã¦ãã‚Œã¦ã„ã‚‹ã‚µã‚¤ãƒˆ LangChain Hub ã‹ã‚‰ â­ ãŒå¤šã„ã‚‚ã®ã‚’ãŠå€Ÿã‚Šã—ã¦ãã¾ã—ãŸã€‚ã‚‚ã¡ã‚ã‚“è‡ªä½œã—ã¦ã‚‚ã‚‰ã£ã¦ã‚‚OKã§ã™ã€‚
https://smith.langchain.com/hub/rlm/rag-prompt
ãŠå€Ÿã‚Šã—ãŸ rag-prompt ã§ã¯ä»¥ä¸‹ã®ã‚ˆã†ã«ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒå®šç¾©ã•ã‚Œã¦ã„ã¾ã™ã€‚
You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.
Question: {question} 
Context: {context} 
Answer:
ç°¡å˜ã«æ—¥æœ¬èªã«è¨³ã™ã¨ ã€Œ context ã®æƒ…å ±ã®ã¿ã‚’ä½¿ã£ã¦ question ã«ç­”ãˆã‚‹ã‚ˆã†ã« Answer ã‚’è€ƒãˆãªã•ã„ã€‚ç­”ãˆã‚‰ã‚Œãªã„ãªã‚‰ã‚ã‹ã‚‰ãªã„ã¨ç­”ãˆãªã•ã„ã€‚ã€ ã¨ãªã‚Šã¾ã™ã€‚ context ã®æƒ…å ±ã®ã¿ã‚’ç”¨ã„ã‚‹ã‚ˆã†æŒ‡å®šã™ã‚‹ã“ã¨ã§ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³ã‚’é˜²ãåŠ¹æœãŒã‚ã‚Šã¾ã™ (ãŸã ã—ï¼‘ï¼ï¼ï¼…é˜²ãã¨ã¯æ–­è¨€ã§ããªã„ã§ã™)
ã“ã¡ã‚‰ã® question éƒ¨åˆ†ã«ãƒ¦ãƒ¼ã‚¶ã®ã‚¯ã‚¨ãƒªãŒã€ context éƒ¨åˆ†ã« retriever ã‚’æŒ‡å®šã—ã¦ prompt ã‚’å®Ÿè¡Œã›ã‚ˆã¨ã—ã¦ã„ã‚‹ã®ãŒãƒã‚§ãƒ¼ãƒ³ã® {"context": retriever, "question": RunnablePassthrough()} | prompt ã®éƒ¨åˆ†ã§ã™ã€‚
æœ€å¾Œã«å®Œæˆã—ãŸ prompt ã‚’ llm ã«æ¸¡ã—ãªã•ã„ã¨æŒ‡å®šã—ã¦ã„ã‚‹ã®ãŒ prompt | llm ã®éƒ¨åˆ†ã§ã™ã€‚
ã“ã®ãƒ¡ã‚½ãƒƒãƒ‰ãƒã‚§ãƒ¼ãƒ³ã‚’ã¾ã¨ã‚ãŸ chain ã¨ã„ã†å¤‰æ•°ã¯ invoke ãƒ¡ã‚½ãƒƒãƒ‰ã‚’æŒã£ã¦ãŠã‚Šã€ã“ã®ãƒ¡ã‚½ãƒƒãƒ‰ã«è³ªå•ã‚’æŠ•ã’ã‚‹ã¨ãã‚ŒãŒ question ã«å…¥ã‚Šãƒã‚§ãƒ¼ãƒ³ãŒå‰ã‹ã‚‰é †ç•ªã«å®Ÿè¡Œã•ã‚Œã¾ã™ã€‚
ä»¥ä¸Šã®ã‚ˆã†ã«å®šç¾©ã™ã‚‹ã“ã¨ã§ RAG ã¨ã—ã¦å¤–éƒ¨ã®æƒ…å ±ã‚’å‚ç…§ã—ã¤ã¤å›ç­”ã™ã‚‹ ChatBot ã‚’å®Ÿè£…ã§ãã¾ã—ãŸã€‚

 main
def main() -> None:
    """ChatGPTã‚’ä½¿ã£ãŸãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã®ãƒ¡ã‚¤ãƒ³é–¢æ•°."""
    chain = initialize_chain()

    # ãƒšãƒ¼ã‚¸ã®è¨­å®š
    st.set_page_config(page_title="RAG ChatGPT")
    st.image(img, use_column_width=False)
    st.header("RAG ChatGPT")

    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®åˆæœŸåŒ–
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ã‚’ç›£è¦–
    if user_input := st.chat_input("èããŸã„ã“ã¨ã‚’å…¥åŠ›ã—ã¦ã­ï¼"):
        st.session_state.messages.append(HumanMessage(content=user_input))
        with st.spinner("GPT is typing ..."):
            response = chain.invoke(user_input)
        st.session_state.messages.append(AIMessage(content=response.content))

    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®è¡¨ç¤º
    messages = st.session_state.get("messages", [])
    for message in messages:
        if isinstance(message, AIMessage):
            with st.chat_message("assistant"):
                st.markdown(message.content)
        elif isinstance(message, HumanMessage):
            with st.chat_message("user"):
                st.markdown(message.content)
        else:
            st.write(f"System message: {message.content}")
æœ€å¾Œã« main é–¢æ•°ã§ã™ã€‚ã“ã¡ã‚‰ã¯ LangChain ã®å®Ÿè£…ã¨ã„ã†ã‚ˆã‚Šã¯ Streamlit ã‚’åˆ©ç”¨ã—ãŸãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰éƒ¨åˆ†ã®å®Ÿè£…ã«ãªã‚Šã¾ã™ã€‚
ã‚­ãƒ¼ã¨ãªã‚‹ç‚¹ã ã‘è§£èª¬ã™ã‚‹ã¨

ãƒ¦ãƒ¼ã‚¶ã¨ ChatBot ã®ä¼šè©±ã¯ messages ã«ä¿å­˜ã•ã‚Œã¦ã„ã¾ã™ã€‚ä»¥ä¸‹ã®ã‚³ãƒ¼ãƒ‰ã‚’è¦‹ã‚‹ã¨ã‚ã‹ã‚‹ã‚ˆã†ã«ãƒ¦ãƒ¼ã‚¶ã‹ã‚‰ã®è³ªå•ã¨ ChatBot ã®è¿”ç­”ã¯ã©ã¡ã‚‰ã‚‚ messages ã« append ã•ã‚Œã¦ã„ã¾ã™ã€‚

    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®åˆæœŸåŒ–
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ã‚’ç›£è¦–
    if user_input := st.chat_input("èããŸã„ã“ã¨ã‚’å…¥åŠ›ã—ã¦ã­ï¼"):
        st.session_state.messages.append(HumanMessage(content=user_input))
        with st.spinner("GPT is typing ..."):
            response = chain.invoke(user_input)
        st.session_state.messages.append(AIMessage(content=response.content))

ãƒ¦ãƒ¼ã‚¶ã‹ã‚‰ã®è³ªå•ã¸ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã¯å…ˆã»ã©å®šç¾©ã—ãŸ chain ã® invoke ãƒ¡ã‚½ãƒƒãƒ‰ã‚’ç”¨ã„ã¦ä½œã‚‰ã‚Œã¦ã„ã¾ã™ã€‚

        with st.spinner("GPT is typing ..."):
            response = chain.invoke(user_input)
        st.session_state.messages.append(AIMessage(content=response.content))
ã¨ã„ã†ç‚¹ãŒã‚ã’ã‚‰ã‚Œã¾ã™ã€‚

 ãƒ†ã‚¹ãƒˆ
ãã‚Œã§ã¯å®Ÿè£…ã—ãŸã‚‚ã®ã‚’å‹•ã‹ã—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚
> streamlit run chatbot.py

Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.


  You can now view your Streamlit app in your browser.

  Local URL: http://localhost:8501
  Network URL: http://10.200.0.4:8501
  External URL: http://13.73.233.61:8501
http://localhost:8501 ã¸ãƒ–ãƒ©ã‚¦ã‚¶ã‹ã‚‰ã‚¢ã‚¯ã‚»ã‚¹ã—ã€è³ªå•ã—ã¦ã¿ã¾ã™ã€‚

ç¾æ™‚ç‚¹ã§ã® note.txt ã®å…ˆé ­ã®æ–¹ã«æ›¸ã„ã¦ã‚ã£ãŸæ–°ã—ã„ãƒ“ã‚¸ãƒ§ãƒ³ã‚’ã¡ã‚ƒã‚“ã¨ç­”ãˆã¦ã„ã¾ã™ã€‚ã“ã®æƒ…å ±ã¯ OpenAI ã«ã¯ãªã„ãŸã‚ãã¡ã‚“ã¨ RAG ãŒåƒã„ã¦ã„ã‚‹ã¨è¨€ãˆãã†ã§ã™ã€‚

ã¾ãŸã€Œ100å¹´å¾Œã«ç™ºå£²äºˆå®šã®æ–°å•†å“ã€ã¨ã„ã†æƒ…å ±ã¨ã—ã¦å«ã¾ãªã„ã‚ˆã†ãªè³ªå•ã‚’ã™ã‚‹ã¨ã¡ã‚ƒã‚“ã¨ã€Œæƒ…å ±ã‚’æŒã£ã¦ã„ãªã„ã€ã¨è¿”ç­”ã—ã¦ãã‚Œã¾ã™ã€‚ã“ã¡ã‚‰ã‚‚æœŸå¾…é€šã‚Šã§ã™ã­ã€‚

 ğŸ’¡ ã¾ã¨ã‚

LangChain v0.2.5 æ™‚ç‚¹ã§ã® RAG ã‚’ç”¨ã„ãŸ ChatBot ã®å®Ÿè£…ã‚’è¡Œã„ã¾ã—ãŸ
Streamlit ã‚’ç”¨ã„ã¦ãƒ–ãƒ©ã‚¦ã‚¶ã‹ã‚‰ãƒ¦ãƒ¼ã‚¶ãŒã‚¢ã‚¯ã‚»ã‚¹ã§ãã‚‹ã‚ˆã†ã«ã—ã¾ã—ãŸ

ãœã²å‚è€ƒã«ã—ã¦ã¿ã¦ãã ã•ã„ã€‚
yamasaKitcheminformatics, machine learning, board gameCykinso's Tech BlogPublicationã€Œç´°èŒå¢ã®åŠ›ã§äººã€…ã‚’å¥åº·ã«ã€ã‚’ãƒŸãƒƒã‚·ãƒ§ãƒ³ã«æ²ã’ã‚‹ãƒã‚¤ã‚ªãƒ†ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆã‚¢ãƒƒãƒ—ã€Œã‚µã‚¤ã‚­ãƒ³ã‚½ãƒ¼ã€ã®æŠ€è¡“ãƒ–ãƒ­ã‚°ã€‚ ãƒãƒƒã‚¸ã‚’è´ˆã£ã¦è‘—è€…ã‚’å¿œæ´ã—ã‚ˆã†ãƒãƒƒã‚¸ã‚’å—ã‘å–ã£ãŸè‘—è€…ã«ã¯Zennã‹ã‚‰ç¾é‡‘ã‚„Amazonã‚®ãƒ•ãƒˆã‚«ãƒ¼ãƒ‰ãŒé‚„å…ƒã•ã‚Œã¾ã™ã€‚ãƒãƒƒã‚¸ã‚’è´ˆã‚‹DiscussionyamasaKitcheminformatics, machine learning, board gameãƒãƒƒã‚¸ã‚’è´ˆã‚‹ãƒãƒƒã‚¸ã‚’è´ˆã‚‹ã¨ã¯ç›®æ¬¡èƒŒæ™¯ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ãªã©æ–¹æ³•.envãƒ‡ãƒ¼ã‚¿ã‚³ãƒ¼ãƒ‰initialize_vector_storeinitialize_retriverinitialize_chainmainãƒ†ã‚¹ãƒˆğŸ’¡ ã¾ã¨ã‚
sectionchatbotOpenAILangChainLLMRAGtech
 èƒŒæ™¯
LangChain ã¯ OpenAI API ã‚’åˆ©ç”¨ã—è‡ªåˆ†ãŸã¡ãŒã‚„ã‚ŠãŸã„ã“ã¨ã‚’å®Ÿç¾ã™ã‚‹ã“ã¨ã«éå¸¸ã«ä¾¿åˆ©ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã§ã™ãŒãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚¢ãƒƒãƒ—ã«ã‚ˆã£ã¦ã‚¯ãƒ©ã‚¹åã‚„ã‚µãƒ–ãƒ©ã‚¤ãƒ–ãƒ©ãƒªåã®å¤‰æ›´ãŒã‚„ã‚„å¤šãå°‘ã—å¤ã„ Web è¨˜äº‹ã‚’å‚è€ƒã«ã—ã¦ã‚‚ã†ã¾ããƒ¯ãƒ¼ã‚¯ã—ãªã„ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚
ã“ã®è¨˜äº‹ã¯ 2024/6/20 ç¾åœ¨ã® LangChain (ãƒãƒ¼ã‚¸ãƒ§ãƒ³ 0.2.5) ã§ OpenAI API ã‚„ Azure OpenAI API ã‚’å‹•ã‹ã™ä¾‹ã¨ã—ã¦æ®‹ã—ã¦ãŠãã¾ã™ã€‚
åŒã˜ã‚ˆã†ãªã“ã¨ã‚’ã—ã‚ˆã†ã¨ã—ã¦ç§ã®ã‚ˆã†ã«è‹¦æˆ¦ã—ã¦ã„ã‚‹æ–¹ã®åŠ©ã‘ã«ãªã‚Œã°å¹¸ã„ã§ã™ã€‚

 ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ãªã©

pyproject.toml
python = ">=3.12,<3.13"
python-dotenv = "^1.0.1"
chromadb = "0.5.2"
langchain = "0.2.5"
langchain-cli = "0.0.25"
langchain-openai = "0.1.8"
langchain-community = "0.2.5"
langchain-chroma = "0.1.1"
langchainhub = "0.1.20"
streamlit = "1.35.0"

ğŸ’¡ Poetry ã§ Python ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’æŒ‡å®šã™ã‚‹æ™‚ã« ^3.12 ã¨ã™ã‚‹ã¨ lancghain-chroma ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã§ããªããªã‚‹ã®ã§ >=3.12,<3.13 ã¨ã—ã¾ã—ãŸã€‚
(langchain-chroma ã¯ >=3.12,<3.13 ã¨ã„ã†æŒ‡å®šãŒã‚ã‚Šã¾ã™)

 æ–¹æ³•
OpenAI API ã‚’ä½¿ã†å ´åˆã¨ AzureOpenAI API ã‚’ä½¿ã†å ´åˆã¯åŸºæœ¬åŒã˜ã“ã¨ã‚’ã™ã‚‹ã®ã§ã¾ãš OpenAI API ã‚’ä½¿ã†å ´åˆã‚’èª¬æ˜ã—ã€è¨˜äº‹ãŒé•·ããªã£ã¦ã—ã¾ã£ãŸã®ã§ã€å¾Œæ—¥åˆ¥è¨˜äº‹ã«ã¦ AzureOpenAI API ã‚’ä½¿ã†å ´åˆã¯ã©ã®éƒ¨åˆ†ã‚’ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆã—ãŸã‚‰ã‚ˆã„ã®ã‹ã‚’èª¬æ˜ã—ãŸã„ã¨æ€ã„ã¾ã™ã€‚
6/28 è¿½è¨˜) AzureOpenAI API ç‰ˆã®è¨˜äº‹ã‚‚æ›¸ãã¾ã—ãŸã®ã§ã‚ˆã‘ã‚Œã°ãœã²ã©ã†ã
https://zenn.dev/cykinso/articles/b055e33734d06b

 .env
ä»¥ä¸‹ã®ã‚ˆã†ã« .env ã‚’ç”¨æ„ã—ã¾ã™ã€‚
OPENAI_API_KEY=sk-XXXXXXXXXXXXXXXX
OPENAI_API_VERSION=2024-02-01
ã‚‚ã— OPENAI_API_KEY ã‚’ã¾ã å–å¾—ã—ã¦ã„ãªã„å ´åˆã¯ä»¥ä¸‹ã®æ–¹æ³•ã§å–å¾—ã—ã¦ãã ã•ã„ã€‚

 OPENAI_API_KEY
OPENAI_API_KEY ã¯ OpenAI ã® Dashboard ã§ä½œæˆã§ãã¾ã™ã€‚
(èª²é‡‘å¯¾è±¡ãªã®ã§ã”è‡ªèº«ã®è²¬ä»»ã®ã‚‚ã¨ã”åˆ©ç”¨ãã ã•ã„)

ã€Œ+ Create new secret keyã€ ã‚’æŠ¼ã™ã¨ãƒ¢ãƒ¼ãƒ€ãƒ«ãŒé–‹ãã®ã§å¾Œã‹ã‚‰åŒºåˆ¥ã§ãã‚‹ã‚ˆã†ãªåå‰ã‚’ã¤ã‘ã¦ ã€ŒCreate secret keyã€ ã‚’æŠ¼ã—ã¾ã™ã€‚

è¡¨ç¤ºã•ã‚Œã‚‹ API ã‚­ãƒ¼ã‚’ .env ã«ãƒ¡ãƒ¢ã—ã¦ãŠãã¾ã™ã€‚ ã€ŒDoneã€ ã‚’æŠ¼ã™ã¨ã‚‚ã†è¡¨ç¤ºã§ãã¾ã›ã‚“ã€‚


 ãƒ‡ãƒ¼ã‚¿
OpenAI ãŒã¾ã å­¦ç¿’ã—ã¦ã„ãªã•ãã†ãªãƒ‡ãƒ¼ã‚¿ã®ä¾‹ã¨ã—ã¦å¼Šç¤¾ Cykinso ã®ãƒ–ãƒ­ã‚°è¨˜äº‹ã®ã€Œä¼šç¤¾ã®ãƒ“ã‚¸ãƒ§ãƒ³ã‚’è©±ã—ã¦ã„ã‚‹ãƒšãƒ¼ã‚¸ã€ã‚’ä»Šå›ã¯ç”¨ã„ãŸã„ã¨æ€ã„ã¾ã™ã€‚
https://note.com/cykinso/n/n432d5ea70783
ğŸ’¡ ãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆã§å®Ÿè£…ã™ã‚‹å ´åˆã¯ã€å¥½ããªãƒãƒ³ã‚¬ãªã©ã®è©³ç´°ã‚’ãƒ†ã‚­ã‚¹ãƒˆã«ã¾ã¨ã‚ã¦ãƒ‡ãƒ¼ã‚¿ã¨ã™ã‚‹ã¨ãƒ¢ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³ã‚‚ä¸ŠãŒã‚‹ã¨æ€ã„ã¾ã™ã€‚
ã–ã£ã¨æ–‡ç« ã‚’ã‚³ãƒ”ãƒ¼ã—ã¦ä»¥ä¸‹ã®ã‚ˆã†ã«æ•´å½¢ã—ã¾ã—ãŸã€‚

note.txt
ç´°èŒå¢ã‹ã‚‰ã®æ–°ãŸãªæ°—ä»˜ãã‚’é€šã˜ã¦ã€æ–°ãƒ“ã‚¸ãƒ§ãƒ³ã‚’ç­–å®šã—ã¾ã—ãŸï¼
2023å¹´11æœˆã«ã‚µã‚¤ã‚­ãƒ³ã‚½ãƒ¼ã¯10æœŸç›®ã«å…¥ã‚Šã¾ã—ãŸã€‚é«˜é½¢åŒ–ç¤¾ä¼šã«ã‚ˆã‚‹ç¤¾ä¼šä¿éšœã¸ã®ä¸å®‰ãŒå‹Ÿã‚‹ç¾åœ¨ã€ç—…æ°—ã‚’æœªç„¶ã«é˜²ã0æ¬¡äºˆé˜²ã®é‡è¦æ€§ãŒé«˜ã¾ã£ã¦ã„ã¾ã™ã€‚ã€Œç´°èŒå¢ã§äººã€…ã‚’å¥åº·ã«ã€ã¨ã„ã†ãƒŸãƒƒã‚·ãƒ§ãƒ³ã«å‘ã‘ã¦ã€ã‚µã‚¤ã‚­ãƒ³ã‚½ãƒ¼ã¯æ–°ãŸãªãƒ“ã‚¸ãƒ§ãƒ³ã‚’åˆ¶å®šã—ã¾ã—ãŸã€‚
æ–°ã—ã„ãƒ“ã‚¸ãƒ§ãƒ³ã«ã¤ã„ã¦
ãƒ¼ãƒ“ã‚¸ãƒ§ãƒ³å¤‰æ›´ã§å…·ä½“çš„ã«ã©ã®å€‹æ‰€ãŒå¤‰æ›´ã—ãŸã‹ã‚’ã¾ãšã”ç´¹ä»‹ã—ã¾ã™ã€‚
ã“ã¡ã‚‰ãŒã‚µã‚¤ã‚­ãƒ³ã‚½ãƒ¼ã®ãƒŸãƒƒã‚·ãƒ§ãƒ³ï¼ˆMISSIONï¼‰ã€ãƒ“ã‚¸ãƒ§ãƒ³(VISION)ã€ãƒãƒªãƒ¥ãƒ¼(VALUE)ã«ãªã‚Šã¾ã™ã€‚
ç§ãŸã¡ãŒç›®æŒ‡ã—ç¶šã‘ã‚‹ã€Œç´°èŒå¢ã§äººã€…ã‚’å¥åº·ã«ã€ã¨ã„ã†ãƒŸãƒƒã‚·ãƒ§ãƒ³ã¯ãã®ã¾ã¾ã«ã€ãƒ“ã‚¸ãƒ§ãƒ³ã‚’æ–°ã—ãå¤‰æ›´è‡´ã—ã¾ã—ãŸã€‚

ï¼œã“ã‚Œã¾ã§ã®ãƒ“ã‚¸ãƒ§ãƒ³ï¼
èŒå¢ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã€Œæ¬¡ä¸–ä»£ã®ãƒ©ã‚¤ãƒ•ã‚¹ã‚¿ã‚¤ãƒ«ã€ã‚’æä¾›ã™ã‚‹ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã«ãªã‚‹

ï¼œæ–°ã—ã„ãƒ“ã‚¸ãƒ§ãƒ³ï¼
ç´°èŒå¢ã‹ã‚‰ã®æ–°ãŸãªæ°—ä»˜ãã‚’é€šã˜ã¦
ãƒ’ãƒˆã€ç¤¾ä¼šã€åœ°çƒç’°å¢ƒã‚’å¥åº·ã«ã™ã‚‹ã‚¨ã‚³ã‚·ã‚¹ãƒ†ãƒ ã‚’å®Ÿç¾ã™ã‚‹
æ–°ã—ã„ãƒ“ã‚¸ãƒ§ãƒ³ã§ã¯ã€ã‚µã‚¤ã‚­ãƒ³ã‚½ãƒ¼ãŒå½±éŸ¿ã‚’ä¸ãˆã¦ã„ããŸã„ç¯„å›²ã‚‚ã“ã‚Œã¾ã§ã‚ˆã‚Šã•ã‚‰ã«å¤§ãããªã£ãŸã“ã¨ãŒåˆ†ã‹ã‚Šã¾ã™ã€‚

ä»Šå›ã®ãƒ“ã‚¸ãƒ§ãƒ³å¤‰æ›´ã‚’é€šã—ã¦ã€ã‚µã‚¤ã‚­ãƒ³ã‚½ãƒ¼ãŒã©ã‚“ãªä¾¡å€¤ç™ºæ®ã‚’ç›®æŒ‡ã—ã¦ã„ãã®ã‹ã€ãã‚Œã«ä¼´ã„äº‹æ¥­é¢ã§ã¯ã©ã‚“ãªæŒ‘æˆ¦ã‚’ã—ã¦ã„ãã®ã‹ã‚’ã€ä»£è¡¨å–ç· å½¹CEOã®æ²¢äº•ã•ã‚“ã«èã„ã¦ãã¾ã—ãŸï¼

...(ä»¥ä¸‹ç•¥)


 ã‚³ãƒ¼ãƒ‰
ç¶šã‘ã¦ã‚³ãƒ¼ãƒ‰ã‚’å®Ÿè£…ã—ã¾ã™ã€‚
ä»Šå›ã¯ RAG ã¨ã—ã¦å¤–éƒ¨ã®æƒ…å ±ã‚’å‚ç…§ã—ã¤ã¤å›ç­”ã™ã‚‹ ChatBot ã‚’å®Ÿè£…ã—ã¦ã¿ã¾ã™ã€‚
ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã¨ã—ã¦ streamlit ã‚’ç”¨ã„ã¾ã™ã€‚
å…ˆã«ã‚³ãƒ¼ãƒ‰å…¨ä½“ã‚’ç¤ºã™ã¨ä»¥ä¸‹ã®ã‚ˆã†ã«ãªã‚Šã¾ã™ã€‚
(streamlit ã®ã‚³ãƒ¼ãƒ‰ã®ãƒ™ãƒ¼ã‚¹ã¨ã—ã¦ä»¥ä¸‹ã®è¨˜äº‹ã‚’å‚è€ƒã«ã•ã›ã¦ã„ãŸã ãã¾ã—ãŸã€‚ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™)
https://tech-lab.sios.jp/archives/41574

chatbot.py
from pathlib import Path

import streamlit as st
from dotenv import load_dotenv
from langchain import hub
from langchain.schema import AIMessage, HumanMessage
from langchain_chroma import Chroma
from langchain_community.document_loaders import TextLoader
from langchain_core.runnables import RunnablePassthrough, RunnableSequence
from langchain_core.vectorstores import VectorStoreRetriever
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_text_splitters import RecursiveCharacterTextSplitter

load_dotenv()


def initialize_vector_store() -> Chroma:
    """VectorStoreã®åˆæœŸåŒ–."""
    embeddings = OpenAIEmbeddings()

    vector_store_path = "./resources/note.db"
    if Path(vector_store_path).exists():
        vector_store = Chroma(embedding_function=embeddings, persist_directory=vector_store_path)
    else:
        loader = TextLoader("resources/note.txt")
        docs = loader.load()

        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
        splits = text_splitter.split_documents(docs)

        vector_store = Chroma.from_documents(
            documents=splits, embedding=embeddings, persist_directory=vector_store_path
        )

    return vector_store


def initialize_retriever() -> VectorStoreRetriever:
    """Retrieverã®åˆæœŸåŒ–."""
    vector_store = initialize_vector_store()
    return vector_store.as_retriever()


def initialize_chain() -> RunnableSequence:
    """Langchainã®åˆæœŸåŒ–."""
    prompt = hub.pull("rlm/rag-prompt")
    llm = ChatOpenAI()
    retriever = initialize_retriever()
    chain = (
        {"context": retriever, "question": RunnablePassthrough()} | prompt | llm
    )
    return chain


def main() -> None:
    """ChatGPTã‚’ä½¿ã£ãŸãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã®ãƒ¡ã‚¤ãƒ³é–¢æ•°."""
    chain = initialize_chain()

    # ãƒšãƒ¼ã‚¸ã®è¨­å®š
    st.set_page_config(page_title="RAG ChatGPT")
    st.header("RAG ChatGPT")

    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®åˆæœŸåŒ–
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ã‚’ç›£è¦–
    if user_input := st.chat_input("èããŸã„ã“ã¨ã‚’å…¥åŠ›ã—ã¦ã­ï¼"):
        st.session_state.messages.append(HumanMessage(content=user_input))
        with st.spinner("GPT is typing ..."):
            response = chain.invoke(user_input)
        st.session_state.messages.append(AIMessage(content=response.content))

    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®è¡¨ç¤º
    messages = st.session_state.get("messages", [])
    for message in messages:
        if isinstance(message, AIMessage):
            with st.chat_message("assistant"):
                st.markdown(message.content)
        elif isinstance(message, HumanMessage):
            with st.chat_message("user"):
                st.markdown(message.content)
        else:
            st.write(f"System message: {message.content}")


if __name__ == "__main__":
    main()

ã‚³ãƒ¼ãƒ‰ã®å„éƒ¨åˆ†ã‚’èª¬æ˜ã—ã¦ã„ãã¾ã™ã€‚

 initialize_vector_store
def initialize_vector_store() -> Chroma:
    """VectorStoreã®åˆæœŸåŒ–."""
    embeddings = OpenAIEmbeddings()

    vector_store_path = "./resources/note.db"
    if Path(vector_store_path).exists():
        vector_store = Chroma(embedding_function=embeddings, persist_directory=vector_store_path)
    else:
        loader = TextLoader("resources/note.txt")
        docs = loader.load()

        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
        splits = text_splitter.split_documents(docs)

        vector_store = Chroma.from_documents(
            documents=splits, embedding=embeddings, persist_directory=vector_store_path
        )

    return vector_store
Vector store ã¨ã¯æƒ…å ±ã¨ã—ã¦èª­ã¿è¾¼ã¾ã›ã¦ã„ã‚‹ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’é©åˆ‡ãªé•·ã•ã«åˆ†å‰²ã—(ãƒãƒ£ãƒ³ã‚¯ã¨å‘¼ã°ã‚Œã¾ã™) ã™ãã«å–ã‚Šå‡ºã›ã‚‹ã‚ˆã†ã«ä¿å­˜ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ã‚ˆã†ãªã‚‚ã®ã§ã™ã€‚
Embeddings ã¨å‘¼ã°ã‚Œã‚‹ãƒ¢ãƒ‡ãƒ«ã§ãƒ†ã‚­ã‚¹ãƒˆã¯æ•°å€¤æƒ…å ±ã®ãƒ™ã‚¯ãƒˆãƒ«ã«ä¿å­˜ã•ã‚Œã¾ã™ã€‚ãã®ä½œæ¥­ã‚’è¡Œã†ãŸã‚ã« OpenAI API ãŒå¿…è¦ã«ãªã£ã¦ã„ã‚‹ãŸã‚é–¢æ•°ã®æœ€åˆã§ OpenAIEmbeddings ã‚’å‘¼ã³å‡ºã—ã¦ã„ã¾ã™ã€‚
ç¶šã‘ã¦ Vector store ã¨ã—ã¦ä¿å­˜ã•ã‚Œã¦ã„ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã™ã§ã«å­˜åœ¨ã—ã¦ã„ãªã„ã‹ã‚’èª¿ã¹ã¦ã„ã¾ã™ã€‚åŸºæœ¬çš„ã«ãƒ‡ãƒ¼ã‚¿ã‚„ãƒ¢ãƒ‡ãƒ«ãŒã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆã•ã‚Œãªã„é™ã‚Š Vector store ã®ãƒ‡ãƒ¼ã‚¿ã¯ã¾ã£ãŸãåŒã˜ã«ãªã‚‹ãŸã‚ã€æ¯å›å®Ÿè¡Œã—ã¦ã—ã¾ã†ã¨æ™‚é–“ã‚‚ API ã®åˆ©ç”¨æ–™é‡‘ã‚‚ç„¡é§„ã«ãªã£ã¦ã—ã¾ã„ã¾ã™ã€‚
ãã“ã§

ã¾ã å­˜åœ¨ã—ã¦ã„ãªã„å ´åˆï¼š æ–°è¦ä½œæˆ
ã™ã§ã«å­˜åœ¨ã—ã¦ã„ã‚‹å ´åˆï¼š ä¿å­˜ã—ã¦ã„ã‚‹ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’èª­ã¿è¾¼ã‚€

ã¨ã—ã¦ã„ã¾ã™ã€‚
ãªãŠå­˜åœ¨ã—ã¦ã„ã‚‹å ´åˆ Chroma ã‚¯ãƒ©ã‚¹ã®å¼•æ•° embedding_function ã« embeddings ã‚’æŒ‡å®šã—ã¦ã„ã¾ã™ãŒã€ã“ã‚Œã¯ã‚¯ã‚¨ãƒªã¨ã—ã¦ã‚ãŸãˆã‚‰ã‚Œã‚‹ãƒ¦ãƒ¼ã‚¶ã®è³ªå•ã¨ Vector store ã«ä¿å­˜ã•ã‚Œã¦ã„ã‚‹ãƒ‡ãƒ¼ã‚¿ã¨ã®é–“ã®é–¢é€£æ€§ã‚’èª¿ã¹ã‚‹ãŸã‚ã«ã€ã‚¯ã‚¨ãƒªã‚‚ Embeddings ã§ãƒ™ã‚¯ãƒˆãƒ«ã«å¤‰æ›ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã‹ã‚‰ã§ã™ã€‚

 initialize_retriver
def initialize_retriever() -> VectorStoreRetriever:
    """Retrieverã®åˆæœŸåŒ–."""
    vector_store = initialize_vector_store()
    return vector_store.as_retriever()
ã“ã¡ã‚‰ã§ã¯ã€å…ˆã»ã©ä½œæˆã—ãŸ(ã‚ã‚‹ã„ã¯ã™ã§ã«ã‚ã‚‹ã‚‚ã®ã‚’èª­ã¿è¾¼ã‚“ã ) vector_store ã‚’ retriever ã«å¤‰æ›ã—ã¦ã„ã¾ã™ã€‚ã“ã¡ã‚‰ã® retriever ã“ã®å¾Œã€ Vectore store ã‹ã‚‰æƒ…å ±ã‚’å–ã‚Šå‡ºã™ã®ã«åˆ©ç”¨ã•ã‚Œã¾ã™ã€‚

 initialize_chain
def initialize_chain() -> RunnableSequence:
    """Langchainã®åˆæœŸåŒ–."""
    prompt = hub.pull("rlm/rag-prompt")
    llm = ChatOpenAI()
    retriever = initialize_retriever()
    chain = (
        {"context": retriever, "question": RunnablePassthrough()} | prompt | llm
    )
    return chain
ã“ã¡ã‚‰ã§ã¯ retriever ã®æƒ…å ±ã‚’ LLM ã§åˆ©ç”¨ã§ãã‚‹ã‚ˆã†ã« chain ã¨å‘¼ã°ã‚Œã‚‹æ¦‚å¿µã‚’åˆ©ç”¨ã—ã¦ãŠã‚Šã¾ã™ã€‚
ã‚ˆããƒ¡ã‚½ãƒƒãƒ‰ãƒã‚§ãƒ¼ãƒ³ã¨ã„ã†è¨€è‘‰ãŒãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°è¨€èªã§ã¯ä½¿ã‚ã‚Œã¦ã„ã¾ã™ã€‚
ä¾‹ãˆã° Python ã® Pandas ã§ã¯
import pandas as pd

# ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
data = {
    'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Edward', 'Frank'],
    'Age': [24, 27, 22, 32, 29, 24],
    'City': ['New York', 'Los Angeles', 'New York', 'Chicago', 'Los Angeles', 'New York'],
    'Score': [85, 90, 88, 92, 95, 70]
}

df = pd.DataFrame(data)

# ãƒ¡ã‚½ãƒƒãƒ‰ãƒã‚§ãƒ¼ãƒ³ã‚’ä½¿ã£ãŸãƒ‡ãƒ¼ã‚¿å¤‰æ›
result = (df
          .query('Age > 25')                     # å¹´é½¢ãŒ25ä»¥ä¸Šã®è¡Œã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
          .groupby('City')                       # éƒ½å¸‚ã”ã¨ã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
          .agg({'Score': 'mean'})                # ã‚¹ã‚³ã‚¢ã®å¹³å‡ã‚’è¨ˆç®—
          .rename(columns={'Score': 'Average Score'})  # åˆ—åã‚’å¤‰æ›´
          .sort_values(by='Average Score', ascending=False)  # å¹³å‡ã‚¹ã‚³ã‚¢ã§ä¸¦ã¹æ›¿ãˆ
          .reset_index()                         # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ãƒªã‚»ãƒƒãƒˆ
         )

print(result)
ã¨ã„ã†ã‚ˆã†ã«ãƒ¡ã‚½ãƒƒãƒ‰ã®è¿”ã‚Šå€¤ã‚’æ¬¡ã®ãƒ¡ã‚½ãƒƒãƒ‰ã¸ã¨ãƒã‚±ãƒ„ãƒªãƒ¬ãƒ¼ã®ã‚ˆã†ã«ã¤ãªã„ã§è¡Œãå‡¦ç†ã•ã›ã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚ã“ã‚Œã‚’ãƒ¡ã‚½ãƒƒãƒ‰ãƒã‚§ãƒ¼ãƒ³ã¨ã„ã„ã¾ã™ã€‚
LangChain ã§ã‚‚ã“ã®ãƒã‚±ãƒ„ãƒªãƒ¬ãƒ¼ã‚’è¡Œã„ã€ã©ã®ã‚ˆã†ã«ãƒ¦ãƒ¼ã‚¶ã®è³ªå•ã«ç­”ãˆã‚‹ã‹ã®ãƒ«ãƒ¼ãƒ«ã‚’æ±ºã‚ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚
LangChain ã®å ´åˆã¯æ˜”ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã§ã¯é–¢æ•°ã®è¿”ã‚Šå€¤ã‚’ã•ã‚‰ã«é–¢æ•°ã®å¼•æ•°ã«ã™ã‚‹ã¨è¨€ã†ã“ã¨ã‚’ç¹°ã‚Šè¿”ã—ã¦ãƒã‚±ãƒ„ãƒªãƒ¬ãƒ¼ã‚’è¡Œã£ã¦ã„ã¾ã—ãŸãŒã€ä»Šã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ 0.2.5 ã§ã¯ä»¥ä¸‹ã®ã‚ˆã†ã« | ã‚’åˆ©ç”¨ã—ãƒã‚§ãƒ¼ãƒ³ã‚’ç¤ºã™ã“ã¨ãŒæ¨å¥¨ã•ã‚Œã¦ã„ã¾ã™ã€‚
    chain = (
        {"context": retriever, "question": RunnablePassthrough()} | prompt | llm
    )
ä»Šå›ã®å ´åˆ

{"context": retriever, "question": RunnablePassthrough()}
prompt
llm

ã¨ã„ã†é †ç•ªã§ãƒã‚§ãƒ¼ãƒ³ãŒã¤ãªãŒã£ã¦ã„ã¾ã™ã€‚
ãƒã‚§ãƒ¼ãƒ³ã®å…ˆé ­ãŒãªãœè¾æ›¸ã§ã‚ã‚‹ã‹ã¯ã€2ç•ªç›®ã® prompt ã®èª¬æ˜ã‚’èã„ã¦ã‚‚ã‚‰ãˆã‚Œã°ã‚ã‹ã‚‹ã¨æ€ã„ã¾ã™ã€‚
    prompt = hub.pull("rlm/rag-prompt")
prompt ã¯ LLM ã«ã©ã®ã‚ˆã†ãªè³ªå•ã‚„ä¾é ¼ã‚’ã™ã‚‹ã®ã‹ã‚’æ±ºã‚ã‚‹éƒ¨åˆ†ã§ã™ã€‚ä»Šå›ã¯ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ(å¤‰æ•°åã‚’æŒ‡ã—ã¦ã„ãªã„å ´åˆã‚«ã‚¿ã‚«ãƒŠè¡¨è¨˜ã¨ã—ã¾ã™)ã‚’æœ‰å¿—ã®æ–¹ãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ä»–ã®äººãŒåˆ©ç”¨ã§ãã‚‹ã‚ˆã†ã«ã—ã¦ãã‚Œã¦ã„ã‚‹ã‚µã‚¤ãƒˆ LangChain Hub ã‹ã‚‰ â­ ãŒå¤šã„ã‚‚ã®ã‚’ãŠå€Ÿã‚Šã—ã¦ãã¾ã—ãŸã€‚ã‚‚ã¡ã‚ã‚“è‡ªä½œã—ã¦ã‚‚ã‚‰ã£ã¦ã‚‚OKã§ã™ã€‚
https://smith.langchain.com/hub/rlm/rag-prompt
ãŠå€Ÿã‚Šã—ãŸ rag-prompt ã§ã¯ä»¥ä¸‹ã®ã‚ˆã†ã«ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒå®šç¾©ã•ã‚Œã¦ã„ã¾ã™ã€‚
You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.
Question: {question} 
Context: {context} 
Answer:
ç°¡å˜ã«æ—¥æœ¬èªã«è¨³ã™ã¨ ã€Œ context ã®æƒ…å ±ã®ã¿ã‚’ä½¿ã£ã¦ question ã«ç­”ãˆã‚‹ã‚ˆã†ã« Answer ã‚’è€ƒãˆãªã•ã„ã€‚ç­”ãˆã‚‰ã‚Œãªã„ãªã‚‰ã‚ã‹ã‚‰ãªã„ã¨ç­”ãˆãªã•ã„ã€‚ã€ ã¨ãªã‚Šã¾ã™ã€‚ context ã®æƒ…å ±ã®ã¿ã‚’ç”¨ã„ã‚‹ã‚ˆã†æŒ‡å®šã™ã‚‹ã“ã¨ã§ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³ã‚’é˜²ãåŠ¹æœãŒã‚ã‚Šã¾ã™ (ãŸã ã—ï¼‘ï¼ï¼ï¼…é˜²ãã¨ã¯æ–­è¨€ã§ããªã„ã§ã™)
ã“ã¡ã‚‰ã® question éƒ¨åˆ†ã«ãƒ¦ãƒ¼ã‚¶ã®ã‚¯ã‚¨ãƒªãŒã€ context éƒ¨åˆ†ã« retriever ã‚’æŒ‡å®šã—ã¦ prompt ã‚’å®Ÿè¡Œã›ã‚ˆã¨ã—ã¦ã„ã‚‹ã®ãŒãƒã‚§ãƒ¼ãƒ³ã® {"context": retriever, "question": RunnablePassthrough()} | prompt ã®éƒ¨åˆ†ã§ã™ã€‚
æœ€å¾Œã«å®Œæˆã—ãŸ prompt ã‚’ llm ã«æ¸¡ã—ãªã•ã„ã¨æŒ‡å®šã—ã¦ã„ã‚‹ã®ãŒ prompt | llm ã®éƒ¨åˆ†ã§ã™ã€‚
ã“ã®ãƒ¡ã‚½ãƒƒãƒ‰ãƒã‚§ãƒ¼ãƒ³ã‚’ã¾ã¨ã‚ãŸ chain ã¨ã„ã†å¤‰æ•°ã¯ invoke ãƒ¡ã‚½ãƒƒãƒ‰ã‚’æŒã£ã¦ãŠã‚Šã€ã“ã®ãƒ¡ã‚½ãƒƒãƒ‰ã«è³ªå•ã‚’æŠ•ã’ã‚‹ã¨ãã‚ŒãŒ question ã«å…¥ã‚Šãƒã‚§ãƒ¼ãƒ³ãŒå‰ã‹ã‚‰é †ç•ªã«å®Ÿè¡Œã•ã‚Œã¾ã™ã€‚
ä»¥ä¸Šã®ã‚ˆã†ã«å®šç¾©ã™ã‚‹ã“ã¨ã§ RAG ã¨ã—ã¦å¤–éƒ¨ã®æƒ…å ±ã‚’å‚ç…§ã—ã¤ã¤å›ç­”ã™ã‚‹ ChatBot ã‚’å®Ÿè£…ã§ãã¾ã—ãŸã€‚

 main
def main() -> None:
    """ChatGPTã‚’ä½¿ã£ãŸãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã®ãƒ¡ã‚¤ãƒ³é–¢æ•°."""
    chain = initialize_chain()

    # ãƒšãƒ¼ã‚¸ã®è¨­å®š
    st.set_page_config(page_title="RAG ChatGPT")
    st.image(img, use_column_width=False)
    st.header("RAG ChatGPT")

    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®åˆæœŸåŒ–
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ã‚’ç›£è¦–
    if user_input := st.chat_input("èããŸã„ã“ã¨ã‚’å…¥åŠ›ã—ã¦ã­ï¼"):
        st.session_state.messages.append(HumanMessage(content=user_input))
        with st.spinner("GPT is typing ..."):
            response = chain.invoke(user_input)
        st.session_state.messages.append(AIMessage(content=response.content))

    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®è¡¨ç¤º
    messages = st.session_state.get("messages", [])
    for message in messages:
        if isinstance(message, AIMessage):
            with st.chat_message("assistant"):
                st.markdown(message.content)
        elif isinstance(message, HumanMessage):
            with st.chat_message("user"):
                st.markdown(message.content)
        else:
            st.write(f"System message: {message.content}")
æœ€å¾Œã« main é–¢æ•°ã§ã™ã€‚ã“ã¡ã‚‰ã¯ LangChain ã®å®Ÿè£…ã¨ã„ã†ã‚ˆã‚Šã¯ Streamlit ã‚’åˆ©ç”¨ã—ãŸãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰éƒ¨åˆ†ã®å®Ÿè£…ã«ãªã‚Šã¾ã™ã€‚
ã‚­ãƒ¼ã¨ãªã‚‹ç‚¹ã ã‘è§£èª¬ã™ã‚‹ã¨

ãƒ¦ãƒ¼ã‚¶ã¨ ChatBot ã®ä¼šè©±ã¯ messages ã«ä¿å­˜ã•ã‚Œã¦ã„ã¾ã™ã€‚ä»¥ä¸‹ã®ã‚³ãƒ¼ãƒ‰ã‚’è¦‹ã‚‹ã¨ã‚ã‹ã‚‹ã‚ˆã†ã«ãƒ¦ãƒ¼ã‚¶ã‹ã‚‰ã®è³ªå•ã¨ ChatBot ã®è¿”ç­”ã¯ã©ã¡ã‚‰ã‚‚ messages ã« append ã•ã‚Œã¦ã„ã¾ã™ã€‚

    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®åˆæœŸåŒ–
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ã‚’ç›£è¦–
    if user_input := st.chat_input("èããŸã„ã“ã¨ã‚’å…¥åŠ›ã—ã¦ã­ï¼"):
        st.session_state.messages.append(HumanMessage(content=user_input))
        with st.spinner("GPT is typing ..."):
            response = chain.invoke(user_input)
        st.session_state.messages.append(AIMessage(content=response.content))

ãƒ¦ãƒ¼ã‚¶ã‹ã‚‰ã®è³ªå•ã¸ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã¯å…ˆã»ã©å®šç¾©ã—ãŸ chain ã® invoke ãƒ¡ã‚½ãƒƒãƒ‰ã‚’ç”¨ã„ã¦ä½œã‚‰ã‚Œã¦ã„ã¾ã™ã€‚

        with st.spinner("GPT is typing ..."):
            response = chain.invoke(user_input)
        st.session_state.messages.append(AIMessage(content=response.content))
ã¨ã„ã†ç‚¹ãŒã‚ã’ã‚‰ã‚Œã¾ã™ã€‚

 ãƒ†ã‚¹ãƒˆ
ãã‚Œã§ã¯å®Ÿè£…ã—ãŸã‚‚ã®ã‚’å‹•ã‹ã—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚
> streamlit run chatbot.py

Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.


  You can now view your Streamlit app in your browser.

  Local URL: http://localhost:8501
  Network URL: http://10.200.0.4:8501
  External URL: http://13.73.233.61:8501
http://localhost:8501 ã¸ãƒ–ãƒ©ã‚¦ã‚¶ã‹ã‚‰ã‚¢ã‚¯ã‚»ã‚¹ã—ã€è³ªå•ã—ã¦ã¿ã¾ã™ã€‚

ç¾æ™‚ç‚¹ã§ã® note.txt ã®å…ˆé ­ã®æ–¹ã«æ›¸ã„ã¦ã‚ã£ãŸæ–°ã—ã„ãƒ“ã‚¸ãƒ§ãƒ³ã‚’ã¡ã‚ƒã‚“ã¨ç­”ãˆã¦ã„ã¾ã™ã€‚ã“ã®æƒ…å ±ã¯ OpenAI ã«ã¯ãªã„ãŸã‚ãã¡ã‚“ã¨ RAG ãŒåƒã„ã¦ã„ã‚‹ã¨è¨€ãˆãã†ã§ã™ã€‚

ã¾ãŸã€Œ100å¹´å¾Œã«ç™ºå£²äºˆå®šã®æ–°å•†å“ã€ã¨ã„ã†æƒ…å ±ã¨ã—ã¦å«ã¾ãªã„ã‚ˆã†ãªè³ªå•ã‚’ã™ã‚‹ã¨ã¡ã‚ƒã‚“ã¨ã€Œæƒ…å ±ã‚’æŒã£ã¦ã„ãªã„ã€ã¨è¿”ç­”ã—ã¦ãã‚Œã¾ã™ã€‚ã“ã¡ã‚‰ã‚‚æœŸå¾…é€šã‚Šã§ã™ã­ã€‚

 ğŸ’¡ ã¾ã¨ã‚

LangChain v0.2.5 æ™‚ç‚¹ã§ã® RAG ã‚’ç”¨ã„ãŸ ChatBot ã®å®Ÿè£…ã‚’è¡Œã„ã¾ã—ãŸ
Streamlit ã‚’ç”¨ã„ã¦ãƒ–ãƒ©ã‚¦ã‚¶ã‹ã‚‰ãƒ¦ãƒ¼ã‚¶ãŒã‚¢ã‚¯ã‚»ã‚¹ã§ãã‚‹ã‚ˆã†ã«ã—ã¾ã—ãŸ

ãœã²å‚è€ƒã«ã—ã¦ã¿ã¦ãã ã•ã„ã€‚
yamasaKitcheminformatics, machine learning, board gameCykinso's Tech BlogPublicationã€Œç´°èŒå¢ã®åŠ›ã§äººã€…ã‚’å¥åº·ã«ã€ã‚’ãƒŸãƒƒã‚·ãƒ§ãƒ³ã«æ²ã’ã‚‹ãƒã‚¤ã‚ªãƒ†ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆã‚¢ãƒƒãƒ—ã€Œã‚µã‚¤ã‚­ãƒ³ã‚½ãƒ¼ã€ã®æŠ€è¡“ãƒ–ãƒ­ã‚°ã€‚ ãƒãƒƒã‚¸ã‚’è´ˆã£ã¦è‘—è€…ã‚’å¿œæ´ã—ã‚ˆã†ãƒãƒƒã‚¸ã‚’å—ã‘å–ã£ãŸè‘—è€…ã«ã¯Zennã‹ã‚‰ç¾é‡‘ã‚„Amazonã‚®ãƒ•ãƒˆã‚«ãƒ¼ãƒ‰ãŒé‚„å…ƒã•ã‚Œã¾ã™ã€‚ãƒãƒƒã‚¸ã‚’è´ˆã‚‹Discussion
divchatbotOpenAILangChainLLMRAGtech
 èƒŒæ™¯
LangChain ã¯ OpenAI API ã‚’åˆ©ç”¨ã—è‡ªåˆ†ãŸã¡ãŒã‚„ã‚ŠãŸã„ã“ã¨ã‚’å®Ÿç¾ã™ã‚‹ã“ã¨ã«éå¸¸ã«ä¾¿åˆ©ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã§ã™ãŒãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚¢ãƒƒãƒ—ã«ã‚ˆã£ã¦ã‚¯ãƒ©ã‚¹åã‚„ã‚µãƒ–ãƒ©ã‚¤ãƒ–ãƒ©ãƒªåã®å¤‰æ›´ãŒã‚„ã‚„å¤šãå°‘ã—å¤ã„ Web è¨˜äº‹ã‚’å‚è€ƒã«ã—ã¦ã‚‚ã†ã¾ããƒ¯ãƒ¼ã‚¯ã—ãªã„ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚
ã“ã®è¨˜äº‹ã¯ 2024/6/20 ç¾åœ¨ã® LangChain (ãƒãƒ¼ã‚¸ãƒ§ãƒ³ 0.2.5) ã§ OpenAI API ã‚„ Azure OpenAI API ã‚’å‹•ã‹ã™ä¾‹ã¨ã—ã¦æ®‹ã—ã¦ãŠãã¾ã™ã€‚
åŒã˜ã‚ˆã†ãªã“ã¨ã‚’ã—ã‚ˆã†ã¨ã—ã¦ç§ã®ã‚ˆã†ã«è‹¦æˆ¦ã—ã¦ã„ã‚‹æ–¹ã®åŠ©ã‘ã«ãªã‚Œã°å¹¸ã„ã§ã™ã€‚

 ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ãªã©

pyproject.toml
python = ">=3.12,<3.13"
python-dotenv = "^1.0.1"
chromadb = "0.5.2"
langchain = "0.2.5"
langchain-cli = "0.0.25"
langchain-openai = "0.1.8"
langchain-community = "0.2.5"
langchain-chroma = "0.1.1"
langchainhub = "0.1.20"
streamlit = "1.35.0"

ğŸ’¡ Poetry ã§ Python ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’æŒ‡å®šã™ã‚‹æ™‚ã« ^3.12 ã¨ã™ã‚‹ã¨ lancghain-chroma ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã§ããªããªã‚‹ã®ã§ >=3.12,<3.13 ã¨ã—ã¾ã—ãŸã€‚
(langchain-chroma ã¯ >=3.12,<3.13 ã¨ã„ã†æŒ‡å®šãŒã‚ã‚Šã¾ã™)

 æ–¹æ³•
OpenAI API ã‚’ä½¿ã†å ´åˆã¨ AzureOpenAI API ã‚’ä½¿ã†å ´åˆã¯åŸºæœ¬åŒã˜ã“ã¨ã‚’ã™ã‚‹ã®ã§ã¾ãš OpenAI API ã‚’ä½¿ã†å ´åˆã‚’èª¬æ˜ã—ã€è¨˜äº‹ãŒé•·ããªã£ã¦ã—ã¾ã£ãŸã®ã§ã€å¾Œæ—¥åˆ¥è¨˜äº‹ã«ã¦ AzureOpenAI API ã‚’ä½¿ã†å ´åˆã¯ã©ã®éƒ¨åˆ†ã‚’ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆã—ãŸã‚‰ã‚ˆã„ã®ã‹ã‚’èª¬æ˜ã—ãŸã„ã¨æ€ã„ã¾ã™ã€‚
6/28 è¿½è¨˜) AzureOpenAI API ç‰ˆã®è¨˜äº‹ã‚‚æ›¸ãã¾ã—ãŸã®ã§ã‚ˆã‘ã‚Œã°ãœã²ã©ã†ã
https://zenn.dev/cykinso/articles/b055e33734d06b

 .env
ä»¥ä¸‹ã®ã‚ˆã†ã« .env ã‚’ç”¨æ„ã—ã¾ã™ã€‚
OPENAI_API_KEY=sk-XXXXXXXXXXXXXXXX
OPENAI_API_VERSION=2024-02-01
ã‚‚ã— OPENAI_API_KEY ã‚’ã¾ã å–å¾—ã—ã¦ã„ãªã„å ´åˆã¯ä»¥ä¸‹ã®æ–¹æ³•ã§å–å¾—ã—ã¦ãã ã•ã„ã€‚

 OPENAI_API_KEY
OPENAI_API_KEY ã¯ OpenAI ã® Dashboard ã§ä½œæˆã§ãã¾ã™ã€‚
(èª²é‡‘å¯¾è±¡ãªã®ã§ã”è‡ªèº«ã®è²¬ä»»ã®ã‚‚ã¨ã”åˆ©ç”¨ãã ã•ã„)

ã€Œ+ Create new secret keyã€ ã‚’æŠ¼ã™ã¨ãƒ¢ãƒ¼ãƒ€ãƒ«ãŒé–‹ãã®ã§å¾Œã‹ã‚‰åŒºåˆ¥ã§ãã‚‹ã‚ˆã†ãªåå‰ã‚’ã¤ã‘ã¦ ã€ŒCreate secret keyã€ ã‚’æŠ¼ã—ã¾ã™ã€‚

è¡¨ç¤ºã•ã‚Œã‚‹ API ã‚­ãƒ¼ã‚’ .env ã«ãƒ¡ãƒ¢ã—ã¦ãŠãã¾ã™ã€‚ ã€ŒDoneã€ ã‚’æŠ¼ã™ã¨ã‚‚ã†è¡¨ç¤ºã§ãã¾ã›ã‚“ã€‚


 ãƒ‡ãƒ¼ã‚¿
OpenAI ãŒã¾ã å­¦ç¿’ã—ã¦ã„ãªã•ãã†ãªãƒ‡ãƒ¼ã‚¿ã®ä¾‹ã¨ã—ã¦å¼Šç¤¾ Cykinso ã®ãƒ–ãƒ­ã‚°è¨˜äº‹ã®ã€Œä¼šç¤¾ã®ãƒ“ã‚¸ãƒ§ãƒ³ã‚’è©±ã—ã¦ã„ã‚‹ãƒšãƒ¼ã‚¸ã€ã‚’ä»Šå›ã¯ç”¨ã„ãŸã„ã¨æ€ã„ã¾ã™ã€‚
https://note.com/cykinso/n/n432d5ea70783
ğŸ’¡ ãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆã§å®Ÿè£…ã™ã‚‹å ´åˆã¯ã€å¥½ããªãƒãƒ³ã‚¬ãªã©ã®è©³ç´°ã‚’ãƒ†ã‚­ã‚¹ãƒˆã«ã¾ã¨ã‚ã¦ãƒ‡ãƒ¼ã‚¿ã¨ã™ã‚‹ã¨ãƒ¢ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³ã‚‚ä¸ŠãŒã‚‹ã¨æ€ã„ã¾ã™ã€‚
ã–ã£ã¨æ–‡ç« ã‚’ã‚³ãƒ”ãƒ¼ã—ã¦ä»¥ä¸‹ã®ã‚ˆã†ã«æ•´å½¢ã—ã¾ã—ãŸã€‚

note.txt
ç´°èŒå¢ã‹ã‚‰ã®æ–°ãŸãªæ°—ä»˜ãã‚’é€šã˜ã¦ã€æ–°ãƒ“ã‚¸ãƒ§ãƒ³ã‚’ç­–å®šã—ã¾ã—ãŸï¼
2023å¹´11æœˆã«ã‚µã‚¤ã‚­ãƒ³ã‚½ãƒ¼ã¯10æœŸç›®ã«å…¥ã‚Šã¾ã—ãŸã€‚é«˜é½¢åŒ–ç¤¾ä¼šã«ã‚ˆã‚‹ç¤¾ä¼šä¿éšœã¸ã®ä¸å®‰ãŒå‹Ÿã‚‹ç¾åœ¨ã€ç—…æ°—ã‚’æœªç„¶ã«é˜²ã0æ¬¡äºˆé˜²ã®é‡è¦æ€§ãŒé«˜ã¾ã£ã¦ã„ã¾ã™ã€‚ã€Œç´°èŒå¢ã§äººã€…ã‚’å¥åº·ã«ã€ã¨ã„ã†ãƒŸãƒƒã‚·ãƒ§ãƒ³ã«å‘ã‘ã¦ã€ã‚µã‚¤ã‚­ãƒ³ã‚½ãƒ¼ã¯æ–°ãŸãªãƒ“ã‚¸ãƒ§ãƒ³ã‚’åˆ¶å®šã—ã¾ã—ãŸã€‚
æ–°ã—ã„ãƒ“ã‚¸ãƒ§ãƒ³ã«ã¤ã„ã¦
ãƒ¼ãƒ“ã‚¸ãƒ§ãƒ³å¤‰æ›´ã§å…·ä½“çš„ã«ã©ã®å€‹æ‰€ãŒå¤‰æ›´ã—ãŸã‹ã‚’ã¾ãšã”ç´¹ä»‹ã—ã¾ã™ã€‚
ã“ã¡ã‚‰ãŒã‚µã‚¤ã‚­ãƒ³ã‚½ãƒ¼ã®ãƒŸãƒƒã‚·ãƒ§ãƒ³ï¼ˆMISSIONï¼‰ã€ãƒ“ã‚¸ãƒ§ãƒ³(VISION)ã€ãƒãƒªãƒ¥ãƒ¼(VALUE)ã«ãªã‚Šã¾ã™ã€‚
ç§ãŸã¡ãŒç›®æŒ‡ã—ç¶šã‘ã‚‹ã€Œç´°èŒå¢ã§äººã€…ã‚’å¥åº·ã«ã€ã¨ã„ã†ãƒŸãƒƒã‚·ãƒ§ãƒ³ã¯ãã®ã¾ã¾ã«ã€ãƒ“ã‚¸ãƒ§ãƒ³ã‚’æ–°ã—ãå¤‰æ›´è‡´ã—ã¾ã—ãŸã€‚

ï¼œã“ã‚Œã¾ã§ã®ãƒ“ã‚¸ãƒ§ãƒ³ï¼
èŒå¢ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã€Œæ¬¡ä¸–ä»£ã®ãƒ©ã‚¤ãƒ•ã‚¹ã‚¿ã‚¤ãƒ«ã€ã‚’æä¾›ã™ã‚‹ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã«ãªã‚‹

ï¼œæ–°ã—ã„ãƒ“ã‚¸ãƒ§ãƒ³ï¼
ç´°èŒå¢ã‹ã‚‰ã®æ–°ãŸãªæ°—ä»˜ãã‚’é€šã˜ã¦
ãƒ’ãƒˆã€ç¤¾ä¼šã€åœ°çƒç’°å¢ƒã‚’å¥åº·ã«ã™ã‚‹ã‚¨ã‚³ã‚·ã‚¹ãƒ†ãƒ ã‚’å®Ÿç¾ã™ã‚‹
æ–°ã—ã„ãƒ“ã‚¸ãƒ§ãƒ³ã§ã¯ã€ã‚µã‚¤ã‚­ãƒ³ã‚½ãƒ¼ãŒå½±éŸ¿ã‚’ä¸ãˆã¦ã„ããŸã„ç¯„å›²ã‚‚ã“ã‚Œã¾ã§ã‚ˆã‚Šã•ã‚‰ã«å¤§ãããªã£ãŸã“ã¨ãŒåˆ†ã‹ã‚Šã¾ã™ã€‚

ä»Šå›ã®ãƒ“ã‚¸ãƒ§ãƒ³å¤‰æ›´ã‚’é€šã—ã¦ã€ã‚µã‚¤ã‚­ãƒ³ã‚½ãƒ¼ãŒã©ã‚“ãªä¾¡å€¤ç™ºæ®ã‚’ç›®æŒ‡ã—ã¦ã„ãã®ã‹ã€ãã‚Œã«ä¼´ã„äº‹æ¥­é¢ã§ã¯ã©ã‚“ãªæŒ‘æˆ¦ã‚’ã—ã¦ã„ãã®ã‹ã‚’ã€ä»£è¡¨å–ç· å½¹CEOã®æ²¢äº•ã•ã‚“ã«èã„ã¦ãã¾ã—ãŸï¼

...(ä»¥ä¸‹ç•¥)


 ã‚³ãƒ¼ãƒ‰
ç¶šã‘ã¦ã‚³ãƒ¼ãƒ‰ã‚’å®Ÿè£…ã—ã¾ã™ã€‚
ä»Šå›ã¯ RAG ã¨ã—ã¦å¤–éƒ¨ã®æƒ…å ±ã‚’å‚ç…§ã—ã¤ã¤å›ç­”ã™ã‚‹ ChatBot ã‚’å®Ÿè£…ã—ã¦ã¿ã¾ã™ã€‚
ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã¨ã—ã¦ streamlit ã‚’ç”¨ã„ã¾ã™ã€‚
å…ˆã«ã‚³ãƒ¼ãƒ‰å…¨ä½“ã‚’ç¤ºã™ã¨ä»¥ä¸‹ã®ã‚ˆã†ã«ãªã‚Šã¾ã™ã€‚
(streamlit ã®ã‚³ãƒ¼ãƒ‰ã®ãƒ™ãƒ¼ã‚¹ã¨ã—ã¦ä»¥ä¸‹ã®è¨˜äº‹ã‚’å‚è€ƒã«ã•ã›ã¦ã„ãŸã ãã¾ã—ãŸã€‚ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™)
https://tech-lab.sios.jp/archives/41574

chatbot.py
from pathlib import Path

import streamlit as st
from dotenv import load_dotenv
from langchain import hub
from langchain.schema import AIMessage, HumanMessage
from langchain_chroma import Chroma
from langchain_community.document_loaders import TextLoader
from langchain_core.runnables import RunnablePassthrough, RunnableSequence
from langchain_core.vectorstores import VectorStoreRetriever
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_text_splitters import RecursiveCharacterTextSplitter

load_dotenv()


def initialize_vector_store() -> Chroma:
    """VectorStoreã®åˆæœŸåŒ–."""
    embeddings = OpenAIEmbeddings()

    vector_store_path = "./resources/note.db"
    if Path(vector_store_path).exists():
        vector_store = Chroma(embedding_function=embeddings, persist_directory=vector_store_path)
    else:
        loader = TextLoader("resources/note.txt")
        docs = loader.load()

        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
        splits = text_splitter.split_documents(docs)

        vector_store = Chroma.from_documents(
            documents=splits, embedding=embeddings, persist_directory=vector_store_path
        )

    return vector_store


def initialize_retriever() -> VectorStoreRetriever:
    """Retrieverã®åˆæœŸåŒ–."""
    vector_store = initialize_vector_store()
    return vector_store.as_retriever()


def initialize_chain() -> RunnableSequence:
    """Langchainã®åˆæœŸåŒ–."""
    prompt = hub.pull("rlm/rag-prompt")
    llm = ChatOpenAI()
    retriever = initialize_retriever()
    chain = (
        {"context": retriever, "question": RunnablePassthrough()} | prompt | llm
    )
    return chain


def main() -> None:
    """ChatGPTã‚’ä½¿ã£ãŸãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã®ãƒ¡ã‚¤ãƒ³é–¢æ•°."""
    chain = initialize_chain()

    # ãƒšãƒ¼ã‚¸ã®è¨­å®š
    st.set_page_config(page_title="RAG ChatGPT")
    st.header("RAG ChatGPT")

    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®åˆæœŸåŒ–
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ã‚’ç›£è¦–
    if user_input := st.chat_input("èããŸã„ã“ã¨ã‚’å…¥åŠ›ã—ã¦ã­ï¼"):
        st.session_state.messages.append(HumanMessage(content=user_input))
        with st.spinner("GPT is typing ..."):
            response = chain.invoke(user_input)
        st.session_state.messages.append(AIMessage(content=response.content))

    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®è¡¨ç¤º
    messages = st.session_state.get("messages", [])
    for message in messages:
        if isinstance(message, AIMessage):
            with st.chat_message("assistant"):
                st.markdown(message.content)
        elif isinstance(message, HumanMessage):
            with st.chat_message("user"):
                st.markdown(message.content)
        else:
            st.write(f"System message: {message.content}")


if __name__ == "__main__":
    main()

ã‚³ãƒ¼ãƒ‰ã®å„éƒ¨åˆ†ã‚’èª¬æ˜ã—ã¦ã„ãã¾ã™ã€‚

 initialize_vector_store
def initialize_vector_store() -> Chroma:
    """VectorStoreã®åˆæœŸåŒ–."""
    embeddings = OpenAIEmbeddings()

    vector_store_path = "./resources/note.db"
    if Path(vector_store_path).exists():
        vector_store = Chroma(embedding_function=embeddings, persist_directory=vector_store_path)
    else:
        loader = TextLoader("resources/note.txt")
        docs = loader.load()

        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
        splits = text_splitter.split_documents(docs)

        vector_store = Chroma.from_documents(
            documents=splits, embedding=embeddings, persist_directory=vector_store_path
        )

    return vector_store
Vector store ã¨ã¯æƒ…å ±ã¨ã—ã¦èª­ã¿è¾¼ã¾ã›ã¦ã„ã‚‹ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’é©åˆ‡ãªé•·ã•ã«åˆ†å‰²ã—(ãƒãƒ£ãƒ³ã‚¯ã¨å‘¼ã°ã‚Œã¾ã™) ã™ãã«å–ã‚Šå‡ºã›ã‚‹ã‚ˆã†ã«ä¿å­˜ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ã‚ˆã†ãªã‚‚ã®ã§ã™ã€‚
Embeddings ã¨å‘¼ã°ã‚Œã‚‹ãƒ¢ãƒ‡ãƒ«ã§ãƒ†ã‚­ã‚¹ãƒˆã¯æ•°å€¤æƒ…å ±ã®ãƒ™ã‚¯ãƒˆãƒ«ã«ä¿å­˜ã•ã‚Œã¾ã™ã€‚ãã®ä½œæ¥­ã‚’è¡Œã†ãŸã‚ã« OpenAI API ãŒå¿…è¦ã«ãªã£ã¦ã„ã‚‹ãŸã‚é–¢æ•°ã®æœ€åˆã§ OpenAIEmbeddings ã‚’å‘¼ã³å‡ºã—ã¦ã„ã¾ã™ã€‚
ç¶šã‘ã¦ Vector store ã¨ã—ã¦ä¿å­˜ã•ã‚Œã¦ã„ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã™ã§ã«å­˜åœ¨ã—ã¦ã„ãªã„ã‹ã‚’èª¿ã¹ã¦ã„ã¾ã™ã€‚åŸºæœ¬çš„ã«ãƒ‡ãƒ¼ã‚¿ã‚„ãƒ¢ãƒ‡ãƒ«ãŒã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆã•ã‚Œãªã„é™ã‚Š Vector store ã®ãƒ‡ãƒ¼ã‚¿ã¯ã¾ã£ãŸãåŒã˜ã«ãªã‚‹ãŸã‚ã€æ¯å›å®Ÿè¡Œã—ã¦ã—ã¾ã†ã¨æ™‚é–“ã‚‚ API ã®åˆ©ç”¨æ–™é‡‘ã‚‚ç„¡é§„ã«ãªã£ã¦ã—ã¾ã„ã¾ã™ã€‚
ãã“ã§

ã¾ã å­˜åœ¨ã—ã¦ã„ãªã„å ´åˆï¼š æ–°è¦ä½œæˆ
ã™ã§ã«å­˜åœ¨ã—ã¦ã„ã‚‹å ´åˆï¼š ä¿å­˜ã—ã¦ã„ã‚‹ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’èª­ã¿è¾¼ã‚€

ã¨ã—ã¦ã„ã¾ã™ã€‚
ãªãŠå­˜åœ¨ã—ã¦ã„ã‚‹å ´åˆ Chroma ã‚¯ãƒ©ã‚¹ã®å¼•æ•° embedding_function ã« embeddings ã‚’æŒ‡å®šã—ã¦ã„ã¾ã™ãŒã€ã“ã‚Œã¯ã‚¯ã‚¨ãƒªã¨ã—ã¦ã‚ãŸãˆã‚‰ã‚Œã‚‹ãƒ¦ãƒ¼ã‚¶ã®è³ªå•ã¨ Vector store ã«ä¿å­˜ã•ã‚Œã¦ã„ã‚‹ãƒ‡ãƒ¼ã‚¿ã¨ã®é–“ã®é–¢é€£æ€§ã‚’èª¿ã¹ã‚‹ãŸã‚ã«ã€ã‚¯ã‚¨ãƒªã‚‚ Embeddings ã§ãƒ™ã‚¯ãƒˆãƒ«ã«å¤‰æ›ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã‹ã‚‰ã§ã™ã€‚

 initialize_retriver
def initialize_retriever() -> VectorStoreRetriever:
    """Retrieverã®åˆæœŸåŒ–."""
    vector_store = initialize_vector_store()
    return vector_store.as_retriever()
ã“ã¡ã‚‰ã§ã¯ã€å…ˆã»ã©ä½œæˆã—ãŸ(ã‚ã‚‹ã„ã¯ã™ã§ã«ã‚ã‚‹ã‚‚ã®ã‚’èª­ã¿è¾¼ã‚“ã ) vector_store ã‚’ retriever ã«å¤‰æ›ã—ã¦ã„ã¾ã™ã€‚ã“ã¡ã‚‰ã® retriever ã“ã®å¾Œã€ Vectore store ã‹ã‚‰æƒ…å ±ã‚’å–ã‚Šå‡ºã™ã®ã«åˆ©ç”¨ã•ã‚Œã¾ã™ã€‚

 initialize_chain
def initialize_chain() -> RunnableSequence:
    """Langchainã®åˆæœŸåŒ–."""
    prompt = hub.pull("rlm/rag-prompt")
    llm = ChatOpenAI()
    retriever = initialize_retriever()
    chain = (
        {"context": retriever, "question": RunnablePassthrough()} | prompt | llm
    )
    return chain
ã“ã¡ã‚‰ã§ã¯ retriever ã®æƒ…å ±ã‚’ LLM ã§åˆ©ç”¨ã§ãã‚‹ã‚ˆã†ã« chain ã¨å‘¼ã°ã‚Œã‚‹æ¦‚å¿µã‚’åˆ©ç”¨ã—ã¦ãŠã‚Šã¾ã™ã€‚
ã‚ˆããƒ¡ã‚½ãƒƒãƒ‰ãƒã‚§ãƒ¼ãƒ³ã¨ã„ã†è¨€è‘‰ãŒãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°è¨€èªã§ã¯ä½¿ã‚ã‚Œã¦ã„ã¾ã™ã€‚
ä¾‹ãˆã° Python ã® Pandas ã§ã¯
import pandas as pd

# ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
data = {
    'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Edward', 'Frank'],
    'Age': [24, 27, 22, 32, 29, 24],
    'City': ['New York', 'Los Angeles', 'New York', 'Chicago', 'Los Angeles', 'New York'],
    'Score': [85, 90, 88, 92, 95, 70]
}

df = pd.DataFrame(data)

# ãƒ¡ã‚½ãƒƒãƒ‰ãƒã‚§ãƒ¼ãƒ³ã‚’ä½¿ã£ãŸãƒ‡ãƒ¼ã‚¿å¤‰æ›
result = (df
          .query('Age > 25')                     # å¹´é½¢ãŒ25ä»¥ä¸Šã®è¡Œã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
          .groupby('City')                       # éƒ½å¸‚ã”ã¨ã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
          .agg({'Score': 'mean'})                # ã‚¹ã‚³ã‚¢ã®å¹³å‡ã‚’è¨ˆç®—
          .rename(columns={'Score': 'Average Score'})  # åˆ—åã‚’å¤‰æ›´
          .sort_values(by='Average Score', ascending=False)  # å¹³å‡ã‚¹ã‚³ã‚¢ã§ä¸¦ã¹æ›¿ãˆ
          .reset_index()                         # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ãƒªã‚»ãƒƒãƒˆ
         )

print(result)
ã¨ã„ã†ã‚ˆã†ã«ãƒ¡ã‚½ãƒƒãƒ‰ã®è¿”ã‚Šå€¤ã‚’æ¬¡ã®ãƒ¡ã‚½ãƒƒãƒ‰ã¸ã¨ãƒã‚±ãƒ„ãƒªãƒ¬ãƒ¼ã®ã‚ˆã†ã«ã¤ãªã„ã§è¡Œãå‡¦ç†ã•ã›ã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚ã“ã‚Œã‚’ãƒ¡ã‚½ãƒƒãƒ‰ãƒã‚§ãƒ¼ãƒ³ã¨ã„ã„ã¾ã™ã€‚
LangChain ã§ã‚‚ã“ã®ãƒã‚±ãƒ„ãƒªãƒ¬ãƒ¼ã‚’è¡Œã„ã€ã©ã®ã‚ˆã†ã«ãƒ¦ãƒ¼ã‚¶ã®è³ªå•ã«ç­”ãˆã‚‹ã‹ã®ãƒ«ãƒ¼ãƒ«ã‚’æ±ºã‚ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚
LangChain ã®å ´åˆã¯æ˜”ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã§ã¯é–¢æ•°ã®è¿”ã‚Šå€¤ã‚’ã•ã‚‰ã«é–¢æ•°ã®å¼•æ•°ã«ã™ã‚‹ã¨è¨€ã†ã“ã¨ã‚’ç¹°ã‚Šè¿”ã—ã¦ãƒã‚±ãƒ„ãƒªãƒ¬ãƒ¼ã‚’è¡Œã£ã¦ã„ã¾ã—ãŸãŒã€ä»Šã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ 0.2.5 ã§ã¯ä»¥ä¸‹ã®ã‚ˆã†ã« | ã‚’åˆ©ç”¨ã—ãƒã‚§ãƒ¼ãƒ³ã‚’ç¤ºã™ã“ã¨ãŒæ¨å¥¨ã•ã‚Œã¦ã„ã¾ã™ã€‚
    chain = (
        {"context": retriever, "question": RunnablePassthrough()} | prompt | llm
    )
ä»Šå›ã®å ´åˆ

{"context": retriever, "question": RunnablePassthrough()}
prompt
llm

ã¨ã„ã†é †ç•ªã§ãƒã‚§ãƒ¼ãƒ³ãŒã¤ãªãŒã£ã¦ã„ã¾ã™ã€‚
ãƒã‚§ãƒ¼ãƒ³ã®å…ˆé ­ãŒãªãœè¾æ›¸ã§ã‚ã‚‹ã‹ã¯ã€2ç•ªç›®ã® prompt ã®èª¬æ˜ã‚’èã„ã¦ã‚‚ã‚‰ãˆã‚Œã°ã‚ã‹ã‚‹ã¨æ€ã„ã¾ã™ã€‚
    prompt = hub.pull("rlm/rag-prompt")
prompt ã¯ LLM ã«ã©ã®ã‚ˆã†ãªè³ªå•ã‚„ä¾é ¼ã‚’ã™ã‚‹ã®ã‹ã‚’æ±ºã‚ã‚‹éƒ¨åˆ†ã§ã™ã€‚ä»Šå›ã¯ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ(å¤‰æ•°åã‚’æŒ‡ã—ã¦ã„ãªã„å ´åˆã‚«ã‚¿ã‚«ãƒŠè¡¨è¨˜ã¨ã—ã¾ã™)ã‚’æœ‰å¿—ã®æ–¹ãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ä»–ã®äººãŒåˆ©ç”¨ã§ãã‚‹ã‚ˆã†ã«ã—ã¦ãã‚Œã¦ã„ã‚‹ã‚µã‚¤ãƒˆ LangChain Hub ã‹ã‚‰ â­ ãŒå¤šã„ã‚‚ã®ã‚’ãŠå€Ÿã‚Šã—ã¦ãã¾ã—ãŸã€‚ã‚‚ã¡ã‚ã‚“è‡ªä½œã—ã¦ã‚‚ã‚‰ã£ã¦ã‚‚OKã§ã™ã€‚
https://smith.langchain.com/hub/rlm/rag-prompt
ãŠå€Ÿã‚Šã—ãŸ rag-prompt ã§ã¯ä»¥ä¸‹ã®ã‚ˆã†ã«ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒå®šç¾©ã•ã‚Œã¦ã„ã¾ã™ã€‚
You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.
Question: {question} 
Context: {context} 
Answer:
ç°¡å˜ã«æ—¥æœ¬èªã«è¨³ã™ã¨ ã€Œ context ã®æƒ…å ±ã®ã¿ã‚’ä½¿ã£ã¦ question ã«ç­”ãˆã‚‹ã‚ˆã†ã« Answer ã‚’è€ƒãˆãªã•ã„ã€‚ç­”ãˆã‚‰ã‚Œãªã„ãªã‚‰ã‚ã‹ã‚‰ãªã„ã¨ç­”ãˆãªã•ã„ã€‚ã€ ã¨ãªã‚Šã¾ã™ã€‚ context ã®æƒ…å ±ã®ã¿ã‚’ç”¨ã„ã‚‹ã‚ˆã†æŒ‡å®šã™ã‚‹ã“ã¨ã§ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³ã‚’é˜²ãåŠ¹æœãŒã‚ã‚Šã¾ã™ (ãŸã ã—ï¼‘ï¼ï¼ï¼…é˜²ãã¨ã¯æ–­è¨€ã§ããªã„ã§ã™)
ã“ã¡ã‚‰ã® question éƒ¨åˆ†ã«ãƒ¦ãƒ¼ã‚¶ã®ã‚¯ã‚¨ãƒªãŒã€ context éƒ¨åˆ†ã« retriever ã‚’æŒ‡å®šã—ã¦ prompt ã‚’å®Ÿè¡Œã›ã‚ˆã¨ã—ã¦ã„ã‚‹ã®ãŒãƒã‚§ãƒ¼ãƒ³ã® {"context": retriever, "question": RunnablePassthrough()} | prompt ã®éƒ¨åˆ†ã§ã™ã€‚
æœ€å¾Œã«å®Œæˆã—ãŸ prompt ã‚’ llm ã«æ¸¡ã—ãªã•ã„ã¨æŒ‡å®šã—ã¦ã„ã‚‹ã®ãŒ prompt | llm ã®éƒ¨åˆ†ã§ã™ã€‚
ã“ã®ãƒ¡ã‚½ãƒƒãƒ‰ãƒã‚§ãƒ¼ãƒ³ã‚’ã¾ã¨ã‚ãŸ chain ã¨ã„ã†å¤‰æ•°ã¯ invoke ãƒ¡ã‚½ãƒƒãƒ‰ã‚’æŒã£ã¦ãŠã‚Šã€ã“ã®ãƒ¡ã‚½ãƒƒãƒ‰ã«è³ªå•ã‚’æŠ•ã’ã‚‹ã¨ãã‚ŒãŒ question ã«å…¥ã‚Šãƒã‚§ãƒ¼ãƒ³ãŒå‰ã‹ã‚‰é †ç•ªã«å®Ÿè¡Œã•ã‚Œã¾ã™ã€‚
ä»¥ä¸Šã®ã‚ˆã†ã«å®šç¾©ã™ã‚‹ã“ã¨ã§ RAG ã¨ã—ã¦å¤–éƒ¨ã®æƒ…å ±ã‚’å‚ç…§ã—ã¤ã¤å›ç­”ã™ã‚‹ ChatBot ã‚’å®Ÿè£…ã§ãã¾ã—ãŸã€‚

 main
def main() -> None:
    """ChatGPTã‚’ä½¿ã£ãŸãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã®ãƒ¡ã‚¤ãƒ³é–¢æ•°."""
    chain = initialize_chain()

    # ãƒšãƒ¼ã‚¸ã®è¨­å®š
    st.set_page_config(page_title="RAG ChatGPT")
    st.image(img, use_column_width=False)
    st.header("RAG ChatGPT")

    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®åˆæœŸåŒ–
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ã‚’ç›£è¦–
    if user_input := st.chat_input("èããŸã„ã“ã¨ã‚’å…¥åŠ›ã—ã¦ã­ï¼"):
        st.session_state.messages.append(HumanMessage(content=user_input))
        with st.spinner("GPT is typing ..."):
            response = chain.invoke(user_input)
        st.session_state.messages.append(AIMessage(content=response.content))

    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®è¡¨ç¤º
    messages = st.session_state.get("messages", [])
    for message in messages:
        if isinstance(message, AIMessage):
            with st.chat_message("assistant"):
                st.markdown(message.content)
        elif isinstance(message, HumanMessage):
            with st.chat_message("user"):
                st.markdown(message.content)
        else:
            st.write(f"System message: {message.content}")
æœ€å¾Œã« main é–¢æ•°ã§ã™ã€‚ã“ã¡ã‚‰ã¯ LangChain ã®å®Ÿè£…ã¨ã„ã†ã‚ˆã‚Šã¯ Streamlit ã‚’åˆ©ç”¨ã—ãŸãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰éƒ¨åˆ†ã®å®Ÿè£…ã«ãªã‚Šã¾ã™ã€‚
ã‚­ãƒ¼ã¨ãªã‚‹ç‚¹ã ã‘è§£èª¬ã™ã‚‹ã¨

ãƒ¦ãƒ¼ã‚¶ã¨ ChatBot ã®ä¼šè©±ã¯ messages ã«ä¿å­˜ã•ã‚Œã¦ã„ã¾ã™ã€‚ä»¥ä¸‹ã®ã‚³ãƒ¼ãƒ‰ã‚’è¦‹ã‚‹ã¨ã‚ã‹ã‚‹ã‚ˆã†ã«ãƒ¦ãƒ¼ã‚¶ã‹ã‚‰ã®è³ªå•ã¨ ChatBot ã®è¿”ç­”ã¯ã©ã¡ã‚‰ã‚‚ messages ã« append ã•ã‚Œã¦ã„ã¾ã™ã€‚

    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®åˆæœŸåŒ–
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ã‚’ç›£è¦–
    if user_input := st.chat_input("èããŸã„ã“ã¨ã‚’å…¥åŠ›ã—ã¦ã­ï¼"):
        st.session_state.messages.append(HumanMessage(content=user_input))
        with st.spinner("GPT is typing ..."):
            response = chain.invoke(user_input)
        st.session_state.messages.append(AIMessage(content=response.content))

ãƒ¦ãƒ¼ã‚¶ã‹ã‚‰ã®è³ªå•ã¸ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã¯å…ˆã»ã©å®šç¾©ã—ãŸ chain ã® invoke ãƒ¡ã‚½ãƒƒãƒ‰ã‚’ç”¨ã„ã¦ä½œã‚‰ã‚Œã¦ã„ã¾ã™ã€‚

        with st.spinner("GPT is typing ..."):
            response = chain.invoke(user_input)
        st.session_state.messages.append(AIMessage(content=response.content))
ã¨ã„ã†ç‚¹ãŒã‚ã’ã‚‰ã‚Œã¾ã™ã€‚

 ãƒ†ã‚¹ãƒˆ
ãã‚Œã§ã¯å®Ÿè£…ã—ãŸã‚‚ã®ã‚’å‹•ã‹ã—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚
> streamlit run chatbot.py

Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.


  You can now view your Streamlit app in your browser.

  Local URL: http://localhost:8501
  Network URL: http://10.200.0.4:8501
  External URL: http://13.73.233.61:8501
http://localhost:8501 ã¸ãƒ–ãƒ©ã‚¦ã‚¶ã‹ã‚‰ã‚¢ã‚¯ã‚»ã‚¹ã—ã€è³ªå•ã—ã¦ã¿ã¾ã™ã€‚

ç¾æ™‚ç‚¹ã§ã® note.txt ã®å…ˆé ­ã®æ–¹ã«æ›¸ã„ã¦ã‚ã£ãŸæ–°ã—ã„ãƒ“ã‚¸ãƒ§ãƒ³ã‚’ã¡ã‚ƒã‚“ã¨ç­”ãˆã¦ã„ã¾ã™ã€‚ã“ã®æƒ…å ±ã¯ OpenAI ã«ã¯ãªã„ãŸã‚ãã¡ã‚“ã¨ RAG ãŒåƒã„ã¦ã„ã‚‹ã¨è¨€ãˆãã†ã§ã™ã€‚

ã¾ãŸã€Œ100å¹´å¾Œã«ç™ºå£²äºˆå®šã®æ–°å•†å“ã€ã¨ã„ã†æƒ…å ±ã¨ã—ã¦å«ã¾ãªã„ã‚ˆã†ãªè³ªå•ã‚’ã™ã‚‹ã¨ã¡ã‚ƒã‚“ã¨ã€Œæƒ…å ±ã‚’æŒã£ã¦ã„ãªã„ã€ã¨è¿”ç­”ã—ã¦ãã‚Œã¾ã™ã€‚ã“ã¡ã‚‰ã‚‚æœŸå¾…é€šã‚Šã§ã™ã­ã€‚

 ğŸ’¡ ã¾ã¨ã‚

LangChain v0.2.5 æ™‚ç‚¹ã§ã® RAG ã‚’ç”¨ã„ãŸ ChatBot ã®å®Ÿè£…ã‚’è¡Œã„ã¾ã—ãŸ
Streamlit ã‚’ç”¨ã„ã¦ãƒ–ãƒ©ã‚¦ã‚¶ã‹ã‚‰ãƒ¦ãƒ¼ã‚¶ãŒã‚¢ã‚¯ã‚»ã‚¹ã§ãã‚‹ã‚ˆã†ã«ã—ã¾ã—ãŸ

ãœã²å‚è€ƒã«ã—ã¦ã¿ã¦ãã ã•ã„ã€‚
yamasaKitcheminformatics, machine learning, board gameCykinso's Tech BlogPublicationã€Œç´°èŒå¢ã®åŠ›ã§äººã€…ã‚’å¥åº·ã«ã€ã‚’ãƒŸãƒƒã‚·ãƒ§ãƒ³ã«æ²ã’ã‚‹ãƒã‚¤ã‚ªãƒ†ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆã‚¢ãƒƒãƒ—ã€Œã‚µã‚¤ã‚­ãƒ³ã‚½ãƒ¼ã€ã®æŠ€è¡“ãƒ–ãƒ­ã‚°ã€‚ ãƒãƒƒã‚¸ã‚’è´ˆã£ã¦è‘—è€…ã‚’å¿œæ´ã—ã‚ˆã†ãƒãƒƒã‚¸ã‚’å—ã‘å–ã£ãŸè‘—è€…ã«ã¯Zennã‹ã‚‰ç¾é‡‘ã‚„Amazonã‚®ãƒ•ãƒˆã‚«ãƒ¼ãƒ‰ãŒé‚„å…ƒã•ã‚Œã¾ã™ã€‚ãƒãƒƒã‚¸ã‚’è´ˆã‚‹
divchatbotOpenAILangChainLLMRAGtech
 èƒŒæ™¯
LangChain ã¯ OpenAI API ã‚’åˆ©ç”¨ã—è‡ªåˆ†ãŸã¡ãŒã‚„ã‚ŠãŸã„ã“ã¨ã‚’å®Ÿç¾ã™ã‚‹ã“ã¨ã«éå¸¸ã«ä¾¿åˆ©ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã§ã™ãŒãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚¢ãƒƒãƒ—ã«ã‚ˆã£ã¦ã‚¯ãƒ©ã‚¹åã‚„ã‚µãƒ–ãƒ©ã‚¤ãƒ–ãƒ©ãƒªåã®å¤‰æ›´ãŒã‚„ã‚„å¤šãå°‘ã—å¤ã„ Web è¨˜äº‹ã‚’å‚è€ƒã«ã—ã¦ã‚‚ã†ã¾ããƒ¯ãƒ¼ã‚¯ã—ãªã„ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚
ã“ã®è¨˜äº‹ã¯ 2024/6/20 ç¾åœ¨ã® LangChain (ãƒãƒ¼ã‚¸ãƒ§ãƒ³ 0.2.5) ã§ OpenAI API ã‚„ Azure OpenAI API ã‚’å‹•ã‹ã™ä¾‹ã¨ã—ã¦æ®‹ã—ã¦ãŠãã¾ã™ã€‚
åŒã˜ã‚ˆã†ãªã“ã¨ã‚’ã—ã‚ˆã†ã¨ã—ã¦ç§ã®ã‚ˆã†ã«è‹¦æˆ¦ã—ã¦ã„ã‚‹æ–¹ã®åŠ©ã‘ã«ãªã‚Œã°å¹¸ã„ã§ã™ã€‚

 ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ãªã©

pyproject.toml
python = ">=3.12,<3.13"
python-dotenv = "^1.0.1"
chromadb = "0.5.2"
langchain = "0.2.5"
langchain-cli = "0.0.25"
langchain-openai = "0.1.8"
langchain-community = "0.2.5"
langchain-chroma = "0.1.1"
langchainhub = "0.1.20"
streamlit = "1.35.0"

ğŸ’¡ Poetry ã§ Python ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’æŒ‡å®šã™ã‚‹æ™‚ã« ^3.12 ã¨ã™ã‚‹ã¨ lancghain-chroma ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã§ããªããªã‚‹ã®ã§ >=3.12,<3.13 ã¨ã—ã¾ã—ãŸã€‚
(langchain-chroma ã¯ >=3.12,<3.13 ã¨ã„ã†æŒ‡å®šãŒã‚ã‚Šã¾ã™)

 æ–¹æ³•
OpenAI API ã‚’ä½¿ã†å ´åˆã¨ AzureOpenAI API ã‚’ä½¿ã†å ´åˆã¯åŸºæœ¬åŒã˜ã“ã¨ã‚’ã™ã‚‹ã®ã§ã¾ãš OpenAI API ã‚’ä½¿ã†å ´åˆã‚’èª¬æ˜ã—ã€è¨˜äº‹ãŒé•·ããªã£ã¦ã—ã¾ã£ãŸã®ã§ã€å¾Œæ—¥åˆ¥è¨˜äº‹ã«ã¦ AzureOpenAI API ã‚’ä½¿ã†å ´åˆã¯ã©ã®éƒ¨åˆ†ã‚’ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆã—ãŸã‚‰ã‚ˆã„ã®ã‹ã‚’èª¬æ˜ã—ãŸã„ã¨æ€ã„ã¾ã™ã€‚
6/28 è¿½è¨˜) AzureOpenAI API ç‰ˆã®è¨˜äº‹ã‚‚æ›¸ãã¾ã—ãŸã®ã§ã‚ˆã‘ã‚Œã°ãœã²ã©ã†ã
https://zenn.dev/cykinso/articles/b055e33734d06b

 .env
ä»¥ä¸‹ã®ã‚ˆã†ã« .env ã‚’ç”¨æ„ã—ã¾ã™ã€‚
OPENAI_API_KEY=sk-XXXXXXXXXXXXXXXX
OPENAI_API_VERSION=2024-02-01
ã‚‚ã— OPENAI_API_KEY ã‚’ã¾ã å–å¾—ã—ã¦ã„ãªã„å ´åˆã¯ä»¥ä¸‹ã®æ–¹æ³•ã§å–å¾—ã—ã¦ãã ã•ã„ã€‚

 OPENAI_API_KEY
OPENAI_API_KEY ã¯ OpenAI ã® Dashboard ã§ä½œæˆã§ãã¾ã™ã€‚
(èª²é‡‘å¯¾è±¡ãªã®ã§ã”è‡ªèº«ã®è²¬ä»»ã®ã‚‚ã¨ã”åˆ©ç”¨ãã ã•ã„)

ã€Œ+ Create new secret keyã€ ã‚’æŠ¼ã™ã¨ãƒ¢ãƒ¼ãƒ€ãƒ«ãŒé–‹ãã®ã§å¾Œã‹ã‚‰åŒºåˆ¥ã§ãã‚‹ã‚ˆã†ãªåå‰ã‚’ã¤ã‘ã¦ ã€ŒCreate secret keyã€ ã‚’æŠ¼ã—ã¾ã™ã€‚

è¡¨ç¤ºã•ã‚Œã‚‹ API ã‚­ãƒ¼ã‚’ .env ã«ãƒ¡ãƒ¢ã—ã¦ãŠãã¾ã™ã€‚ ã€ŒDoneã€ ã‚’æŠ¼ã™ã¨ã‚‚ã†è¡¨ç¤ºã§ãã¾ã›ã‚“ã€‚


 ãƒ‡ãƒ¼ã‚¿
OpenAI ãŒã¾ã å­¦ç¿’ã—ã¦ã„ãªã•ãã†ãªãƒ‡ãƒ¼ã‚¿ã®ä¾‹ã¨ã—ã¦å¼Šç¤¾ Cykinso ã®ãƒ–ãƒ­ã‚°è¨˜äº‹ã®ã€Œä¼šç¤¾ã®ãƒ“ã‚¸ãƒ§ãƒ³ã‚’è©±ã—ã¦ã„ã‚‹ãƒšãƒ¼ã‚¸ã€ã‚’ä»Šå›ã¯ç”¨ã„ãŸã„ã¨æ€ã„ã¾ã™ã€‚
https://note.com/cykinso/n/n432d5ea70783
ğŸ’¡ ãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆã§å®Ÿè£…ã™ã‚‹å ´åˆã¯ã€å¥½ããªãƒãƒ³ã‚¬ãªã©ã®è©³ç´°ã‚’ãƒ†ã‚­ã‚¹ãƒˆã«ã¾ã¨ã‚ã¦ãƒ‡ãƒ¼ã‚¿ã¨ã™ã‚‹ã¨ãƒ¢ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³ã‚‚ä¸ŠãŒã‚‹ã¨æ€ã„ã¾ã™ã€‚
ã–ã£ã¨æ–‡ç« ã‚’ã‚³ãƒ”ãƒ¼ã—ã¦ä»¥ä¸‹ã®ã‚ˆã†ã«æ•´å½¢ã—ã¾ã—ãŸã€‚

note.txt
ç´°èŒå¢ã‹ã‚‰ã®æ–°ãŸãªæ°—ä»˜ãã‚’é€šã˜ã¦ã€æ–°ãƒ“ã‚¸ãƒ§ãƒ³ã‚’ç­–å®šã—ã¾ã—ãŸï¼
2023å¹´11æœˆã«ã‚µã‚¤ã‚­ãƒ³ã‚½ãƒ¼ã¯10æœŸç›®ã«å…¥ã‚Šã¾ã—ãŸã€‚é«˜é½¢åŒ–ç¤¾ä¼šã«ã‚ˆã‚‹ç¤¾ä¼šä¿éšœã¸ã®ä¸å®‰ãŒå‹Ÿã‚‹ç¾åœ¨ã€ç—…æ°—ã‚’æœªç„¶ã«é˜²ã0æ¬¡äºˆé˜²ã®é‡è¦æ€§ãŒé«˜ã¾ã£ã¦ã„ã¾ã™ã€‚ã€Œç´°èŒå¢ã§äººã€…ã‚’å¥åº·ã«ã€ã¨ã„ã†ãƒŸãƒƒã‚·ãƒ§ãƒ³ã«å‘ã‘ã¦ã€ã‚µã‚¤ã‚­ãƒ³ã‚½ãƒ¼ã¯æ–°ãŸãªãƒ“ã‚¸ãƒ§ãƒ³ã‚’åˆ¶å®šã—ã¾ã—ãŸã€‚
æ–°ã—ã„ãƒ“ã‚¸ãƒ§ãƒ³ã«ã¤ã„ã¦
ãƒ¼ãƒ“ã‚¸ãƒ§ãƒ³å¤‰æ›´ã§å…·ä½“çš„ã«ã©ã®å€‹æ‰€ãŒå¤‰æ›´ã—ãŸã‹ã‚’ã¾ãšã”ç´¹ä»‹ã—ã¾ã™ã€‚
ã“ã¡ã‚‰ãŒã‚µã‚¤ã‚­ãƒ³ã‚½ãƒ¼ã®ãƒŸãƒƒã‚·ãƒ§ãƒ³ï¼ˆMISSIONï¼‰ã€ãƒ“ã‚¸ãƒ§ãƒ³(VISION)ã€ãƒãƒªãƒ¥ãƒ¼(VALUE)ã«ãªã‚Šã¾ã™ã€‚
ç§ãŸã¡ãŒç›®æŒ‡ã—ç¶šã‘ã‚‹ã€Œç´°èŒå¢ã§äººã€…ã‚’å¥åº·ã«ã€ã¨ã„ã†ãƒŸãƒƒã‚·ãƒ§ãƒ³ã¯ãã®ã¾ã¾ã«ã€ãƒ“ã‚¸ãƒ§ãƒ³ã‚’æ–°ã—ãå¤‰æ›´è‡´ã—ã¾ã—ãŸã€‚

ï¼œã“ã‚Œã¾ã§ã®ãƒ“ã‚¸ãƒ§ãƒ³ï¼
èŒå¢ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã€Œæ¬¡ä¸–ä»£ã®ãƒ©ã‚¤ãƒ•ã‚¹ã‚¿ã‚¤ãƒ«ã€ã‚’æä¾›ã™ã‚‹ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã«ãªã‚‹

ï¼œæ–°ã—ã„ãƒ“ã‚¸ãƒ§ãƒ³ï¼
ç´°èŒå¢ã‹ã‚‰ã®æ–°ãŸãªæ°—ä»˜ãã‚’é€šã˜ã¦
ãƒ’ãƒˆã€ç¤¾ä¼šã€åœ°çƒç’°å¢ƒã‚’å¥åº·ã«ã™ã‚‹ã‚¨ã‚³ã‚·ã‚¹ãƒ†ãƒ ã‚’å®Ÿç¾ã™ã‚‹
æ–°ã—ã„ãƒ“ã‚¸ãƒ§ãƒ³ã§ã¯ã€ã‚µã‚¤ã‚­ãƒ³ã‚½ãƒ¼ãŒå½±éŸ¿ã‚’ä¸ãˆã¦ã„ããŸã„ç¯„å›²ã‚‚ã“ã‚Œã¾ã§ã‚ˆã‚Šã•ã‚‰ã«å¤§ãããªã£ãŸã“ã¨ãŒåˆ†ã‹ã‚Šã¾ã™ã€‚

ä»Šå›ã®ãƒ“ã‚¸ãƒ§ãƒ³å¤‰æ›´ã‚’é€šã—ã¦ã€ã‚µã‚¤ã‚­ãƒ³ã‚½ãƒ¼ãŒã©ã‚“ãªä¾¡å€¤ç™ºæ®ã‚’ç›®æŒ‡ã—ã¦ã„ãã®ã‹ã€ãã‚Œã«ä¼´ã„äº‹æ¥­é¢ã§ã¯ã©ã‚“ãªæŒ‘æˆ¦ã‚’ã—ã¦ã„ãã®ã‹ã‚’ã€ä»£è¡¨å–ç· å½¹CEOã®æ²¢äº•ã•ã‚“ã«èã„ã¦ãã¾ã—ãŸï¼

...(ä»¥ä¸‹ç•¥)


 ã‚³ãƒ¼ãƒ‰
ç¶šã‘ã¦ã‚³ãƒ¼ãƒ‰ã‚’å®Ÿè£…ã—ã¾ã™ã€‚
ä»Šå›ã¯ RAG ã¨ã—ã¦å¤–éƒ¨ã®æƒ…å ±ã‚’å‚ç…§ã—ã¤ã¤å›ç­”ã™ã‚‹ ChatBot ã‚’å®Ÿè£…ã—ã¦ã¿ã¾ã™ã€‚
ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã¨ã—ã¦ streamlit ã‚’ç”¨ã„ã¾ã™ã€‚
å…ˆã«ã‚³ãƒ¼ãƒ‰å…¨ä½“ã‚’ç¤ºã™ã¨ä»¥ä¸‹ã®ã‚ˆã†ã«ãªã‚Šã¾ã™ã€‚
(streamlit ã®ã‚³ãƒ¼ãƒ‰ã®ãƒ™ãƒ¼ã‚¹ã¨ã—ã¦ä»¥ä¸‹ã®è¨˜äº‹ã‚’å‚è€ƒã«ã•ã›ã¦ã„ãŸã ãã¾ã—ãŸã€‚ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™)
https://tech-lab.sios.jp/archives/41574

chatbot.py
from pathlib import Path

import streamlit as st
from dotenv import load_dotenv
from langchain import hub
from langchain.schema import AIMessage, HumanMessage
from langchain_chroma import Chroma
from langchain_community.document_loaders import TextLoader
from langchain_core.runnables import RunnablePassthrough, RunnableSequence
from langchain_core.vectorstores import VectorStoreRetriever
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_text_splitters import RecursiveCharacterTextSplitter

load_dotenv()


def initialize_vector_store() -> Chroma:
    """VectorStoreã®åˆæœŸåŒ–."""
    embeddings = OpenAIEmbeddings()

    vector_store_path = "./resources/note.db"
    if Path(vector_store_path).exists():
        vector_store = Chroma(embedding_function=embeddings, persist_directory=vector_store_path)
    else:
        loader = TextLoader("resources/note.txt")
        docs = loader.load()

        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
        splits = text_splitter.split_documents(docs)

        vector_store = Chroma.from_documents(
            documents=splits, embedding=embeddings, persist_directory=vector_store_path
        )

    return vector_store


def initialize_retriever() -> VectorStoreRetriever:
    """Retrieverã®åˆæœŸåŒ–."""
    vector_store = initialize_vector_store()
    return vector_store.as_retriever()


def initialize_chain() -> RunnableSequence:
    """Langchainã®åˆæœŸåŒ–."""
    prompt = hub.pull("rlm/rag-prompt")
    llm = ChatOpenAI()
    retriever = initialize_retriever()
    chain = (
        {"context": retriever, "question": RunnablePassthrough()} | prompt | llm
    )
    return chain


def main() -> None:
    """ChatGPTã‚’ä½¿ã£ãŸãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã®ãƒ¡ã‚¤ãƒ³é–¢æ•°."""
    chain = initialize_chain()

    # ãƒšãƒ¼ã‚¸ã®è¨­å®š
    st.set_page_config(page_title="RAG ChatGPT")
    st.header("RAG ChatGPT")

    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®åˆæœŸåŒ–
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ã‚’ç›£è¦–
    if user_input := st.chat_input("èããŸã„ã“ã¨ã‚’å…¥åŠ›ã—ã¦ã­ï¼"):
        st.session_state.messages.append(HumanMessage(content=user_input))
        with st.spinner("GPT is typing ..."):
            response = chain.invoke(user_input)
        st.session_state.messages.append(AIMessage(content=response.content))

    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®è¡¨ç¤º
    messages = st.session_state.get("messages", [])
    for message in messages:
        if isinstance(message, AIMessage):
            with st.chat_message("assistant"):
                st.markdown(message.content)
        elif isinstance(message, HumanMessage):
            with st.chat_message("user"):
                st.markdown(message.content)
        else:
            st.write(f"System message: {message.content}")


if __name__ == "__main__":
    main()

ã‚³ãƒ¼ãƒ‰ã®å„éƒ¨åˆ†ã‚’èª¬æ˜ã—ã¦ã„ãã¾ã™ã€‚

 initialize_vector_store
def initialize_vector_store() -> Chroma:
    """VectorStoreã®åˆæœŸåŒ–."""
    embeddings = OpenAIEmbeddings()

    vector_store_path = "./resources/note.db"
    if Path(vector_store_path).exists():
        vector_store = Chroma(embedding_function=embeddings, persist_directory=vector_store_path)
    else:
        loader = TextLoader("resources/note.txt")
        docs = loader.load()

        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
        splits = text_splitter.split_documents(docs)

        vector_store = Chroma.from_documents(
            documents=splits, embedding=embeddings, persist_directory=vector_store_path
        )

    return vector_store
Vector store ã¨ã¯æƒ…å ±ã¨ã—ã¦èª­ã¿è¾¼ã¾ã›ã¦ã„ã‚‹ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’é©åˆ‡ãªé•·ã•ã«åˆ†å‰²ã—(ãƒãƒ£ãƒ³ã‚¯ã¨å‘¼ã°ã‚Œã¾ã™) ã™ãã«å–ã‚Šå‡ºã›ã‚‹ã‚ˆã†ã«ä¿å­˜ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ã‚ˆã†ãªã‚‚ã®ã§ã™ã€‚
Embeddings ã¨å‘¼ã°ã‚Œã‚‹ãƒ¢ãƒ‡ãƒ«ã§ãƒ†ã‚­ã‚¹ãƒˆã¯æ•°å€¤æƒ…å ±ã®ãƒ™ã‚¯ãƒˆãƒ«ã«ä¿å­˜ã•ã‚Œã¾ã™ã€‚ãã®ä½œæ¥­ã‚’è¡Œã†ãŸã‚ã« OpenAI API ãŒå¿…è¦ã«ãªã£ã¦ã„ã‚‹ãŸã‚é–¢æ•°ã®æœ€åˆã§ OpenAIEmbeddings ã‚’å‘¼ã³å‡ºã—ã¦ã„ã¾ã™ã€‚
ç¶šã‘ã¦ Vector store ã¨ã—ã¦ä¿å­˜ã•ã‚Œã¦ã„ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã™ã§ã«å­˜åœ¨ã—ã¦ã„ãªã„ã‹ã‚’èª¿ã¹ã¦ã„ã¾ã™ã€‚åŸºæœ¬çš„ã«ãƒ‡ãƒ¼ã‚¿ã‚„ãƒ¢ãƒ‡ãƒ«ãŒã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆã•ã‚Œãªã„é™ã‚Š Vector store ã®ãƒ‡ãƒ¼ã‚¿ã¯ã¾ã£ãŸãåŒã˜ã«ãªã‚‹ãŸã‚ã€æ¯å›å®Ÿè¡Œã—ã¦ã—ã¾ã†ã¨æ™‚é–“ã‚‚ API ã®åˆ©ç”¨æ–™é‡‘ã‚‚ç„¡é§„ã«ãªã£ã¦ã—ã¾ã„ã¾ã™ã€‚
ãã“ã§

ã¾ã å­˜åœ¨ã—ã¦ã„ãªã„å ´åˆï¼š æ–°è¦ä½œæˆ
ã™ã§ã«å­˜åœ¨ã—ã¦ã„ã‚‹å ´åˆï¼š ä¿å­˜ã—ã¦ã„ã‚‹ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’èª­ã¿è¾¼ã‚€

ã¨ã—ã¦ã„ã¾ã™ã€‚
ãªãŠå­˜åœ¨ã—ã¦ã„ã‚‹å ´åˆ Chroma ã‚¯ãƒ©ã‚¹ã®å¼•æ•° embedding_function ã« embeddings ã‚’æŒ‡å®šã—ã¦ã„ã¾ã™ãŒã€ã“ã‚Œã¯ã‚¯ã‚¨ãƒªã¨ã—ã¦ã‚ãŸãˆã‚‰ã‚Œã‚‹ãƒ¦ãƒ¼ã‚¶ã®è³ªå•ã¨ Vector store ã«ä¿å­˜ã•ã‚Œã¦ã„ã‚‹ãƒ‡ãƒ¼ã‚¿ã¨ã®é–“ã®é–¢é€£æ€§ã‚’èª¿ã¹ã‚‹ãŸã‚ã«ã€ã‚¯ã‚¨ãƒªã‚‚ Embeddings ã§ãƒ™ã‚¯ãƒˆãƒ«ã«å¤‰æ›ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã‹ã‚‰ã§ã™ã€‚

 initialize_retriver
def initialize_retriever() -> VectorStoreRetriever:
    """Retrieverã®åˆæœŸåŒ–."""
    vector_store = initialize_vector_store()
    return vector_store.as_retriever()
ã“ã¡ã‚‰ã§ã¯ã€å…ˆã»ã©ä½œæˆã—ãŸ(ã‚ã‚‹ã„ã¯ã™ã§ã«ã‚ã‚‹ã‚‚ã®ã‚’èª­ã¿è¾¼ã‚“ã ) vector_store ã‚’ retriever ã«å¤‰æ›ã—ã¦ã„ã¾ã™ã€‚ã“ã¡ã‚‰ã® retriever ã“ã®å¾Œã€ Vectore store ã‹ã‚‰æƒ…å ±ã‚’å–ã‚Šå‡ºã™ã®ã«åˆ©ç”¨ã•ã‚Œã¾ã™ã€‚

 initialize_chain
def initialize_chain() -> RunnableSequence:
    """Langchainã®åˆæœŸåŒ–."""
    prompt = hub.pull("rlm/rag-prompt")
    llm = ChatOpenAI()
    retriever = initialize_retriever()
    chain = (
        {"context": retriever, "question": RunnablePassthrough()} | prompt | llm
    )
    return chain
ã“ã¡ã‚‰ã§ã¯ retriever ã®æƒ…å ±ã‚’ LLM ã§åˆ©ç”¨ã§ãã‚‹ã‚ˆã†ã« chain ã¨å‘¼ã°ã‚Œã‚‹æ¦‚å¿µã‚’åˆ©ç”¨ã—ã¦ãŠã‚Šã¾ã™ã€‚
ã‚ˆããƒ¡ã‚½ãƒƒãƒ‰ãƒã‚§ãƒ¼ãƒ³ã¨ã„ã†è¨€è‘‰ãŒãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°è¨€èªã§ã¯ä½¿ã‚ã‚Œã¦ã„ã¾ã™ã€‚
ä¾‹ãˆã° Python ã® Pandas ã§ã¯
import pandas as pd

# ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
data = {
    'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Edward', 'Frank'],
    'Age': [24, 27, 22, 32, 29, 24],
    'City': ['New York', 'Los Angeles', 'New York', 'Chicago', 'Los Angeles', 'New York'],
    'Score': [85, 90, 88, 92, 95, 70]
}

df = pd.DataFrame(data)

# ãƒ¡ã‚½ãƒƒãƒ‰ãƒã‚§ãƒ¼ãƒ³ã‚’ä½¿ã£ãŸãƒ‡ãƒ¼ã‚¿å¤‰æ›
result = (df
          .query('Age > 25')                     # å¹´é½¢ãŒ25ä»¥ä¸Šã®è¡Œã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
          .groupby('City')                       # éƒ½å¸‚ã”ã¨ã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
          .agg({'Score': 'mean'})                # ã‚¹ã‚³ã‚¢ã®å¹³å‡ã‚’è¨ˆç®—
          .rename(columns={'Score': 'Average Score'})  # åˆ—åã‚’å¤‰æ›´
          .sort_values(by='Average Score', ascending=False)  # å¹³å‡ã‚¹ã‚³ã‚¢ã§ä¸¦ã¹æ›¿ãˆ
          .reset_index()                         # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ãƒªã‚»ãƒƒãƒˆ
         )

print(result)
ã¨ã„ã†ã‚ˆã†ã«ãƒ¡ã‚½ãƒƒãƒ‰ã®è¿”ã‚Šå€¤ã‚’æ¬¡ã®ãƒ¡ã‚½ãƒƒãƒ‰ã¸ã¨ãƒã‚±ãƒ„ãƒªãƒ¬ãƒ¼ã®ã‚ˆã†ã«ã¤ãªã„ã§è¡Œãå‡¦ç†ã•ã›ã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚ã“ã‚Œã‚’ãƒ¡ã‚½ãƒƒãƒ‰ãƒã‚§ãƒ¼ãƒ³ã¨ã„ã„ã¾ã™ã€‚
LangChain ã§ã‚‚ã“ã®ãƒã‚±ãƒ„ãƒªãƒ¬ãƒ¼ã‚’è¡Œã„ã€ã©ã®ã‚ˆã†ã«ãƒ¦ãƒ¼ã‚¶ã®è³ªå•ã«ç­”ãˆã‚‹ã‹ã®ãƒ«ãƒ¼ãƒ«ã‚’æ±ºã‚ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚
LangChain ã®å ´åˆã¯æ˜”ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã§ã¯é–¢æ•°ã®è¿”ã‚Šå€¤ã‚’ã•ã‚‰ã«é–¢æ•°ã®å¼•æ•°ã«ã™ã‚‹ã¨è¨€ã†ã“ã¨ã‚’ç¹°ã‚Šè¿”ã—ã¦ãƒã‚±ãƒ„ãƒªãƒ¬ãƒ¼ã‚’è¡Œã£ã¦ã„ã¾ã—ãŸãŒã€ä»Šã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ 0.2.5 ã§ã¯ä»¥ä¸‹ã®ã‚ˆã†ã« | ã‚’åˆ©ç”¨ã—ãƒã‚§ãƒ¼ãƒ³ã‚’ç¤ºã™ã“ã¨ãŒæ¨å¥¨ã•ã‚Œã¦ã„ã¾ã™ã€‚
    chain = (
        {"context": retriever, "question": RunnablePassthrough()} | prompt | llm
    )
ä»Šå›ã®å ´åˆ

{"context": retriever, "question": RunnablePassthrough()}
prompt
llm

ã¨ã„ã†é †ç•ªã§ãƒã‚§ãƒ¼ãƒ³ãŒã¤ãªãŒã£ã¦ã„ã¾ã™ã€‚
ãƒã‚§ãƒ¼ãƒ³ã®å…ˆé ­ãŒãªãœè¾æ›¸ã§ã‚ã‚‹ã‹ã¯ã€2ç•ªç›®ã® prompt ã®èª¬æ˜ã‚’èã„ã¦ã‚‚ã‚‰ãˆã‚Œã°ã‚ã‹ã‚‹ã¨æ€ã„ã¾ã™ã€‚
    prompt = hub.pull("rlm/rag-prompt")
prompt ã¯ LLM ã«ã©ã®ã‚ˆã†ãªè³ªå•ã‚„ä¾é ¼ã‚’ã™ã‚‹ã®ã‹ã‚’æ±ºã‚ã‚‹éƒ¨åˆ†ã§ã™ã€‚ä»Šå›ã¯ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ(å¤‰æ•°åã‚’æŒ‡ã—ã¦ã„ãªã„å ´åˆã‚«ã‚¿ã‚«ãƒŠè¡¨è¨˜ã¨ã—ã¾ã™)ã‚’æœ‰å¿—ã®æ–¹ãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ä»–ã®äººãŒåˆ©ç”¨ã§ãã‚‹ã‚ˆã†ã«ã—ã¦ãã‚Œã¦ã„ã‚‹ã‚µã‚¤ãƒˆ LangChain Hub ã‹ã‚‰ â­ ãŒå¤šã„ã‚‚ã®ã‚’ãŠå€Ÿã‚Šã—ã¦ãã¾ã—ãŸã€‚ã‚‚ã¡ã‚ã‚“è‡ªä½œã—ã¦ã‚‚ã‚‰ã£ã¦ã‚‚OKã§ã™ã€‚
https://smith.langchain.com/hub/rlm/rag-prompt
ãŠå€Ÿã‚Šã—ãŸ rag-prompt ã§ã¯ä»¥ä¸‹ã®ã‚ˆã†ã«ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒå®šç¾©ã•ã‚Œã¦ã„ã¾ã™ã€‚
You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.
Question: {question} 
Context: {context} 
Answer:
ç°¡å˜ã«æ—¥æœ¬èªã«è¨³ã™ã¨ ã€Œ context ã®æƒ…å ±ã®ã¿ã‚’ä½¿ã£ã¦ question ã«ç­”ãˆã‚‹ã‚ˆã†ã« Answer ã‚’è€ƒãˆãªã•ã„ã€‚ç­”ãˆã‚‰ã‚Œãªã„ãªã‚‰ã‚ã‹ã‚‰ãªã„ã¨ç­”ãˆãªã•ã„ã€‚ã€ ã¨ãªã‚Šã¾ã™ã€‚ context ã®æƒ…å ±ã®ã¿ã‚’ç”¨ã„ã‚‹ã‚ˆã†æŒ‡å®šã™ã‚‹ã“ã¨ã§ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³ã‚’é˜²ãåŠ¹æœãŒã‚ã‚Šã¾ã™ (ãŸã ã—ï¼‘ï¼ï¼ï¼…é˜²ãã¨ã¯æ–­è¨€ã§ããªã„ã§ã™)
ã“ã¡ã‚‰ã® question éƒ¨åˆ†ã«ãƒ¦ãƒ¼ã‚¶ã®ã‚¯ã‚¨ãƒªãŒã€ context éƒ¨åˆ†ã« retriever ã‚’æŒ‡å®šã—ã¦ prompt ã‚’å®Ÿè¡Œã›ã‚ˆã¨ã—ã¦ã„ã‚‹ã®ãŒãƒã‚§ãƒ¼ãƒ³ã® {"context": retriever, "question": RunnablePassthrough()} | prompt ã®éƒ¨åˆ†ã§ã™ã€‚
æœ€å¾Œã«å®Œæˆã—ãŸ prompt ã‚’ llm ã«æ¸¡ã—ãªã•ã„ã¨æŒ‡å®šã—ã¦ã„ã‚‹ã®ãŒ prompt | llm ã®éƒ¨åˆ†ã§ã™ã€‚
ã“ã®ãƒ¡ã‚½ãƒƒãƒ‰ãƒã‚§ãƒ¼ãƒ³ã‚’ã¾ã¨ã‚ãŸ chain ã¨ã„ã†å¤‰æ•°ã¯ invoke ãƒ¡ã‚½ãƒƒãƒ‰ã‚’æŒã£ã¦ãŠã‚Šã€ã“ã®ãƒ¡ã‚½ãƒƒãƒ‰ã«è³ªå•ã‚’æŠ•ã’ã‚‹ã¨ãã‚ŒãŒ question ã«å…¥ã‚Šãƒã‚§ãƒ¼ãƒ³ãŒå‰ã‹ã‚‰é †ç•ªã«å®Ÿè¡Œã•ã‚Œã¾ã™ã€‚
ä»¥ä¸Šã®ã‚ˆã†ã«å®šç¾©ã™ã‚‹ã“ã¨ã§ RAG ã¨ã—ã¦å¤–éƒ¨ã®æƒ…å ±ã‚’å‚ç…§ã—ã¤ã¤å›ç­”ã™ã‚‹ ChatBot ã‚’å®Ÿè£…ã§ãã¾ã—ãŸã€‚

 main
def main() -> None:
    """ChatGPTã‚’ä½¿ã£ãŸãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã®ãƒ¡ã‚¤ãƒ³é–¢æ•°."""
    chain = initialize_chain()

    # ãƒšãƒ¼ã‚¸ã®è¨­å®š
    st.set_page_config(page_title="RAG ChatGPT")
    st.image(img, use_column_width=False)
    st.header("RAG ChatGPT")

    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®åˆæœŸåŒ–
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ã‚’ç›£è¦–
    if user_input := st.chat_input("èããŸã„ã“ã¨ã‚’å…¥åŠ›ã—ã¦ã­ï¼"):
        st.session_state.messages.append(HumanMessage(content=user_input))
        with st.spinner("GPT is typing ..."):
            response = chain.invoke(user_input)
        st.session_state.messages.append(AIMessage(content=response.content))

    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®è¡¨ç¤º
    messages = st.session_state.get("messages", [])
    for message in messages:
        if isinstance(message, AIMessage):
            with st.chat_message("assistant"):
                st.markdown(message.content)
        elif isinstance(message, HumanMessage):
            with st.chat_message("user"):
                st.markdown(message.content)
        else:
            st.write(f"System message: {message.content}")
æœ€å¾Œã« main é–¢æ•°ã§ã™ã€‚ã“ã¡ã‚‰ã¯ LangChain ã®å®Ÿè£…ã¨ã„ã†ã‚ˆã‚Šã¯ Streamlit ã‚’åˆ©ç”¨ã—ãŸãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰éƒ¨åˆ†ã®å®Ÿè£…ã«ãªã‚Šã¾ã™ã€‚
ã‚­ãƒ¼ã¨ãªã‚‹ç‚¹ã ã‘è§£èª¬ã™ã‚‹ã¨

ãƒ¦ãƒ¼ã‚¶ã¨ ChatBot ã®ä¼šè©±ã¯ messages ã«ä¿å­˜ã•ã‚Œã¦ã„ã¾ã™ã€‚ä»¥ä¸‹ã®ã‚³ãƒ¼ãƒ‰ã‚’è¦‹ã‚‹ã¨ã‚ã‹ã‚‹ã‚ˆã†ã«ãƒ¦ãƒ¼ã‚¶ã‹ã‚‰ã®è³ªå•ã¨ ChatBot ã®è¿”ç­”ã¯ã©ã¡ã‚‰ã‚‚ messages ã« append ã•ã‚Œã¦ã„ã¾ã™ã€‚

    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®åˆæœŸåŒ–
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ã‚’ç›£è¦–
    if user_input := st.chat_input("èããŸã„ã“ã¨ã‚’å…¥åŠ›ã—ã¦ã­ï¼"):
        st.session_state.messages.append(HumanMessage(content=user_input))
        with st.spinner("GPT is typing ..."):
            response = chain.invoke(user_input)
        st.session_state.messages.append(AIMessage(content=response.content))

ãƒ¦ãƒ¼ã‚¶ã‹ã‚‰ã®è³ªå•ã¸ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã¯å…ˆã»ã©å®šç¾©ã—ãŸ chain ã® invoke ãƒ¡ã‚½ãƒƒãƒ‰ã‚’ç”¨ã„ã¦ä½œã‚‰ã‚Œã¦ã„ã¾ã™ã€‚

        with st.spinner("GPT is typing ..."):
            response = chain.invoke(user_input)
        st.session_state.messages.append(AIMessage(content=response.content))
ã¨ã„ã†ç‚¹ãŒã‚ã’ã‚‰ã‚Œã¾ã™ã€‚

 ãƒ†ã‚¹ãƒˆ
ãã‚Œã§ã¯å®Ÿè£…ã—ãŸã‚‚ã®ã‚’å‹•ã‹ã—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚
> streamlit run chatbot.py

Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.


  You can now view your Streamlit app in your browser.

  Local URL: http://localhost:8501
  Network URL: http://10.200.0.4:8501
  External URL: http://13.73.233.61:8501
http://localhost:8501 ã¸ãƒ–ãƒ©ã‚¦ã‚¶ã‹ã‚‰ã‚¢ã‚¯ã‚»ã‚¹ã—ã€è³ªå•ã—ã¦ã¿ã¾ã™ã€‚

ç¾æ™‚ç‚¹ã§ã® note.txt ã®å…ˆé ­ã®æ–¹ã«æ›¸ã„ã¦ã‚ã£ãŸæ–°ã—ã„ãƒ“ã‚¸ãƒ§ãƒ³ã‚’ã¡ã‚ƒã‚“ã¨ç­”ãˆã¦ã„ã¾ã™ã€‚ã“ã®æƒ…å ±ã¯ OpenAI ã«ã¯ãªã„ãŸã‚ãã¡ã‚“ã¨ RAG ãŒåƒã„ã¦ã„ã‚‹ã¨è¨€ãˆãã†ã§ã™ã€‚

ã¾ãŸã€Œ100å¹´å¾Œã«ç™ºå£²äºˆå®šã®æ–°å•†å“ã€ã¨ã„ã†æƒ…å ±ã¨ã—ã¦å«ã¾ãªã„ã‚ˆã†ãªè³ªå•ã‚’ã™ã‚‹ã¨ã¡ã‚ƒã‚“ã¨ã€Œæƒ…å ±ã‚’æŒã£ã¦ã„ãªã„ã€ã¨è¿”ç­”ã—ã¦ãã‚Œã¾ã™ã€‚ã“ã¡ã‚‰ã‚‚æœŸå¾…é€šã‚Šã§ã™ã­ã€‚

 ğŸ’¡ ã¾ã¨ã‚

LangChain v0.2.5 æ™‚ç‚¹ã§ã® RAG ã‚’ç”¨ã„ãŸ ChatBot ã®å®Ÿè£…ã‚’è¡Œã„ã¾ã—ãŸ
Streamlit ã‚’ç”¨ã„ã¦ãƒ–ãƒ©ã‚¦ã‚¶ã‹ã‚‰ãƒ¦ãƒ¼ã‚¶ãŒã‚¢ã‚¯ã‚»ã‚¹ã§ãã‚‹ã‚ˆã†ã«ã—ã¾ã—ãŸ

ãœã²å‚è€ƒã«ã—ã¦ã¿ã¦ãã ã•ã„ã€‚
yamasaKitcheminformatics, machine learning, board gameCykinso's Tech BlogPublicationã€Œç´°èŒå¢ã®åŠ›ã§äººã€…ã‚’å¥åº·ã«ã€ã‚’ãƒŸãƒƒã‚·ãƒ§ãƒ³ã«æ²ã’ã‚‹ãƒã‚¤ã‚ªãƒ†ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆã‚¢ãƒƒãƒ—ã€Œã‚µã‚¤ã‚­ãƒ³ã‚½ãƒ¼ã€ã®æŠ€è¡“ãƒ–ãƒ­ã‚°ã€‚ ãƒãƒƒã‚¸ã‚’è´ˆã£ã¦è‘—è€…ã‚’å¿œæ´ã—ã‚ˆã†ãƒãƒƒã‚¸ã‚’å—ã‘å–ã£ãŸè‘—è€…ã«ã¯Zennã‹ã‚‰ç¾é‡‘ã‚„Amazonã‚®ãƒ•ãƒˆã‚«ãƒ¼ãƒ‰ãŒé‚„å…ƒã•ã‚Œã¾ã™ã€‚ãƒãƒƒã‚¸ã‚’è´ˆã‚‹
divchatbotOpenAILangChainLLMRAGtech
achatbot
div
img
divchatbot
aOpenAI
div
img
divOpenAI
aLangChain
div
img
divLangChain
aLLM
div
img
divLLM
aRAG
div
img
divRAG
atech
div
img
divtech
div
 èƒŒæ™¯
LangChain ã¯ OpenAI API ã‚’åˆ©ç”¨ã—è‡ªåˆ†ãŸã¡ãŒã‚„ã‚ŠãŸã„ã“ã¨ã‚’å®Ÿç¾ã™ã‚‹ã“ã¨ã«éå¸¸ã«ä¾¿åˆ©ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã§ã™ãŒãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚¢ãƒƒãƒ—ã«ã‚ˆã£ã¦ã‚¯ãƒ©ã‚¹åã‚„ã‚µãƒ–ãƒ©ã‚¤ãƒ–ãƒ©ãƒªåã®å¤‰æ›´ãŒã‚„ã‚„å¤šãå°‘ã—å¤ã„ Web è¨˜äº‹ã‚’å‚è€ƒã«ã—ã¦ã‚‚ã†ã¾ããƒ¯ãƒ¼ã‚¯ã—ãªã„ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚
ã“ã®è¨˜äº‹ã¯ 2024/6/20 ç¾åœ¨ã® LangChain (ãƒãƒ¼ã‚¸ãƒ§ãƒ³ 0.2.5) ã§ OpenAI API ã‚„ Azure OpenAI API ã‚’å‹•ã‹ã™ä¾‹ã¨ã—ã¦æ®‹ã—ã¦ãŠãã¾ã™ã€‚
åŒã˜ã‚ˆã†ãªã“ã¨ã‚’ã—ã‚ˆã†ã¨ã—ã¦ç§ã®ã‚ˆã†ã«è‹¦æˆ¦ã—ã¦ã„ã‚‹æ–¹ã®åŠ©ã‘ã«ãªã‚Œã°å¹¸ã„ã§ã™ã€‚

 ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ãªã©

pyproject.toml
python = ">=3.12,<3.13"
python-dotenv = "^1.0.1"
chromadb = "0.5.2"
langchain = "0.2.5"
langchain-cli = "0.0.25"
langchain-openai = "0.1.8"
langchain-community = "0.2.5"
langchain-chroma = "0.1.1"
langchainhub = "0.1.20"
streamlit = "1.35.0"

ğŸ’¡ Poetry ã§ Python ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’æŒ‡å®šã™ã‚‹æ™‚ã« ^3.12 ã¨ã™ã‚‹ã¨ lancghain-chroma ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã§ããªããªã‚‹ã®ã§ >=3.12,<3.13 ã¨ã—ã¾ã—ãŸã€‚
(langchain-chroma ã¯ >=3.12,<3.13 ã¨ã„ã†æŒ‡å®šãŒã‚ã‚Šã¾ã™)

 æ–¹æ³•
OpenAI API ã‚’ä½¿ã†å ´åˆã¨ AzureOpenAI API ã‚’ä½¿ã†å ´åˆã¯åŸºæœ¬åŒã˜ã“ã¨ã‚’ã™ã‚‹ã®ã§ã¾ãš OpenAI API ã‚’ä½¿ã†å ´åˆã‚’èª¬æ˜ã—ã€è¨˜äº‹ãŒé•·ããªã£ã¦ã—ã¾ã£ãŸã®ã§ã€å¾Œæ—¥åˆ¥è¨˜äº‹ã«ã¦ AzureOpenAI API ã‚’ä½¿ã†å ´åˆã¯ã©ã®éƒ¨åˆ†ã‚’ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆã—ãŸã‚‰ã‚ˆã„ã®ã‹ã‚’èª¬æ˜ã—ãŸã„ã¨æ€ã„ã¾ã™ã€‚
6/28 è¿½è¨˜) AzureOpenAI API ç‰ˆã®è¨˜äº‹ã‚‚æ›¸ãã¾ã—ãŸã®ã§ã‚ˆã‘ã‚Œã°ãœã²ã©ã†ã
https://zenn.dev/cykinso/articles/b055e33734d06b

 .env
ä»¥ä¸‹ã®ã‚ˆã†ã« .env ã‚’ç”¨æ„ã—ã¾ã™ã€‚
OPENAI_API_KEY=sk-XXXXXXXXXXXXXXXX
OPENAI_API_VERSION=2024-02-01
ã‚‚ã— OPENAI_API_KEY ã‚’ã¾ã å–å¾—ã—ã¦ã„ãªã„å ´åˆã¯ä»¥ä¸‹ã®æ–¹æ³•ã§å–å¾—ã—ã¦ãã ã•ã„ã€‚

 OPENAI_API_KEY
OPENAI_API_KEY ã¯ OpenAI ã® Dashboard ã§ä½œæˆã§ãã¾ã™ã€‚
(èª²é‡‘å¯¾è±¡ãªã®ã§ã”è‡ªèº«ã®è²¬ä»»ã®ã‚‚ã¨ã”åˆ©ç”¨ãã ã•ã„)

ã€Œ+ Create new secret keyã€ ã‚’æŠ¼ã™ã¨ãƒ¢ãƒ¼ãƒ€ãƒ«ãŒé–‹ãã®ã§å¾Œã‹ã‚‰åŒºåˆ¥ã§ãã‚‹ã‚ˆã†ãªåå‰ã‚’ã¤ã‘ã¦ ã€ŒCreate secret keyã€ ã‚’æŠ¼ã—ã¾ã™ã€‚

è¡¨ç¤ºã•ã‚Œã‚‹ API ã‚­ãƒ¼ã‚’ .env ã«ãƒ¡ãƒ¢ã—ã¦ãŠãã¾ã™ã€‚ ã€ŒDoneã€ ã‚’æŠ¼ã™ã¨ã‚‚ã†è¡¨ç¤ºã§ãã¾ã›ã‚“ã€‚


 ãƒ‡ãƒ¼ã‚¿
OpenAI ãŒã¾ã å­¦ç¿’ã—ã¦ã„ãªã•ãã†ãªãƒ‡ãƒ¼ã‚¿ã®ä¾‹ã¨ã—ã¦å¼Šç¤¾ Cykinso ã®ãƒ–ãƒ­ã‚°è¨˜äº‹ã®ã€Œä¼šç¤¾ã®ãƒ“ã‚¸ãƒ§ãƒ³ã‚’è©±ã—ã¦ã„ã‚‹ãƒšãƒ¼ã‚¸ã€ã‚’ä»Šå›ã¯ç”¨ã„ãŸã„ã¨æ€ã„ã¾ã™ã€‚
https://note.com/cykinso/n/n432d5ea70783
ğŸ’¡ ãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆã§å®Ÿè£…ã™ã‚‹å ´åˆã¯ã€å¥½ããªãƒãƒ³ã‚¬ãªã©ã®è©³ç´°ã‚’ãƒ†ã‚­ã‚¹ãƒˆã«ã¾ã¨ã‚ã¦ãƒ‡ãƒ¼ã‚¿ã¨ã™ã‚‹ã¨ãƒ¢ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³ã‚‚ä¸ŠãŒã‚‹ã¨æ€ã„ã¾ã™ã€‚
ã–ã£ã¨æ–‡ç« ã‚’ã‚³ãƒ”ãƒ¼ã—ã¦ä»¥ä¸‹ã®ã‚ˆã†ã«æ•´å½¢ã—ã¾ã—ãŸã€‚

note.txt
ç´°èŒå¢ã‹ã‚‰ã®æ–°ãŸãªæ°—ä»˜ãã‚’é€šã˜ã¦ã€æ–°ãƒ“ã‚¸ãƒ§ãƒ³ã‚’ç­–å®šã—ã¾ã—ãŸï¼
2023å¹´11æœˆã«ã‚µã‚¤ã‚­ãƒ³ã‚½ãƒ¼ã¯10æœŸç›®ã«å…¥ã‚Šã¾ã—ãŸã€‚é«˜é½¢åŒ–ç¤¾ä¼šã«ã‚ˆã‚‹ç¤¾ä¼šä¿éšœã¸ã®ä¸å®‰ãŒå‹Ÿã‚‹ç¾åœ¨ã€ç—…æ°—ã‚’æœªç„¶ã«é˜²ã0æ¬¡äºˆé˜²ã®é‡è¦æ€§ãŒé«˜ã¾ã£ã¦ã„ã¾ã™ã€‚ã€Œç´°èŒå¢ã§äººã€…ã‚’å¥åº·ã«ã€ã¨ã„ã†ãƒŸãƒƒã‚·ãƒ§ãƒ³ã«å‘ã‘ã¦ã€ã‚µã‚¤ã‚­ãƒ³ã‚½ãƒ¼ã¯æ–°ãŸãªãƒ“ã‚¸ãƒ§ãƒ³ã‚’åˆ¶å®šã—ã¾ã—ãŸã€‚
æ–°ã—ã„ãƒ“ã‚¸ãƒ§ãƒ³ã«ã¤ã„ã¦
ãƒ¼ãƒ“ã‚¸ãƒ§ãƒ³å¤‰æ›´ã§å…·ä½“çš„ã«ã©ã®å€‹æ‰€ãŒå¤‰æ›´ã—ãŸã‹ã‚’ã¾ãšã”ç´¹ä»‹ã—ã¾ã™ã€‚
ã“ã¡ã‚‰ãŒã‚µã‚¤ã‚­ãƒ³ã‚½ãƒ¼ã®ãƒŸãƒƒã‚·ãƒ§ãƒ³ï¼ˆMISSIONï¼‰ã€ãƒ“ã‚¸ãƒ§ãƒ³(VISION)ã€ãƒãƒªãƒ¥ãƒ¼(VALUE)ã«ãªã‚Šã¾ã™ã€‚
ç§ãŸã¡ãŒç›®æŒ‡ã—ç¶šã‘ã‚‹ã€Œç´°èŒå¢ã§äººã€…ã‚’å¥åº·ã«ã€ã¨ã„ã†ãƒŸãƒƒã‚·ãƒ§ãƒ³ã¯ãã®ã¾ã¾ã«ã€ãƒ“ã‚¸ãƒ§ãƒ³ã‚’æ–°ã—ãå¤‰æ›´è‡´ã—ã¾ã—ãŸã€‚

ï¼œã“ã‚Œã¾ã§ã®ãƒ“ã‚¸ãƒ§ãƒ³ï¼
èŒå¢ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã€Œæ¬¡ä¸–ä»£ã®ãƒ©ã‚¤ãƒ•ã‚¹ã‚¿ã‚¤ãƒ«ã€ã‚’æä¾›ã™ã‚‹ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã«ãªã‚‹

ï¼œæ–°ã—ã„ãƒ“ã‚¸ãƒ§ãƒ³ï¼
ç´°èŒå¢ã‹ã‚‰ã®æ–°ãŸãªæ°—ä»˜ãã‚’é€šã˜ã¦
ãƒ’ãƒˆã€ç¤¾ä¼šã€åœ°çƒç’°å¢ƒã‚’å¥åº·ã«ã™ã‚‹ã‚¨ã‚³ã‚·ã‚¹ãƒ†ãƒ ã‚’å®Ÿç¾ã™ã‚‹
æ–°ã—ã„ãƒ“ã‚¸ãƒ§ãƒ³ã§ã¯ã€ã‚µã‚¤ã‚­ãƒ³ã‚½ãƒ¼ãŒå½±éŸ¿ã‚’ä¸ãˆã¦ã„ããŸã„ç¯„å›²ã‚‚ã“ã‚Œã¾ã§ã‚ˆã‚Šã•ã‚‰ã«å¤§ãããªã£ãŸã“ã¨ãŒåˆ†ã‹ã‚Šã¾ã™ã€‚

ä»Šå›ã®ãƒ“ã‚¸ãƒ§ãƒ³å¤‰æ›´ã‚’é€šã—ã¦ã€ã‚µã‚¤ã‚­ãƒ³ã‚½ãƒ¼ãŒã©ã‚“ãªä¾¡å€¤ç™ºæ®ã‚’ç›®æŒ‡ã—ã¦ã„ãã®ã‹ã€ãã‚Œã«ä¼´ã„äº‹æ¥­é¢ã§ã¯ã©ã‚“ãªæŒ‘æˆ¦ã‚’ã—ã¦ã„ãã®ã‹ã‚’ã€ä»£è¡¨å–ç· å½¹CEOã®æ²¢äº•ã•ã‚“ã«èã„ã¦ãã¾ã—ãŸï¼

...(ä»¥ä¸‹ç•¥)


 ã‚³ãƒ¼ãƒ‰
ç¶šã‘ã¦ã‚³ãƒ¼ãƒ‰ã‚’å®Ÿè£…ã—ã¾ã™ã€‚
ä»Šå›ã¯ RAG ã¨ã—ã¦å¤–éƒ¨ã®æƒ…å ±ã‚’å‚ç…§ã—ã¤ã¤å›ç­”ã™ã‚‹ ChatBot ã‚’å®Ÿè£…ã—ã¦ã¿ã¾ã™ã€‚
ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã¨ã—ã¦ streamlit ã‚’ç”¨ã„ã¾ã™ã€‚
å…ˆã«ã‚³ãƒ¼ãƒ‰å…¨ä½“ã‚’ç¤ºã™ã¨ä»¥ä¸‹ã®ã‚ˆã†ã«ãªã‚Šã¾ã™ã€‚
(streamlit ã®ã‚³ãƒ¼ãƒ‰ã®ãƒ™ãƒ¼ã‚¹ã¨ã—ã¦ä»¥ä¸‹ã®è¨˜äº‹ã‚’å‚è€ƒã«ã•ã›ã¦ã„ãŸã ãã¾ã—ãŸã€‚ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™)
https://tech-lab.sios.jp/archives/41574

chatbot.py
from pathlib import Path

import streamlit as st
from dotenv import load_dotenv
from langchain import hub
from langchain.schema import AIMessage, HumanMessage
from langchain_chroma import Chroma
from langchain_community.document_loaders import TextLoader
from langchain_core.runnables import RunnablePassthrough, RunnableSequence
from langchain_core.vectorstores import VectorStoreRetriever
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_text_splitters import RecursiveCharacterTextSplitter

load_dotenv()


def initialize_vector_store() -> Chroma:
    """VectorStoreã®åˆæœŸåŒ–."""
    embeddings = OpenAIEmbeddings()

    vector_store_path = "./resources/note.db"
    if Path(vector_store_path).exists():
        vector_store = Chroma(embedding_function=embeddings, persist_directory=vector_store_path)
    else:
        loader = TextLoader("resources/note.txt")
        docs = loader.load()

        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
        splits = text_splitter.split_documents(docs)

        vector_store = Chroma.from_documents(
            documents=splits, embedding=embeddings, persist_directory=vector_store_path
        )

    return vector_store


def initialize_retriever() -> VectorStoreRetriever:
    """Retrieverã®åˆæœŸåŒ–."""
    vector_store = initialize_vector_store()
    return vector_store.as_retriever()


def initialize_chain() -> RunnableSequence:
    """Langchainã®åˆæœŸåŒ–."""
    prompt = hub.pull("rlm/rag-prompt")
    llm = ChatOpenAI()
    retriever = initialize_retriever()
    chain = (
        {"context": retriever, "question": RunnablePassthrough()} | prompt | llm
    )
    return chain


def main() -> None:
    """ChatGPTã‚’ä½¿ã£ãŸãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã®ãƒ¡ã‚¤ãƒ³é–¢æ•°."""
    chain = initialize_chain()

    # ãƒšãƒ¼ã‚¸ã®è¨­å®š
    st.set_page_config(page_title="RAG ChatGPT")
    st.header("RAG ChatGPT")

    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®åˆæœŸåŒ–
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ã‚’ç›£è¦–
    if user_input := st.chat_input("èããŸã„ã“ã¨ã‚’å…¥åŠ›ã—ã¦ã­ï¼"):
        st.session_state.messages.append(HumanMessage(content=user_input))
        with st.spinner("GPT is typing ..."):
            response = chain.invoke(user_input)
        st.session_state.messages.append(AIMessage(content=response.content))

    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®è¡¨ç¤º
    messages = st.session_state.get("messages", [])
    for message in messages:
        if isinstance(message, AIMessage):
            with st.chat_message("assistant"):
                st.markdown(message.content)
        elif isinstance(message, HumanMessage):
            with st.chat_message("user"):
                st.markdown(message.content)
        else:
            st.write(f"System message: {message.content}")


if __name__ == "__main__":
    main()

ã‚³ãƒ¼ãƒ‰ã®å„éƒ¨åˆ†ã‚’èª¬æ˜ã—ã¦ã„ãã¾ã™ã€‚

 initialize_vector_store
def initialize_vector_store() -> Chroma:
    """VectorStoreã®åˆæœŸåŒ–."""
    embeddings = OpenAIEmbeddings()

    vector_store_path = "./resources/note.db"
    if Path(vector_store_path).exists():
        vector_store = Chroma(embedding_function=embeddings, persist_directory=vector_store_path)
    else:
        loader = TextLoader("resources/note.txt")
        docs = loader.load()

        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
        splits = text_splitter.split_documents(docs)

        vector_store = Chroma.from_documents(
            documents=splits, embedding=embeddings, persist_directory=vector_store_path
        )

    return vector_store
Vector store ã¨ã¯æƒ…å ±ã¨ã—ã¦èª­ã¿è¾¼ã¾ã›ã¦ã„ã‚‹ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’é©åˆ‡ãªé•·ã•ã«åˆ†å‰²ã—(ãƒãƒ£ãƒ³ã‚¯ã¨å‘¼ã°ã‚Œã¾ã™) ã™ãã«å–ã‚Šå‡ºã›ã‚‹ã‚ˆã†ã«ä¿å­˜ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ã‚ˆã†ãªã‚‚ã®ã§ã™ã€‚
Embeddings ã¨å‘¼ã°ã‚Œã‚‹ãƒ¢ãƒ‡ãƒ«ã§ãƒ†ã‚­ã‚¹ãƒˆã¯æ•°å€¤æƒ…å ±ã®ãƒ™ã‚¯ãƒˆãƒ«ã«ä¿å­˜ã•ã‚Œã¾ã™ã€‚ãã®ä½œæ¥­ã‚’è¡Œã†ãŸã‚ã« OpenAI API ãŒå¿…è¦ã«ãªã£ã¦ã„ã‚‹ãŸã‚é–¢æ•°ã®æœ€åˆã§ OpenAIEmbeddings ã‚’å‘¼ã³å‡ºã—ã¦ã„ã¾ã™ã€‚
ç¶šã‘ã¦ Vector store ã¨ã—ã¦ä¿å­˜ã•ã‚Œã¦ã„ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã™ã§ã«å­˜åœ¨ã—ã¦ã„ãªã„ã‹ã‚’èª¿ã¹ã¦ã„ã¾ã™ã€‚åŸºæœ¬çš„ã«ãƒ‡ãƒ¼ã‚¿ã‚„ãƒ¢ãƒ‡ãƒ«ãŒã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆã•ã‚Œãªã„é™ã‚Š Vector store ã®ãƒ‡ãƒ¼ã‚¿ã¯ã¾ã£ãŸãåŒã˜ã«ãªã‚‹ãŸã‚ã€æ¯å›å®Ÿè¡Œã—ã¦ã—ã¾ã†ã¨æ™‚é–“ã‚‚ API ã®åˆ©ç”¨æ–™é‡‘ã‚‚ç„¡é§„ã«ãªã£ã¦ã—ã¾ã„ã¾ã™ã€‚
ãã“ã§

ã¾ã å­˜åœ¨ã—ã¦ã„ãªã„å ´åˆï¼š æ–°è¦ä½œæˆ
ã™ã§ã«å­˜åœ¨ã—ã¦ã„ã‚‹å ´åˆï¼š ä¿å­˜ã—ã¦ã„ã‚‹ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’èª­ã¿è¾¼ã‚€

ã¨ã—ã¦ã„ã¾ã™ã€‚
ãªãŠå­˜åœ¨ã—ã¦ã„ã‚‹å ´åˆ Chroma ã‚¯ãƒ©ã‚¹ã®å¼•æ•° embedding_function ã« embeddings ã‚’æŒ‡å®šã—ã¦ã„ã¾ã™ãŒã€ã“ã‚Œã¯ã‚¯ã‚¨ãƒªã¨ã—ã¦ã‚ãŸãˆã‚‰ã‚Œã‚‹ãƒ¦ãƒ¼ã‚¶ã®è³ªå•ã¨ Vector store ã«ä¿å­˜ã•ã‚Œã¦ã„ã‚‹ãƒ‡ãƒ¼ã‚¿ã¨ã®é–“ã®é–¢é€£æ€§ã‚’èª¿ã¹ã‚‹ãŸã‚ã«ã€ã‚¯ã‚¨ãƒªã‚‚ Embeddings ã§ãƒ™ã‚¯ãƒˆãƒ«ã«å¤‰æ›ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã‹ã‚‰ã§ã™ã€‚

 initialize_retriver
def initialize_retriever() -> VectorStoreRetriever:
    """Retrieverã®åˆæœŸåŒ–."""
    vector_store = initialize_vector_store()
    return vector_store.as_retriever()
ã“ã¡ã‚‰ã§ã¯ã€å…ˆã»ã©ä½œæˆã—ãŸ(ã‚ã‚‹ã„ã¯ã™ã§ã«ã‚ã‚‹ã‚‚ã®ã‚’èª­ã¿è¾¼ã‚“ã ) vector_store ã‚’ retriever ã«å¤‰æ›ã—ã¦ã„ã¾ã™ã€‚ã“ã¡ã‚‰ã® retriever ã“ã®å¾Œã€ Vectore store ã‹ã‚‰æƒ…å ±ã‚’å–ã‚Šå‡ºã™ã®ã«åˆ©ç”¨ã•ã‚Œã¾ã™ã€‚

 initialize_chain
def initialize_chain() -> RunnableSequence:
    """Langchainã®åˆæœŸåŒ–."""
    prompt = hub.pull("rlm/rag-prompt")
    llm = ChatOpenAI()
    retriever = initialize_retriever()
    chain = (
        {"context": retriever, "question": RunnablePassthrough()} | prompt | llm
    )
    return chain
ã“ã¡ã‚‰ã§ã¯ retriever ã®æƒ…å ±ã‚’ LLM ã§åˆ©ç”¨ã§ãã‚‹ã‚ˆã†ã« chain ã¨å‘¼ã°ã‚Œã‚‹æ¦‚å¿µã‚’åˆ©ç”¨ã—ã¦ãŠã‚Šã¾ã™ã€‚
ã‚ˆããƒ¡ã‚½ãƒƒãƒ‰ãƒã‚§ãƒ¼ãƒ³ã¨ã„ã†è¨€è‘‰ãŒãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°è¨€èªã§ã¯ä½¿ã‚ã‚Œã¦ã„ã¾ã™ã€‚
ä¾‹ãˆã° Python ã® Pandas ã§ã¯
import pandas as pd

# ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
data = {
    'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Edward', 'Frank'],
    'Age': [24, 27, 22, 32, 29, 24],
    'City': ['New York', 'Los Angeles', 'New York', 'Chicago', 'Los Angeles', 'New York'],
    'Score': [85, 90, 88, 92, 95, 70]
}

df = pd.DataFrame(data)

# ãƒ¡ã‚½ãƒƒãƒ‰ãƒã‚§ãƒ¼ãƒ³ã‚’ä½¿ã£ãŸãƒ‡ãƒ¼ã‚¿å¤‰æ›
result = (df
          .query('Age > 25')                     # å¹´é½¢ãŒ25ä»¥ä¸Šã®è¡Œã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
          .groupby('City')                       # éƒ½å¸‚ã”ã¨ã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
          .agg({'Score': 'mean'})                # ã‚¹ã‚³ã‚¢ã®å¹³å‡ã‚’è¨ˆç®—
          .rename(columns={'Score': 'Average Score'})  # åˆ—åã‚’å¤‰æ›´
          .sort_values(by='Average Score', ascending=False)  # å¹³å‡ã‚¹ã‚³ã‚¢ã§ä¸¦ã¹æ›¿ãˆ
          .reset_index()                         # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ãƒªã‚»ãƒƒãƒˆ
         )

print(result)
ã¨ã„ã†ã‚ˆã†ã«ãƒ¡ã‚½ãƒƒãƒ‰ã®è¿”ã‚Šå€¤ã‚’æ¬¡ã®ãƒ¡ã‚½ãƒƒãƒ‰ã¸ã¨ãƒã‚±ãƒ„ãƒªãƒ¬ãƒ¼ã®ã‚ˆã†ã«ã¤ãªã„ã§è¡Œãå‡¦ç†ã•ã›ã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚ã“ã‚Œã‚’ãƒ¡ã‚½ãƒƒãƒ‰ãƒã‚§ãƒ¼ãƒ³ã¨ã„ã„ã¾ã™ã€‚
LangChain ã§ã‚‚ã“ã®ãƒã‚±ãƒ„ãƒªãƒ¬ãƒ¼ã‚’è¡Œã„ã€ã©ã®ã‚ˆã†ã«ãƒ¦ãƒ¼ã‚¶ã®è³ªå•ã«ç­”ãˆã‚‹ã‹ã®ãƒ«ãƒ¼ãƒ«ã‚’æ±ºã‚ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚
LangChain ã®å ´åˆã¯æ˜”ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã§ã¯é–¢æ•°ã®è¿”ã‚Šå€¤ã‚’ã•ã‚‰ã«é–¢æ•°ã®å¼•æ•°ã«ã™ã‚‹ã¨è¨€ã†ã“ã¨ã‚’ç¹°ã‚Šè¿”ã—ã¦ãƒã‚±ãƒ„ãƒªãƒ¬ãƒ¼ã‚’è¡Œã£ã¦ã„ã¾ã—ãŸãŒã€ä»Šã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ 0.2.5 ã§ã¯ä»¥ä¸‹ã®ã‚ˆã†ã« | ã‚’åˆ©ç”¨ã—ãƒã‚§ãƒ¼ãƒ³ã‚’ç¤ºã™ã“ã¨ãŒæ¨å¥¨ã•ã‚Œã¦ã„ã¾ã™ã€‚
    chain = (
        {"context": retriever, "question": RunnablePassthrough()} | prompt | llm
    )
ä»Šå›ã®å ´åˆ

{"context": retriever, "question": RunnablePassthrough()}
prompt
llm

ã¨ã„ã†é †ç•ªã§ãƒã‚§ãƒ¼ãƒ³ãŒã¤ãªãŒã£ã¦ã„ã¾ã™ã€‚
ãƒã‚§ãƒ¼ãƒ³ã®å…ˆé ­ãŒãªãœè¾æ›¸ã§ã‚ã‚‹ã‹ã¯ã€2ç•ªç›®ã® prompt ã®èª¬æ˜ã‚’èã„ã¦ã‚‚ã‚‰ãˆã‚Œã°ã‚ã‹ã‚‹ã¨æ€ã„ã¾ã™ã€‚
    prompt = hub.pull("rlm/rag-prompt")
prompt ã¯ LLM ã«ã©ã®ã‚ˆã†ãªè³ªå•ã‚„ä¾é ¼ã‚’ã™ã‚‹ã®ã‹ã‚’æ±ºã‚ã‚‹éƒ¨åˆ†ã§ã™ã€‚ä»Šå›ã¯ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ(å¤‰æ•°åã‚’æŒ‡ã—ã¦ã„ãªã„å ´åˆã‚«ã‚¿ã‚«ãƒŠè¡¨è¨˜ã¨ã—ã¾ã™)ã‚’æœ‰å¿—ã®æ–¹ãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ä»–ã®äººãŒåˆ©ç”¨ã§ãã‚‹ã‚ˆã†ã«ã—ã¦ãã‚Œã¦ã„ã‚‹ã‚µã‚¤ãƒˆ LangChain Hub ã‹ã‚‰ â­ ãŒå¤šã„ã‚‚ã®ã‚’ãŠå€Ÿã‚Šã—ã¦ãã¾ã—ãŸã€‚ã‚‚ã¡ã‚ã‚“è‡ªä½œã—ã¦ã‚‚ã‚‰ã£ã¦ã‚‚OKã§ã™ã€‚
https://smith.langchain.com/hub/rlm/rag-prompt
ãŠå€Ÿã‚Šã—ãŸ rag-prompt ã§ã¯ä»¥ä¸‹ã®ã‚ˆã†ã«ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒå®šç¾©ã•ã‚Œã¦ã„ã¾ã™ã€‚
You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.
Question: {question} 
Context: {context} 
Answer:
ç°¡å˜ã«æ—¥æœ¬èªã«è¨³ã™ã¨ ã€Œ context ã®æƒ…å ±ã®ã¿ã‚’ä½¿ã£ã¦ question ã«ç­”ãˆã‚‹ã‚ˆã†ã« Answer ã‚’è€ƒãˆãªã•ã„ã€‚ç­”ãˆã‚‰ã‚Œãªã„ãªã‚‰ã‚ã‹ã‚‰ãªã„ã¨ç­”ãˆãªã•ã„ã€‚ã€ ã¨ãªã‚Šã¾ã™ã€‚ context ã®æƒ…å ±ã®ã¿ã‚’ç”¨ã„ã‚‹ã‚ˆã†æŒ‡å®šã™ã‚‹ã“ã¨ã§ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³ã‚’é˜²ãåŠ¹æœãŒã‚ã‚Šã¾ã™ (ãŸã ã—ï¼‘ï¼ï¼ï¼…é˜²ãã¨ã¯æ–­è¨€ã§ããªã„ã§ã™)
ã“ã¡ã‚‰ã® question éƒ¨åˆ†ã«ãƒ¦ãƒ¼ã‚¶ã®ã‚¯ã‚¨ãƒªãŒã€ context éƒ¨åˆ†ã« retriever ã‚’æŒ‡å®šã—ã¦ prompt ã‚’å®Ÿè¡Œã›ã‚ˆã¨ã—ã¦ã„ã‚‹ã®ãŒãƒã‚§ãƒ¼ãƒ³ã® {"context": retriever, "question": RunnablePassthrough()} | prompt ã®éƒ¨åˆ†ã§ã™ã€‚
æœ€å¾Œã«å®Œæˆã—ãŸ prompt ã‚’ llm ã«æ¸¡ã—ãªã•ã„ã¨æŒ‡å®šã—ã¦ã„ã‚‹ã®ãŒ prompt | llm ã®éƒ¨åˆ†ã§ã™ã€‚
ã“ã®ãƒ¡ã‚½ãƒƒãƒ‰ãƒã‚§ãƒ¼ãƒ³ã‚’ã¾ã¨ã‚ãŸ chain ã¨ã„ã†å¤‰æ•°ã¯ invoke ãƒ¡ã‚½ãƒƒãƒ‰ã‚’æŒã£ã¦ãŠã‚Šã€ã“ã®ãƒ¡ã‚½ãƒƒãƒ‰ã«è³ªå•ã‚’æŠ•ã’ã‚‹ã¨ãã‚ŒãŒ question ã«å…¥ã‚Šãƒã‚§ãƒ¼ãƒ³ãŒå‰ã‹ã‚‰é †ç•ªã«å®Ÿè¡Œã•ã‚Œã¾ã™ã€‚
ä»¥ä¸Šã®ã‚ˆã†ã«å®šç¾©ã™ã‚‹ã“ã¨ã§ RAG ã¨ã—ã¦å¤–éƒ¨ã®æƒ…å ±ã‚’å‚ç…§ã—ã¤ã¤å›ç­”ã™ã‚‹ ChatBot ã‚’å®Ÿè£…ã§ãã¾ã—ãŸã€‚

 main
def main() -> None:
    """ChatGPTã‚’ä½¿ã£ãŸãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã®ãƒ¡ã‚¤ãƒ³é–¢æ•°."""
    chain = initialize_chain()

    # ãƒšãƒ¼ã‚¸ã®è¨­å®š
    st.set_page_config(page_title="RAG ChatGPT")
    st.image(img, use_column_width=False)
    st.header("RAG ChatGPT")

    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®åˆæœŸåŒ–
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ã‚’ç›£è¦–
    if user_input := st.chat_input("èããŸã„ã“ã¨ã‚’å…¥åŠ›ã—ã¦ã­ï¼"):
        st.session_state.messages.append(HumanMessage(content=user_input))
        with st.spinner("GPT is typing ..."):
            response = chain.invoke(user_input)
        st.session_state.messages.append(AIMessage(content=response.content))

    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®è¡¨ç¤º
    messages = st.session_state.get("messages", [])
    for message in messages:
        if isinstance(message, AIMessage):
            with st.chat_message("assistant"):
                st.markdown(message.content)
        elif isinstance(message, HumanMessage):
            with st.chat_message("user"):
                st.markdown(message.content)
        else:
            st.write(f"System message: {message.content}")
æœ€å¾Œã« main é–¢æ•°ã§ã™ã€‚ã“ã¡ã‚‰ã¯ LangChain ã®å®Ÿè£…ã¨ã„ã†ã‚ˆã‚Šã¯ Streamlit ã‚’åˆ©ç”¨ã—ãŸãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰éƒ¨åˆ†ã®å®Ÿè£…ã«ãªã‚Šã¾ã™ã€‚
ã‚­ãƒ¼ã¨ãªã‚‹ç‚¹ã ã‘è§£èª¬ã™ã‚‹ã¨

ãƒ¦ãƒ¼ã‚¶ã¨ ChatBot ã®ä¼šè©±ã¯ messages ã«ä¿å­˜ã•ã‚Œã¦ã„ã¾ã™ã€‚ä»¥ä¸‹ã®ã‚³ãƒ¼ãƒ‰ã‚’è¦‹ã‚‹ã¨ã‚ã‹ã‚‹ã‚ˆã†ã«ãƒ¦ãƒ¼ã‚¶ã‹ã‚‰ã®è³ªå•ã¨ ChatBot ã®è¿”ç­”ã¯ã©ã¡ã‚‰ã‚‚ messages ã« append ã•ã‚Œã¦ã„ã¾ã™ã€‚

    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®åˆæœŸåŒ–
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ã‚’ç›£è¦–
    if user_input := st.chat_input("èããŸã„ã“ã¨ã‚’å…¥åŠ›ã—ã¦ã­ï¼"):
        st.session_state.messages.append(HumanMessage(content=user_input))
        with st.spinner("GPT is typing ..."):
            response = chain.invoke(user_input)
        st.session_state.messages.append(AIMessage(content=response.content))

ãƒ¦ãƒ¼ã‚¶ã‹ã‚‰ã®è³ªå•ã¸ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã¯å…ˆã»ã©å®šç¾©ã—ãŸ chain ã® invoke ãƒ¡ã‚½ãƒƒãƒ‰ã‚’ç”¨ã„ã¦ä½œã‚‰ã‚Œã¦ã„ã¾ã™ã€‚

        with st.spinner("GPT is typing ..."):
            response = chain.invoke(user_input)
        st.session_state.messages.append(AIMessage(content=response.content))
ã¨ã„ã†ç‚¹ãŒã‚ã’ã‚‰ã‚Œã¾ã™ã€‚

 ãƒ†ã‚¹ãƒˆ
ãã‚Œã§ã¯å®Ÿè£…ã—ãŸã‚‚ã®ã‚’å‹•ã‹ã—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚
> streamlit run chatbot.py

Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.


  You can now view your Streamlit app in your browser.

  Local URL: http://localhost:8501
  Network URL: http://10.200.0.4:8501
  External URL: http://13.73.233.61:8501
http://localhost:8501 ã¸ãƒ–ãƒ©ã‚¦ã‚¶ã‹ã‚‰ã‚¢ã‚¯ã‚»ã‚¹ã—ã€è³ªå•ã—ã¦ã¿ã¾ã™ã€‚

ç¾æ™‚ç‚¹ã§ã® note.txt ã®å…ˆé ­ã®æ–¹ã«æ›¸ã„ã¦ã‚ã£ãŸæ–°ã—ã„ãƒ“ã‚¸ãƒ§ãƒ³ã‚’ã¡ã‚ƒã‚“ã¨ç­”ãˆã¦ã„ã¾ã™ã€‚ã“ã®æƒ…å ±ã¯ OpenAI ã«ã¯ãªã„ãŸã‚ãã¡ã‚“ã¨ RAG ãŒåƒã„ã¦ã„ã‚‹ã¨è¨€ãˆãã†ã§ã™ã€‚

ã¾ãŸã€Œ100å¹´å¾Œã«ç™ºå£²äºˆå®šã®æ–°å•†å“ã€ã¨ã„ã†æƒ…å ±ã¨ã—ã¦å«ã¾ãªã„ã‚ˆã†ãªè³ªå•ã‚’ã™ã‚‹ã¨ã¡ã‚ƒã‚“ã¨ã€Œæƒ…å ±ã‚’æŒã£ã¦ã„ãªã„ã€ã¨è¿”ç­”ã—ã¦ãã‚Œã¾ã™ã€‚ã“ã¡ã‚‰ã‚‚æœŸå¾…é€šã‚Šã§ã™ã­ã€‚

 ğŸ’¡ ã¾ã¨ã‚

LangChain v0.2.5 æ™‚ç‚¹ã§ã® RAG ã‚’ç”¨ã„ãŸ ChatBot ã®å®Ÿè£…ã‚’è¡Œã„ã¾ã—ãŸ
Streamlit ã‚’ç”¨ã„ã¦ãƒ–ãƒ©ã‚¦ã‚¶ã‹ã‚‰ãƒ¦ãƒ¼ã‚¶ãŒã‚¢ã‚¯ã‚»ã‚¹ã§ãã‚‹ã‚ˆã†ã«ã—ã¾ã—ãŸ

ãœã²å‚è€ƒã«ã—ã¦ã¿ã¦ãã ã•ã„ã€‚

div
 èƒŒæ™¯
LangChain ã¯ OpenAI API ã‚’åˆ©ç”¨ã—è‡ªåˆ†ãŸã¡ãŒã‚„ã‚ŠãŸã„ã“ã¨ã‚’å®Ÿç¾ã™ã‚‹ã“ã¨ã«éå¸¸ã«ä¾¿åˆ©ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã§ã™ãŒãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚¢ãƒƒãƒ—ã«ã‚ˆã£ã¦ã‚¯ãƒ©ã‚¹åã‚„ã‚µãƒ–ãƒ©ã‚¤ãƒ–ãƒ©ãƒªåã®å¤‰æ›´ãŒã‚„ã‚„å¤šãå°‘ã—å¤ã„ Web è¨˜äº‹ã‚’å‚è€ƒã«ã—ã¦ã‚‚ã†ã¾ããƒ¯ãƒ¼ã‚¯ã—ãªã„ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚
ã“ã®è¨˜äº‹ã¯ 2024/6/20 ç¾åœ¨ã® LangChain (ãƒãƒ¼ã‚¸ãƒ§ãƒ³ 0.2.5) ã§ OpenAI API ã‚„ Azure OpenAI API ã‚’å‹•ã‹ã™ä¾‹ã¨ã—ã¦æ®‹ã—ã¦ãŠãã¾ã™ã€‚
åŒã˜ã‚ˆã†ãªã“ã¨ã‚’ã—ã‚ˆã†ã¨ã—ã¦ç§ã®ã‚ˆã†ã«è‹¦æˆ¦ã—ã¦ã„ã‚‹æ–¹ã®åŠ©ã‘ã«ãªã‚Œã°å¹¸ã„ã§ã™ã€‚

 ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ãªã©

pyproject.toml
python = ">=3.12,<3.13"
python-dotenv = "^1.0.1"
chromadb = "0.5.2"
langchain = "0.2.5"
langchain-cli = "0.0.25"
langchain-openai = "0.1.8"
langchain-community = "0.2.5"
langchain-chroma = "0.1.1"
langchainhub = "0.1.20"
streamlit = "1.35.0"

ğŸ’¡ Poetry ã§ Python ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’æŒ‡å®šã™ã‚‹æ™‚ã« ^3.12 ã¨ã™ã‚‹ã¨ lancghain-chroma ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã§ããªããªã‚‹ã®ã§ >=3.12,<3.13 ã¨ã—ã¾ã—ãŸã€‚
(langchain-chroma ã¯ >=3.12,<3.13 ã¨ã„ã†æŒ‡å®šãŒã‚ã‚Šã¾ã™)

 æ–¹æ³•
OpenAI API ã‚’ä½¿ã†å ´åˆã¨ AzureOpenAI API ã‚’ä½¿ã†å ´åˆã¯åŸºæœ¬åŒã˜ã“ã¨ã‚’ã™ã‚‹ã®ã§ã¾ãš OpenAI API ã‚’ä½¿ã†å ´åˆã‚’èª¬æ˜ã—ã€è¨˜äº‹ãŒé•·ããªã£ã¦ã—ã¾ã£ãŸã®ã§ã€å¾Œæ—¥åˆ¥è¨˜äº‹ã«ã¦ AzureOpenAI API ã‚’ä½¿ã†å ´åˆã¯ã©ã®éƒ¨åˆ†ã‚’ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆã—ãŸã‚‰ã‚ˆã„ã®ã‹ã‚’èª¬æ˜ã—ãŸã„ã¨æ€ã„ã¾ã™ã€‚
6/28 è¿½è¨˜) AzureOpenAI API ç‰ˆã®è¨˜äº‹ã‚‚æ›¸ãã¾ã—ãŸã®ã§ã‚ˆã‘ã‚Œã°ãœã²ã©ã†ã
https://zenn.dev/cykinso/articles/b055e33734d06b

 .env
ä»¥ä¸‹ã®ã‚ˆã†ã« .env ã‚’ç”¨æ„ã—ã¾ã™ã€‚
OPENAI_API_KEY=sk-XXXXXXXXXXXXXXXX
OPENAI_API_VERSION=2024-02-01
ã‚‚ã— OPENAI_API_KEY ã‚’ã¾ã å–å¾—ã—ã¦ã„ãªã„å ´åˆã¯ä»¥ä¸‹ã®æ–¹æ³•ã§å–å¾—ã—ã¦ãã ã•ã„ã€‚

 OPENAI_API_KEY
OPENAI_API_KEY ã¯ OpenAI ã® Dashboard ã§ä½œæˆã§ãã¾ã™ã€‚
(èª²é‡‘å¯¾è±¡ãªã®ã§ã”è‡ªèº«ã®è²¬ä»»ã®ã‚‚ã¨ã”åˆ©ç”¨ãã ã•ã„)

ã€Œ+ Create new secret keyã€ ã‚’æŠ¼ã™ã¨ãƒ¢ãƒ¼ãƒ€ãƒ«ãŒé–‹ãã®ã§å¾Œã‹ã‚‰åŒºåˆ¥ã§ãã‚‹ã‚ˆã†ãªåå‰ã‚’ã¤ã‘ã¦ ã€ŒCreate secret keyã€ ã‚’æŠ¼ã—ã¾ã™ã€‚

è¡¨ç¤ºã•ã‚Œã‚‹ API ã‚­ãƒ¼ã‚’ .env ã«ãƒ¡ãƒ¢ã—ã¦ãŠãã¾ã™ã€‚ ã€ŒDoneã€ ã‚’æŠ¼ã™ã¨ã‚‚ã†è¡¨ç¤ºã§ãã¾ã›ã‚“ã€‚


 ãƒ‡ãƒ¼ã‚¿
OpenAI ãŒã¾ã å­¦ç¿’ã—ã¦ã„ãªã•ãã†ãªãƒ‡ãƒ¼ã‚¿ã®ä¾‹ã¨ã—ã¦å¼Šç¤¾ Cykinso ã®ãƒ–ãƒ­ã‚°è¨˜äº‹ã®ã€Œä¼šç¤¾ã®ãƒ“ã‚¸ãƒ§ãƒ³ã‚’è©±ã—ã¦ã„ã‚‹ãƒšãƒ¼ã‚¸ã€ã‚’ä»Šå›ã¯ç”¨ã„ãŸã„ã¨æ€ã„ã¾ã™ã€‚
https://note.com/cykinso/n/n432d5ea70783
ğŸ’¡ ãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆã§å®Ÿè£…ã™ã‚‹å ´åˆã¯ã€å¥½ããªãƒãƒ³ã‚¬ãªã©ã®è©³ç´°ã‚’ãƒ†ã‚­ã‚¹ãƒˆã«ã¾ã¨ã‚ã¦ãƒ‡ãƒ¼ã‚¿ã¨ã™ã‚‹ã¨ãƒ¢ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³ã‚‚ä¸ŠãŒã‚‹ã¨æ€ã„ã¾ã™ã€‚
ã–ã£ã¨æ–‡ç« ã‚’ã‚³ãƒ”ãƒ¼ã—ã¦ä»¥ä¸‹ã®ã‚ˆã†ã«æ•´å½¢ã—ã¾ã—ãŸã€‚

note.txt
ç´°èŒå¢ã‹ã‚‰ã®æ–°ãŸãªæ°—ä»˜ãã‚’é€šã˜ã¦ã€æ–°ãƒ“ã‚¸ãƒ§ãƒ³ã‚’ç­–å®šã—ã¾ã—ãŸï¼
2023å¹´11æœˆã«ã‚µã‚¤ã‚­ãƒ³ã‚½ãƒ¼ã¯10æœŸç›®ã«å…¥ã‚Šã¾ã—ãŸã€‚é«˜é½¢åŒ–ç¤¾ä¼šã«ã‚ˆã‚‹ç¤¾ä¼šä¿éšœã¸ã®ä¸å®‰ãŒå‹Ÿã‚‹ç¾åœ¨ã€ç—…æ°—ã‚’æœªç„¶ã«é˜²ã0æ¬¡äºˆé˜²ã®é‡è¦æ€§ãŒé«˜ã¾ã£ã¦ã„ã¾ã™ã€‚ã€Œç´°èŒå¢ã§äººã€…ã‚’å¥åº·ã«ã€ã¨ã„ã†ãƒŸãƒƒã‚·ãƒ§ãƒ³ã«å‘ã‘ã¦ã€ã‚µã‚¤ã‚­ãƒ³ã‚½ãƒ¼ã¯æ–°ãŸãªãƒ“ã‚¸ãƒ§ãƒ³ã‚’åˆ¶å®šã—ã¾ã—ãŸã€‚
æ–°ã—ã„ãƒ“ã‚¸ãƒ§ãƒ³ã«ã¤ã„ã¦
ãƒ¼ãƒ“ã‚¸ãƒ§ãƒ³å¤‰æ›´ã§å…·ä½“çš„ã«ã©ã®å€‹æ‰€ãŒå¤‰æ›´ã—ãŸã‹ã‚’ã¾ãšã”ç´¹ä»‹ã—ã¾ã™ã€‚
ã“ã¡ã‚‰ãŒã‚µã‚¤ã‚­ãƒ³ã‚½ãƒ¼ã®ãƒŸãƒƒã‚·ãƒ§ãƒ³ï¼ˆMISSIONï¼‰ã€ãƒ“ã‚¸ãƒ§ãƒ³(VISION)ã€ãƒãƒªãƒ¥ãƒ¼(VALUE)ã«ãªã‚Šã¾ã™ã€‚
ç§ãŸã¡ãŒç›®æŒ‡ã—ç¶šã‘ã‚‹ã€Œç´°èŒå¢ã§äººã€…ã‚’å¥åº·ã«ã€ã¨ã„ã†ãƒŸãƒƒã‚·ãƒ§ãƒ³ã¯ãã®ã¾ã¾ã«ã€ãƒ“ã‚¸ãƒ§ãƒ³ã‚’æ–°ã—ãå¤‰æ›´è‡´ã—ã¾ã—ãŸã€‚

ï¼œã“ã‚Œã¾ã§ã®ãƒ“ã‚¸ãƒ§ãƒ³ï¼
èŒå¢ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã€Œæ¬¡ä¸–ä»£ã®ãƒ©ã‚¤ãƒ•ã‚¹ã‚¿ã‚¤ãƒ«ã€ã‚’æä¾›ã™ã‚‹ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã«ãªã‚‹

ï¼œæ–°ã—ã„ãƒ“ã‚¸ãƒ§ãƒ³ï¼
ç´°èŒå¢ã‹ã‚‰ã®æ–°ãŸãªæ°—ä»˜ãã‚’é€šã˜ã¦
ãƒ’ãƒˆã€ç¤¾ä¼šã€åœ°çƒç’°å¢ƒã‚’å¥åº·ã«ã™ã‚‹ã‚¨ã‚³ã‚·ã‚¹ãƒ†ãƒ ã‚’å®Ÿç¾ã™ã‚‹
æ–°ã—ã„ãƒ“ã‚¸ãƒ§ãƒ³ã§ã¯ã€ã‚µã‚¤ã‚­ãƒ³ã‚½ãƒ¼ãŒå½±éŸ¿ã‚’ä¸ãˆã¦ã„ããŸã„ç¯„å›²ã‚‚ã“ã‚Œã¾ã§ã‚ˆã‚Šã•ã‚‰ã«å¤§ãããªã£ãŸã“ã¨ãŒåˆ†ã‹ã‚Šã¾ã™ã€‚

ä»Šå›ã®ãƒ“ã‚¸ãƒ§ãƒ³å¤‰æ›´ã‚’é€šã—ã¦ã€ã‚µã‚¤ã‚­ãƒ³ã‚½ãƒ¼ãŒã©ã‚“ãªä¾¡å€¤ç™ºæ®ã‚’ç›®æŒ‡ã—ã¦ã„ãã®ã‹ã€ãã‚Œã«ä¼´ã„äº‹æ¥­é¢ã§ã¯ã©ã‚“ãªæŒ‘æˆ¦ã‚’ã—ã¦ã„ãã®ã‹ã‚’ã€ä»£è¡¨å–ç· å½¹CEOã®æ²¢äº•ã•ã‚“ã«èã„ã¦ãã¾ã—ãŸï¼

...(ä»¥ä¸‹ç•¥)


 ã‚³ãƒ¼ãƒ‰
ç¶šã‘ã¦ã‚³ãƒ¼ãƒ‰ã‚’å®Ÿè£…ã—ã¾ã™ã€‚
ä»Šå›ã¯ RAG ã¨ã—ã¦å¤–éƒ¨ã®æƒ…å ±ã‚’å‚ç…§ã—ã¤ã¤å›ç­”ã™ã‚‹ ChatBot ã‚’å®Ÿè£…ã—ã¦ã¿ã¾ã™ã€‚
ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã¨ã—ã¦ streamlit ã‚’ç”¨ã„ã¾ã™ã€‚
å…ˆã«ã‚³ãƒ¼ãƒ‰å…¨ä½“ã‚’ç¤ºã™ã¨ä»¥ä¸‹ã®ã‚ˆã†ã«ãªã‚Šã¾ã™ã€‚
(streamlit ã®ã‚³ãƒ¼ãƒ‰ã®ãƒ™ãƒ¼ã‚¹ã¨ã—ã¦ä»¥ä¸‹ã®è¨˜äº‹ã‚’å‚è€ƒã«ã•ã›ã¦ã„ãŸã ãã¾ã—ãŸã€‚ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™)
https://tech-lab.sios.jp/archives/41574

chatbot.py
from pathlib import Path

import streamlit as st
from dotenv import load_dotenv
from langchain import hub
from langchain.schema import AIMessage, HumanMessage
from langchain_chroma import Chroma
from langchain_community.document_loaders import TextLoader
from langchain_core.runnables import RunnablePassthrough, RunnableSequence
from langchain_core.vectorstores import VectorStoreRetriever
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_text_splitters import RecursiveCharacterTextSplitter

load_dotenv()


def initialize_vector_store() -> Chroma:
    """VectorStoreã®åˆæœŸåŒ–."""
    embeddings = OpenAIEmbeddings()

    vector_store_path = "./resources/note.db"
    if Path(vector_store_path).exists():
        vector_store = Chroma(embedding_function=embeddings, persist_directory=vector_store_path)
    else:
        loader = TextLoader("resources/note.txt")
        docs = loader.load()

        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
        splits = text_splitter.split_documents(docs)

        vector_store = Chroma.from_documents(
            documents=splits, embedding=embeddings, persist_directory=vector_store_path
        )

    return vector_store


def initialize_retriever() -> VectorStoreRetriever:
    """Retrieverã®åˆæœŸåŒ–."""
    vector_store = initialize_vector_store()
    return vector_store.as_retriever()


def initialize_chain() -> RunnableSequence:
    """Langchainã®åˆæœŸåŒ–."""
    prompt = hub.pull("rlm/rag-prompt")
    llm = ChatOpenAI()
    retriever = initialize_retriever()
    chain = (
        {"context": retriever, "question": RunnablePassthrough()} | prompt | llm
    )
    return chain


def main() -> None:
    """ChatGPTã‚’ä½¿ã£ãŸãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã®ãƒ¡ã‚¤ãƒ³é–¢æ•°."""
    chain = initialize_chain()

    # ãƒšãƒ¼ã‚¸ã®è¨­å®š
    st.set_page_config(page_title="RAG ChatGPT")
    st.header("RAG ChatGPT")

    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®åˆæœŸåŒ–
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ã‚’ç›£è¦–
    if user_input := st.chat_input("èããŸã„ã“ã¨ã‚’å…¥åŠ›ã—ã¦ã­ï¼"):
        st.session_state.messages.append(HumanMessage(content=user_input))
        with st.spinner("GPT is typing ..."):
            response = chain.invoke(user_input)
        st.session_state.messages.append(AIMessage(content=response.content))

    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®è¡¨ç¤º
    messages = st.session_state.get("messages", [])
    for message in messages:
        if isinstance(message, AIMessage):
            with st.chat_message("assistant"):
                st.markdown(message.content)
        elif isinstance(message, HumanMessage):
            with st.chat_message("user"):
                st.markdown(message.content)
        else:
            st.write(f"System message: {message.content}")


if __name__ == "__main__":
    main()

ã‚³ãƒ¼ãƒ‰ã®å„éƒ¨åˆ†ã‚’èª¬æ˜ã—ã¦ã„ãã¾ã™ã€‚

 initialize_vector_store
def initialize_vector_store() -> Chroma:
    """VectorStoreã®åˆæœŸåŒ–."""
    embeddings = OpenAIEmbeddings()

    vector_store_path = "./resources/note.db"
    if Path(vector_store_path).exists():
        vector_store = Chroma(embedding_function=embeddings, persist_directory=vector_store_path)
    else:
        loader = TextLoader("resources/note.txt")
        docs = loader.load()

        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
        splits = text_splitter.split_documents(docs)

        vector_store = Chroma.from_documents(
            documents=splits, embedding=embeddings, persist_directory=vector_store_path
        )

    return vector_store
Vector store ã¨ã¯æƒ…å ±ã¨ã—ã¦èª­ã¿è¾¼ã¾ã›ã¦ã„ã‚‹ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’é©åˆ‡ãªé•·ã•ã«åˆ†å‰²ã—(ãƒãƒ£ãƒ³ã‚¯ã¨å‘¼ã°ã‚Œã¾ã™) ã™ãã«å–ã‚Šå‡ºã›ã‚‹ã‚ˆã†ã«ä¿å­˜ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ã‚ˆã†ãªã‚‚ã®ã§ã™ã€‚
Embeddings ã¨å‘¼ã°ã‚Œã‚‹ãƒ¢ãƒ‡ãƒ«ã§ãƒ†ã‚­ã‚¹ãƒˆã¯æ•°å€¤æƒ…å ±ã®ãƒ™ã‚¯ãƒˆãƒ«ã«ä¿å­˜ã•ã‚Œã¾ã™ã€‚ãã®ä½œæ¥­ã‚’è¡Œã†ãŸã‚ã« OpenAI API ãŒå¿…è¦ã«ãªã£ã¦ã„ã‚‹ãŸã‚é–¢æ•°ã®æœ€åˆã§ OpenAIEmbeddings ã‚’å‘¼ã³å‡ºã—ã¦ã„ã¾ã™ã€‚
ç¶šã‘ã¦ Vector store ã¨ã—ã¦ä¿å­˜ã•ã‚Œã¦ã„ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã™ã§ã«å­˜åœ¨ã—ã¦ã„ãªã„ã‹ã‚’èª¿ã¹ã¦ã„ã¾ã™ã€‚åŸºæœ¬çš„ã«ãƒ‡ãƒ¼ã‚¿ã‚„ãƒ¢ãƒ‡ãƒ«ãŒã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆã•ã‚Œãªã„é™ã‚Š Vector store ã®ãƒ‡ãƒ¼ã‚¿ã¯ã¾ã£ãŸãåŒã˜ã«ãªã‚‹ãŸã‚ã€æ¯å›å®Ÿè¡Œã—ã¦ã—ã¾ã†ã¨æ™‚é–“ã‚‚ API ã®åˆ©ç”¨æ–™é‡‘ã‚‚ç„¡é§„ã«ãªã£ã¦ã—ã¾ã„ã¾ã™ã€‚
ãã“ã§

ã¾ã å­˜åœ¨ã—ã¦ã„ãªã„å ´åˆï¼š æ–°è¦ä½œæˆ
ã™ã§ã«å­˜åœ¨ã—ã¦ã„ã‚‹å ´åˆï¼š ä¿å­˜ã—ã¦ã„ã‚‹ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’èª­ã¿è¾¼ã‚€

ã¨ã—ã¦ã„ã¾ã™ã€‚
ãªãŠå­˜åœ¨ã—ã¦ã„ã‚‹å ´åˆ Chroma ã‚¯ãƒ©ã‚¹ã®å¼•æ•° embedding_function ã« embeddings ã‚’æŒ‡å®šã—ã¦ã„ã¾ã™ãŒã€ã“ã‚Œã¯ã‚¯ã‚¨ãƒªã¨ã—ã¦ã‚ãŸãˆã‚‰ã‚Œã‚‹ãƒ¦ãƒ¼ã‚¶ã®è³ªå•ã¨ Vector store ã«ä¿å­˜ã•ã‚Œã¦ã„ã‚‹ãƒ‡ãƒ¼ã‚¿ã¨ã®é–“ã®é–¢é€£æ€§ã‚’èª¿ã¹ã‚‹ãŸã‚ã«ã€ã‚¯ã‚¨ãƒªã‚‚ Embeddings ã§ãƒ™ã‚¯ãƒˆãƒ«ã«å¤‰æ›ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã‹ã‚‰ã§ã™ã€‚

 initialize_retriver
def initialize_retriever() -> VectorStoreRetriever:
    """Retrieverã®åˆæœŸåŒ–."""
    vector_store = initialize_vector_store()
    return vector_store.as_retriever()
ã“ã¡ã‚‰ã§ã¯ã€å…ˆã»ã©ä½œæˆã—ãŸ(ã‚ã‚‹ã„ã¯ã™ã§ã«ã‚ã‚‹ã‚‚ã®ã‚’èª­ã¿è¾¼ã‚“ã ) vector_store ã‚’ retriever ã«å¤‰æ›ã—ã¦ã„ã¾ã™ã€‚ã“ã¡ã‚‰ã® retriever ã“ã®å¾Œã€ Vectore store ã‹ã‚‰æƒ…å ±ã‚’å–ã‚Šå‡ºã™ã®ã«åˆ©ç”¨ã•ã‚Œã¾ã™ã€‚

 initialize_chain
def initialize_chain() -> RunnableSequence:
    """Langchainã®åˆæœŸåŒ–."""
    prompt = hub.pull("rlm/rag-prompt")
    llm = ChatOpenAI()
    retriever = initialize_retriever()
    chain = (
        {"context": retriever, "question": RunnablePassthrough()} | prompt | llm
    )
    return chain
ã“ã¡ã‚‰ã§ã¯ retriever ã®æƒ…å ±ã‚’ LLM ã§åˆ©ç”¨ã§ãã‚‹ã‚ˆã†ã« chain ã¨å‘¼ã°ã‚Œã‚‹æ¦‚å¿µã‚’åˆ©ç”¨ã—ã¦ãŠã‚Šã¾ã™ã€‚
ã‚ˆããƒ¡ã‚½ãƒƒãƒ‰ãƒã‚§ãƒ¼ãƒ³ã¨ã„ã†è¨€è‘‰ãŒãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°è¨€èªã§ã¯ä½¿ã‚ã‚Œã¦ã„ã¾ã™ã€‚
ä¾‹ãˆã° Python ã® Pandas ã§ã¯
import pandas as pd

# ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
data = {
    'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Edward', 'Frank'],
    'Age': [24, 27, 22, 32, 29, 24],
    'City': ['New York', 'Los Angeles', 'New York', 'Chicago', 'Los Angeles', 'New York'],
    'Score': [85, 90, 88, 92, 95, 70]
}

df = pd.DataFrame(data)

# ãƒ¡ã‚½ãƒƒãƒ‰ãƒã‚§ãƒ¼ãƒ³ã‚’ä½¿ã£ãŸãƒ‡ãƒ¼ã‚¿å¤‰æ›
result = (df
          .query('Age > 25')                     # å¹´é½¢ãŒ25ä»¥ä¸Šã®è¡Œã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
          .groupby('City')                       # éƒ½å¸‚ã”ã¨ã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
          .agg({'Score': 'mean'})                # ã‚¹ã‚³ã‚¢ã®å¹³å‡ã‚’è¨ˆç®—
          .rename(columns={'Score': 'Average Score'})  # åˆ—åã‚’å¤‰æ›´
          .sort_values(by='Average Score', ascending=False)  # å¹³å‡ã‚¹ã‚³ã‚¢ã§ä¸¦ã¹æ›¿ãˆ
          .reset_index()                         # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ãƒªã‚»ãƒƒãƒˆ
         )

print(result)
ã¨ã„ã†ã‚ˆã†ã«ãƒ¡ã‚½ãƒƒãƒ‰ã®è¿”ã‚Šå€¤ã‚’æ¬¡ã®ãƒ¡ã‚½ãƒƒãƒ‰ã¸ã¨ãƒã‚±ãƒ„ãƒªãƒ¬ãƒ¼ã®ã‚ˆã†ã«ã¤ãªã„ã§è¡Œãå‡¦ç†ã•ã›ã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚ã“ã‚Œã‚’ãƒ¡ã‚½ãƒƒãƒ‰ãƒã‚§ãƒ¼ãƒ³ã¨ã„ã„ã¾ã™ã€‚
LangChain ã§ã‚‚ã“ã®ãƒã‚±ãƒ„ãƒªãƒ¬ãƒ¼ã‚’è¡Œã„ã€ã©ã®ã‚ˆã†ã«ãƒ¦ãƒ¼ã‚¶ã®è³ªå•ã«ç­”ãˆã‚‹ã‹ã®ãƒ«ãƒ¼ãƒ«ã‚’æ±ºã‚ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚
LangChain ã®å ´åˆã¯æ˜”ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã§ã¯é–¢æ•°ã®è¿”ã‚Šå€¤ã‚’ã•ã‚‰ã«é–¢æ•°ã®å¼•æ•°ã«ã™ã‚‹ã¨è¨€ã†ã“ã¨ã‚’ç¹°ã‚Šè¿”ã—ã¦ãƒã‚±ãƒ„ãƒªãƒ¬ãƒ¼ã‚’è¡Œã£ã¦ã„ã¾ã—ãŸãŒã€ä»Šã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ 0.2.5 ã§ã¯ä»¥ä¸‹ã®ã‚ˆã†ã« | ã‚’åˆ©ç”¨ã—ãƒã‚§ãƒ¼ãƒ³ã‚’ç¤ºã™ã“ã¨ãŒæ¨å¥¨ã•ã‚Œã¦ã„ã¾ã™ã€‚
    chain = (
        {"context": retriever, "question": RunnablePassthrough()} | prompt | llm
    )
ä»Šå›ã®å ´åˆ

{"context": retriever, "question": RunnablePassthrough()}
prompt
llm

ã¨ã„ã†é †ç•ªã§ãƒã‚§ãƒ¼ãƒ³ãŒã¤ãªãŒã£ã¦ã„ã¾ã™ã€‚
ãƒã‚§ãƒ¼ãƒ³ã®å…ˆé ­ãŒãªãœè¾æ›¸ã§ã‚ã‚‹ã‹ã¯ã€2ç•ªç›®ã® prompt ã®èª¬æ˜ã‚’èã„ã¦ã‚‚ã‚‰ãˆã‚Œã°ã‚ã‹ã‚‹ã¨æ€ã„ã¾ã™ã€‚
    prompt = hub.pull("rlm/rag-prompt")
prompt ã¯ LLM ã«ã©ã®ã‚ˆã†ãªè³ªå•ã‚„ä¾é ¼ã‚’ã™ã‚‹ã®ã‹ã‚’æ±ºã‚ã‚‹éƒ¨åˆ†ã§ã™ã€‚ä»Šå›ã¯ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ(å¤‰æ•°åã‚’æŒ‡ã—ã¦ã„ãªã„å ´åˆã‚«ã‚¿ã‚«ãƒŠè¡¨è¨˜ã¨ã—ã¾ã™)ã‚’æœ‰å¿—ã®æ–¹ãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ä»–ã®äººãŒåˆ©ç”¨ã§ãã‚‹ã‚ˆã†ã«ã—ã¦ãã‚Œã¦ã„ã‚‹ã‚µã‚¤ãƒˆ LangChain Hub ã‹ã‚‰ â­ ãŒå¤šã„ã‚‚ã®ã‚’ãŠå€Ÿã‚Šã—ã¦ãã¾ã—ãŸã€‚ã‚‚ã¡ã‚ã‚“è‡ªä½œã—ã¦ã‚‚ã‚‰ã£ã¦ã‚‚OKã§ã™ã€‚
https://smith.langchain.com/hub/rlm/rag-prompt
ãŠå€Ÿã‚Šã—ãŸ rag-prompt ã§ã¯ä»¥ä¸‹ã®ã‚ˆã†ã«ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒå®šç¾©ã•ã‚Œã¦ã„ã¾ã™ã€‚
You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.
Question: {question} 
Context: {context} 
Answer:
ç°¡å˜ã«æ—¥æœ¬èªã«è¨³ã™ã¨ ã€Œ context ã®æƒ…å ±ã®ã¿ã‚’ä½¿ã£ã¦ question ã«ç­”ãˆã‚‹ã‚ˆã†ã« Answer ã‚’è€ƒãˆãªã•ã„ã€‚ç­”ãˆã‚‰ã‚Œãªã„ãªã‚‰ã‚ã‹ã‚‰ãªã„ã¨ç­”ãˆãªã•ã„ã€‚ã€ ã¨ãªã‚Šã¾ã™ã€‚ context ã®æƒ…å ±ã®ã¿ã‚’ç”¨ã„ã‚‹ã‚ˆã†æŒ‡å®šã™ã‚‹ã“ã¨ã§ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³ã‚’é˜²ãåŠ¹æœãŒã‚ã‚Šã¾ã™ (ãŸã ã—ï¼‘ï¼ï¼ï¼…é˜²ãã¨ã¯æ–­è¨€ã§ããªã„ã§ã™)
ã“ã¡ã‚‰ã® question éƒ¨åˆ†ã«ãƒ¦ãƒ¼ã‚¶ã®ã‚¯ã‚¨ãƒªãŒã€ context éƒ¨åˆ†ã« retriever ã‚’æŒ‡å®šã—ã¦ prompt ã‚’å®Ÿè¡Œã›ã‚ˆã¨ã—ã¦ã„ã‚‹ã®ãŒãƒã‚§ãƒ¼ãƒ³ã® {"context": retriever, "question": RunnablePassthrough()} | prompt ã®éƒ¨åˆ†ã§ã™ã€‚
æœ€å¾Œã«å®Œæˆã—ãŸ prompt ã‚’ llm ã«æ¸¡ã—ãªã•ã„ã¨æŒ‡å®šã—ã¦ã„ã‚‹ã®ãŒ prompt | llm ã®éƒ¨åˆ†ã§ã™ã€‚
ã“ã®ãƒ¡ã‚½ãƒƒãƒ‰ãƒã‚§ãƒ¼ãƒ³ã‚’ã¾ã¨ã‚ãŸ chain ã¨ã„ã†å¤‰æ•°ã¯ invoke ãƒ¡ã‚½ãƒƒãƒ‰ã‚’æŒã£ã¦ãŠã‚Šã€ã“ã®ãƒ¡ã‚½ãƒƒãƒ‰ã«è³ªå•ã‚’æŠ•ã’ã‚‹ã¨ãã‚ŒãŒ question ã«å…¥ã‚Šãƒã‚§ãƒ¼ãƒ³ãŒå‰ã‹ã‚‰é †ç•ªã«å®Ÿè¡Œã•ã‚Œã¾ã™ã€‚
ä»¥ä¸Šã®ã‚ˆã†ã«å®šç¾©ã™ã‚‹ã“ã¨ã§ RAG ã¨ã—ã¦å¤–éƒ¨ã®æƒ…å ±ã‚’å‚ç…§ã—ã¤ã¤å›ç­”ã™ã‚‹ ChatBot ã‚’å®Ÿè£…ã§ãã¾ã—ãŸã€‚

 main
def main() -> None:
    """ChatGPTã‚’ä½¿ã£ãŸãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã®ãƒ¡ã‚¤ãƒ³é–¢æ•°."""
    chain = initialize_chain()

    # ãƒšãƒ¼ã‚¸ã®è¨­å®š
    st.set_page_config(page_title="RAG ChatGPT")
    st.image(img, use_column_width=False)
    st.header("RAG ChatGPT")

    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®åˆæœŸåŒ–
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ã‚’ç›£è¦–
    if user_input := st.chat_input("èããŸã„ã“ã¨ã‚’å…¥åŠ›ã—ã¦ã­ï¼"):
        st.session_state.messages.append(HumanMessage(content=user_input))
        with st.spinner("GPT is typing ..."):
            response = chain.invoke(user_input)
        st.session_state.messages.append(AIMessage(content=response.content))

    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®è¡¨ç¤º
    messages = st.session_state.get("messages", [])
    for message in messages:
        if isinstance(message, AIMessage):
            with st.chat_message("assistant"):
                st.markdown(message.content)
        elif isinstance(message, HumanMessage):
            with st.chat_message("user"):
                st.markdown(message.content)
        else:
            st.write(f"System message: {message.content}")
æœ€å¾Œã« main é–¢æ•°ã§ã™ã€‚ã“ã¡ã‚‰ã¯ LangChain ã®å®Ÿè£…ã¨ã„ã†ã‚ˆã‚Šã¯ Streamlit ã‚’åˆ©ç”¨ã—ãŸãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰éƒ¨åˆ†ã®å®Ÿè£…ã«ãªã‚Šã¾ã™ã€‚
ã‚­ãƒ¼ã¨ãªã‚‹ç‚¹ã ã‘è§£èª¬ã™ã‚‹ã¨

ãƒ¦ãƒ¼ã‚¶ã¨ ChatBot ã®ä¼šè©±ã¯ messages ã«ä¿å­˜ã•ã‚Œã¦ã„ã¾ã™ã€‚ä»¥ä¸‹ã®ã‚³ãƒ¼ãƒ‰ã‚’è¦‹ã‚‹ã¨ã‚ã‹ã‚‹ã‚ˆã†ã«ãƒ¦ãƒ¼ã‚¶ã‹ã‚‰ã®è³ªå•ã¨ ChatBot ã®è¿”ç­”ã¯ã©ã¡ã‚‰ã‚‚ messages ã« append ã•ã‚Œã¦ã„ã¾ã™ã€‚

    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®åˆæœŸåŒ–
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ã‚’ç›£è¦–
    if user_input := st.chat_input("èããŸã„ã“ã¨ã‚’å…¥åŠ›ã—ã¦ã­ï¼"):
        st.session_state.messages.append(HumanMessage(content=user_input))
        with st.spinner("GPT is typing ..."):
            response = chain.invoke(user_input)
        st.session_state.messages.append(AIMessage(content=response.content))

ãƒ¦ãƒ¼ã‚¶ã‹ã‚‰ã®è³ªå•ã¸ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã¯å…ˆã»ã©å®šç¾©ã—ãŸ chain ã® invoke ãƒ¡ã‚½ãƒƒãƒ‰ã‚’ç”¨ã„ã¦ä½œã‚‰ã‚Œã¦ã„ã¾ã™ã€‚

        with st.spinner("GPT is typing ..."):
            response = chain.invoke(user_input)
        st.session_state.messages.append(AIMessage(content=response.content))
ã¨ã„ã†ç‚¹ãŒã‚ã’ã‚‰ã‚Œã¾ã™ã€‚

 ãƒ†ã‚¹ãƒˆ
ãã‚Œã§ã¯å®Ÿè£…ã—ãŸã‚‚ã®ã‚’å‹•ã‹ã—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚
> streamlit run chatbot.py

Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.


  You can now view your Streamlit app in your browser.

  Local URL: http://localhost:8501
  Network URL: http://10.200.0.4:8501
  External URL: http://13.73.233.61:8501
http://localhost:8501 ã¸ãƒ–ãƒ©ã‚¦ã‚¶ã‹ã‚‰ã‚¢ã‚¯ã‚»ã‚¹ã—ã€è³ªå•ã—ã¦ã¿ã¾ã™ã€‚

ç¾æ™‚ç‚¹ã§ã® note.txt ã®å…ˆé ­ã®æ–¹ã«æ›¸ã„ã¦ã‚ã£ãŸæ–°ã—ã„ãƒ“ã‚¸ãƒ§ãƒ³ã‚’ã¡ã‚ƒã‚“ã¨ç­”ãˆã¦ã„ã¾ã™ã€‚ã“ã®æƒ…å ±ã¯ OpenAI ã«ã¯ãªã„ãŸã‚ãã¡ã‚“ã¨ RAG ãŒåƒã„ã¦ã„ã‚‹ã¨è¨€ãˆãã†ã§ã™ã€‚

ã¾ãŸã€Œ100å¹´å¾Œã«ç™ºå£²äºˆå®šã®æ–°å•†å“ã€ã¨ã„ã†æƒ…å ±ã¨ã—ã¦å«ã¾ãªã„ã‚ˆã†ãªè³ªå•ã‚’ã™ã‚‹ã¨ã¡ã‚ƒã‚“ã¨ã€Œæƒ…å ±ã‚’æŒã£ã¦ã„ãªã„ã€ã¨è¿”ç­”ã—ã¦ãã‚Œã¾ã™ã€‚ã“ã¡ã‚‰ã‚‚æœŸå¾…é€šã‚Šã§ã™ã­ã€‚

 ğŸ’¡ ã¾ã¨ã‚

LangChain v0.2.5 æ™‚ç‚¹ã§ã® RAG ã‚’ç”¨ã„ãŸ ChatBot ã®å®Ÿè£…ã‚’è¡Œã„ã¾ã—ãŸ
Streamlit ã‚’ç”¨ã„ã¦ãƒ–ãƒ©ã‚¦ã‚¶ã‹ã‚‰ãƒ¦ãƒ¼ã‚¶ãŒã‚¢ã‚¯ã‚»ã‚¹ã§ãã‚‹ã‚ˆã†ã«ã—ã¾ã—ãŸ

ãœã²å‚è€ƒã«ã—ã¦ã¿ã¦ãã ã•ã„ã€‚

a
a
div
pyproject.toml
python = ">=3.12,<3.13"
python-dotenv = "^1.0.1"
chromadb = "0.5.2"
langchain = "0.2.5"
langchain-cli = "0.0.25"
langchain-openai = "0.1.8"
langchain-community = "0.2.5"
langchain-chroma = "0.1.1"
langchainhub = "0.1.20"
streamlit = "1.35.0"


divpyproject.toml
spanpyproject.toml
prepython = ">=3.12,<3.13"
python-dotenv = "^1.0.1"
chromadb = "0.5.2"
langchain = "0.2.5"
langchain-cli = "0.0.25"
langchain-openai = "0.1.8"
langchain-community = "0.2.5"
langchain-chroma = "0.1.1"
langchainhub = "0.1.20"
streamlit = "1.35.0"

codepython = ">=3.12,<3.13"
python-dotenv = "^1.0.1"
chromadb = "0.5.2"
langchain = "0.2.5"
langchain-cli = "0.0.25"
langchain-openai = "0.1.8"
langchain-community = "0.2.5"
langchain-chroma = "0.1.1"
langchainhub = "0.1.20"
streamlit = "1.35.0"

spanpython
span=
span">=3.12,<3.13"
spanpython-dotenv
span=
span"^1.0.1"
spanchromadb
span=
span"0.5.2"
spanlangchain
span=
span"0.2.5"
spanlangchain-cli
span=
span"0.0.25"
spanlangchain-openai
span=
span"0.1.8"
spanlangchain-community
span=
span"0.2.5"
spanlangchain-chroma
span=
span"0.1.1"
spanlangchainhub
span=
span"0.1.20"
spanstreamlit
span=
span"1.35.0"
a
span
a
divOPENAI_API_KEY=sk-XXXXXXXXXXXXXXXX
OPENAI_API_VERSION=2024-02-01

a
img
img
img
a
span
div
note.txt
ç´°èŒå¢ã‹ã‚‰ã®æ–°ãŸãªæ°—ä»˜ãã‚’é€šã˜ã¦ã€æ–°ãƒ“ã‚¸ãƒ§ãƒ³ã‚’ç­–å®šã—ã¾ã—ãŸï¼
2023å¹´11æœˆã«ã‚µã‚¤ã‚­ãƒ³ã‚½ãƒ¼ã¯10æœŸç›®ã«å…¥ã‚Šã¾ã—ãŸã€‚é«˜é½¢åŒ–ç¤¾ä¼šã«ã‚ˆã‚‹ç¤¾ä¼šä¿éšœã¸ã®ä¸å®‰ãŒå‹Ÿã‚‹ç¾åœ¨ã€ç—…æ°—ã‚’æœªç„¶ã«é˜²ã0æ¬¡äºˆé˜²ã®é‡è¦æ€§ãŒé«˜ã¾ã£ã¦ã„ã¾ã™ã€‚ã€Œç´°èŒå¢ã§äººã€…ã‚’å¥åº·ã«ã€ã¨ã„ã†ãƒŸãƒƒã‚·ãƒ§ãƒ³ã«å‘ã‘ã¦ã€ã‚µã‚¤ã‚­ãƒ³ã‚½ãƒ¼ã¯æ–°ãŸãªãƒ“ã‚¸ãƒ§ãƒ³ã‚’åˆ¶å®šã—ã¾ã—ãŸã€‚
æ–°ã—ã„ãƒ“ã‚¸ãƒ§ãƒ³ã«ã¤ã„ã¦
ãƒ¼ãƒ“ã‚¸ãƒ§ãƒ³å¤‰æ›´ã§å…·ä½“çš„ã«ã©ã®å€‹æ‰€ãŒå¤‰æ›´ã—ãŸã‹ã‚’ã¾ãšã”ç´¹ä»‹ã—ã¾ã™ã€‚
ã“ã¡ã‚‰ãŒã‚µã‚¤ã‚­ãƒ³ã‚½ãƒ¼ã®ãƒŸãƒƒã‚·ãƒ§ãƒ³ï¼ˆMISSIONï¼‰ã€ãƒ“ã‚¸ãƒ§ãƒ³(VISION)ã€ãƒãƒªãƒ¥ãƒ¼(VALUE)ã«ãªã‚Šã¾ã™ã€‚
ç§ãŸã¡ãŒç›®æŒ‡ã—ç¶šã‘ã‚‹ã€Œç´°èŒå¢ã§äººã€…ã‚’å¥åº·ã«ã€ã¨ã„ã†ãƒŸãƒƒã‚·ãƒ§ãƒ³ã¯ãã®ã¾ã¾ã«ã€ãƒ“ã‚¸ãƒ§ãƒ³ã‚’æ–°ã—ãå¤‰æ›´è‡´ã—ã¾ã—ãŸã€‚

ï¼œã“ã‚Œã¾ã§ã®ãƒ“ã‚¸ãƒ§ãƒ³ï¼
èŒå¢ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã€Œæ¬¡ä¸–ä»£ã®ãƒ©ã‚¤ãƒ•ã‚¹ã‚¿ã‚¤ãƒ«ã€ã‚’æä¾›ã™ã‚‹ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã«ãªã‚‹

ï¼œæ–°ã—ã„ãƒ“ã‚¸ãƒ§ãƒ³ï¼
ç´°èŒå¢ã‹ã‚‰ã®æ–°ãŸãªæ°—ä»˜ãã‚’é€šã˜ã¦
ãƒ’ãƒˆã€ç¤¾ä¼šã€åœ°çƒç’°å¢ƒã‚’å¥åº·ã«ã™ã‚‹ã‚¨ã‚³ã‚·ã‚¹ãƒ†ãƒ ã‚’å®Ÿç¾ã™ã‚‹
æ–°ã—ã„ãƒ“ã‚¸ãƒ§ãƒ³ã§ã¯ã€ã‚µã‚¤ã‚­ãƒ³ã‚½ãƒ¼ãŒå½±éŸ¿ã‚’ä¸ãˆã¦ã„ããŸã„ç¯„å›²ã‚‚ã“ã‚Œã¾ã§ã‚ˆã‚Šã•ã‚‰ã«å¤§ãããªã£ãŸã“ã¨ãŒåˆ†ã‹ã‚Šã¾ã™ã€‚

ä»Šå›ã®ãƒ“ã‚¸ãƒ§ãƒ³å¤‰æ›´ã‚’é€šã—ã¦ã€ã‚µã‚¤ã‚­ãƒ³ã‚½ãƒ¼ãŒã©ã‚“ãªä¾¡å€¤ç™ºæ®ã‚’ç›®æŒ‡ã—ã¦ã„ãã®ã‹ã€ãã‚Œã«ä¼´ã„äº‹æ¥­é¢ã§ã¯ã©ã‚“ãªæŒ‘æˆ¦ã‚’ã—ã¦ã„ãã®ã‹ã‚’ã€ä»£è¡¨å–ç· å½¹CEOã®æ²¢äº•ã•ã‚“ã«èã„ã¦ãã¾ã—ãŸï¼

...(ä»¥ä¸‹ç•¥)


divnote.txt
spannote.txt
preç´°èŒå¢ã‹ã‚‰ã®æ–°ãŸãªæ°—ä»˜ãã‚’é€šã˜ã¦ã€æ–°ãƒ“ã‚¸ãƒ§ãƒ³ã‚’ç­–å®šã—ã¾ã—ãŸï¼
2023å¹´11æœˆã«ã‚µã‚¤ã‚­ãƒ³ã‚½ãƒ¼ã¯10æœŸç›®ã«å…¥ã‚Šã¾ã—ãŸã€‚é«˜é½¢åŒ–ç¤¾ä¼šã«ã‚ˆã‚‹ç¤¾ä¼šä¿éšœã¸ã®ä¸å®‰ãŒå‹Ÿã‚‹ç¾åœ¨ã€ç—…æ°—ã‚’æœªç„¶ã«é˜²ã0æ¬¡äºˆé˜²ã®é‡è¦æ€§ãŒé«˜ã¾ã£ã¦ã„ã¾ã™ã€‚ã€Œç´°èŒå¢ã§äººã€…ã‚’å¥åº·ã«ã€ã¨ã„ã†ãƒŸãƒƒã‚·ãƒ§ãƒ³ã«å‘ã‘ã¦ã€ã‚µã‚¤ã‚­ãƒ³ã‚½ãƒ¼ã¯æ–°ãŸãªãƒ“ã‚¸ãƒ§ãƒ³ã‚’åˆ¶å®šã—ã¾ã—ãŸã€‚
æ–°ã—ã„ãƒ“ã‚¸ãƒ§ãƒ³ã«ã¤ã„ã¦
ãƒ¼ãƒ“ã‚¸ãƒ§ãƒ³å¤‰æ›´ã§å…·ä½“çš„ã«ã©ã®å€‹æ‰€ãŒå¤‰æ›´ã—ãŸã‹ã‚’ã¾ãšã”ç´¹ä»‹ã—ã¾ã™ã€‚
ã“ã¡ã‚‰ãŒã‚µã‚¤ã‚­ãƒ³ã‚½ãƒ¼ã®ãƒŸãƒƒã‚·ãƒ§ãƒ³ï¼ˆMISSIONï¼‰ã€ãƒ“ã‚¸ãƒ§ãƒ³(VISION)ã€ãƒãƒªãƒ¥ãƒ¼(VALUE)ã«ãªã‚Šã¾ã™ã€‚
ç§ãŸã¡ãŒç›®æŒ‡ã—ç¶šã‘ã‚‹ã€Œç´°èŒå¢ã§äººã€…ã‚’å¥åº·ã«ã€ã¨ã„ã†ãƒŸãƒƒã‚·ãƒ§ãƒ³ã¯ãã®ã¾ã¾ã«ã€ãƒ“ã‚¸ãƒ§ãƒ³ã‚’æ–°ã—ãå¤‰æ›´è‡´ã—ã¾ã—ãŸã€‚

ï¼œã“ã‚Œã¾ã§ã®ãƒ“ã‚¸ãƒ§ãƒ³ï¼
èŒå¢ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã€Œæ¬¡ä¸–ä»£ã®ãƒ©ã‚¤ãƒ•ã‚¹ã‚¿ã‚¤ãƒ«ã€ã‚’æä¾›ã™ã‚‹ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã«ãªã‚‹

ï¼œæ–°ã—ã„ãƒ“ã‚¸ãƒ§ãƒ³ï¼
ç´°èŒå¢ã‹ã‚‰ã®æ–°ãŸãªæ°—ä»˜ãã‚’é€šã˜ã¦
ãƒ’ãƒˆã€ç¤¾ä¼šã€åœ°çƒç’°å¢ƒã‚’å¥åº·ã«ã™ã‚‹ã‚¨ã‚³ã‚·ã‚¹ãƒ†ãƒ ã‚’å®Ÿç¾ã™ã‚‹
æ–°ã—ã„ãƒ“ã‚¸ãƒ§ãƒ³ã§ã¯ã€ã‚µã‚¤ã‚­ãƒ³ã‚½ãƒ¼ãŒå½±éŸ¿ã‚’ä¸ãˆã¦ã„ããŸã„ç¯„å›²ã‚‚ã“ã‚Œã¾ã§ã‚ˆã‚Šã•ã‚‰ã«å¤§ãããªã£ãŸã“ã¨ãŒåˆ†ã‹ã‚Šã¾ã™ã€‚

ä»Šå›ã®ãƒ“ã‚¸ãƒ§ãƒ³å¤‰æ›´ã‚’é€šã—ã¦ã€ã‚µã‚¤ã‚­ãƒ³ã‚½ãƒ¼ãŒã©ã‚“ãªä¾¡å€¤ç™ºæ®ã‚’ç›®æŒ‡ã—ã¦ã„ãã®ã‹ã€ãã‚Œã«ä¼´ã„äº‹æ¥­é¢ã§ã¯ã©ã‚“ãªæŒ‘æˆ¦ã‚’ã—ã¦ã„ãã®ã‹ã‚’ã€ä»£è¡¨å–ç· å½¹CEOã®æ²¢äº•ã•ã‚“ã«èã„ã¦ãã¾ã—ãŸï¼

...(ä»¥ä¸‹ç•¥)

codeç´°èŒå¢ã‹ã‚‰ã®æ–°ãŸãªæ°—ä»˜ãã‚’é€šã˜ã¦ã€æ–°ãƒ“ã‚¸ãƒ§ãƒ³ã‚’ç­–å®šã—ã¾ã—ãŸï¼
2023å¹´11æœˆã«ã‚µã‚¤ã‚­ãƒ³ã‚½ãƒ¼ã¯10æœŸç›®ã«å…¥ã‚Šã¾ã—ãŸã€‚é«˜é½¢åŒ–ç¤¾ä¼šã«ã‚ˆã‚‹ç¤¾ä¼šä¿éšœã¸ã®ä¸å®‰ãŒå‹Ÿã‚‹ç¾åœ¨ã€ç—…æ°—ã‚’æœªç„¶ã«é˜²ã0æ¬¡äºˆé˜²ã®é‡è¦æ€§ãŒé«˜ã¾ã£ã¦ã„ã¾ã™ã€‚ã€Œç´°èŒå¢ã§äººã€…ã‚’å¥åº·ã«ã€ã¨ã„ã†ãƒŸãƒƒã‚·ãƒ§ãƒ³ã«å‘ã‘ã¦ã€ã‚µã‚¤ã‚­ãƒ³ã‚½ãƒ¼ã¯æ–°ãŸãªãƒ“ã‚¸ãƒ§ãƒ³ã‚’åˆ¶å®šã—ã¾ã—ãŸã€‚
æ–°ã—ã„ãƒ“ã‚¸ãƒ§ãƒ³ã«ã¤ã„ã¦
ãƒ¼ãƒ“ã‚¸ãƒ§ãƒ³å¤‰æ›´ã§å…·ä½“çš„ã«ã©ã®å€‹æ‰€ãŒå¤‰æ›´ã—ãŸã‹ã‚’ã¾ãšã”ç´¹ä»‹ã—ã¾ã™ã€‚
ã“ã¡ã‚‰ãŒã‚µã‚¤ã‚­ãƒ³ã‚½ãƒ¼ã®ãƒŸãƒƒã‚·ãƒ§ãƒ³ï¼ˆMISSIONï¼‰ã€ãƒ“ã‚¸ãƒ§ãƒ³(VISION)ã€ãƒãƒªãƒ¥ãƒ¼(VALUE)ã«ãªã‚Šã¾ã™ã€‚
ç§ãŸã¡ãŒç›®æŒ‡ã—ç¶šã‘ã‚‹ã€Œç´°èŒå¢ã§äººã€…ã‚’å¥åº·ã«ã€ã¨ã„ã†ãƒŸãƒƒã‚·ãƒ§ãƒ³ã¯ãã®ã¾ã¾ã«ã€ãƒ“ã‚¸ãƒ§ãƒ³ã‚’æ–°ã—ãå¤‰æ›´è‡´ã—ã¾ã—ãŸã€‚

ï¼œã“ã‚Œã¾ã§ã®ãƒ“ã‚¸ãƒ§ãƒ³ï¼
èŒå¢ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã€Œæ¬¡ä¸–ä»£ã®ãƒ©ã‚¤ãƒ•ã‚¹ã‚¿ã‚¤ãƒ«ã€ã‚’æä¾›ã™ã‚‹ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã«ãªã‚‹

ï¼œæ–°ã—ã„ãƒ“ã‚¸ãƒ§ãƒ³ï¼
ç´°èŒå¢ã‹ã‚‰ã®æ–°ãŸãªæ°—ä»˜ãã‚’é€šã˜ã¦
ãƒ’ãƒˆã€ç¤¾ä¼šã€åœ°çƒç’°å¢ƒã‚’å¥åº·ã«ã™ã‚‹ã‚¨ã‚³ã‚·ã‚¹ãƒ†ãƒ ã‚’å®Ÿç¾ã™ã‚‹
æ–°ã—ã„ãƒ“ã‚¸ãƒ§ãƒ³ã§ã¯ã€ã‚µã‚¤ã‚­ãƒ³ã‚½ãƒ¼ãŒå½±éŸ¿ã‚’ä¸ãˆã¦ã„ããŸã„ç¯„å›²ã‚‚ã“ã‚Œã¾ã§ã‚ˆã‚Šã•ã‚‰ã«å¤§ãããªã£ãŸã“ã¨ãŒåˆ†ã‹ã‚Šã¾ã™ã€‚

ä»Šå›ã®ãƒ“ã‚¸ãƒ§ãƒ³å¤‰æ›´ã‚’é€šã—ã¦ã€ã‚µã‚¤ã‚­ãƒ³ã‚½ãƒ¼ãŒã©ã‚“ãªä¾¡å€¤ç™ºæ®ã‚’ç›®æŒ‡ã—ã¦ã„ãã®ã‹ã€ãã‚Œã«ä¼´ã„äº‹æ¥­é¢ã§ã¯ã©ã‚“ãªæŒ‘æˆ¦ã‚’ã—ã¦ã„ãã®ã‹ã‚’ã€ä»£è¡¨å–ç· å½¹CEOã®æ²¢äº•ã•ã‚“ã«èã„ã¦ãã¾ã—ãŸï¼

...(ä»¥ä¸‹ç•¥)

a
span
div
chatbot.py
from pathlib import Path

import streamlit as st
from dotenv import load_dotenv
from langchain import hub
from langchain.schema import AIMessage, HumanMessage
from langchain_chroma import Chroma
from langchain_community.document_loaders import TextLoader
from langchain_core.runnables import RunnablePassthrough, RunnableSequence
from langchain_core.vectorstores import VectorStoreRetriever
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_text_splitters import RecursiveCharacterTextSplitter

load_dotenv()


def initialize_vector_store() -> Chroma:
    """VectorStoreã®åˆæœŸåŒ–."""
    embeddings = OpenAIEmbeddings()

    vector_store_path = "./resources/note.db"
    if Path(vector_store_path).exists():
        vector_store = Chroma(embedding_function=embeddings, persist_directory=vector_store_path)
    else:
        loader = TextLoader("resources/note.txt")
        docs = loader.load()

        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
        splits = text_splitter.split_documents(docs)

        vector_store = Chroma.from_documents(
            documents=splits, embedding=embeddings, persist_directory=vector_store_path
        )

    return vector_store


def initialize_retriever() -> VectorStoreRetriever:
    """Retrieverã®åˆæœŸåŒ–."""
    vector_store = initialize_vector_store()
    return vector_store.as_retriever()


def initialize_chain() -> RunnableSequence:
    """Langchainã®åˆæœŸåŒ–."""
    prompt = hub.pull("rlm/rag-prompt")
    llm = ChatOpenAI()
    retriever = initialize_retriever()
    chain = (
        {"context": retriever, "question": RunnablePassthrough()} | prompt | llm
    )
    return chain


def main() -> None:
    """ChatGPTã‚’ä½¿ã£ãŸãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã®ãƒ¡ã‚¤ãƒ³é–¢æ•°."""
    chain = initialize_chain()

    # ãƒšãƒ¼ã‚¸ã®è¨­å®š
    st.set_page_config(page_title="RAG ChatGPT")
    st.header("RAG ChatGPT")

    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®åˆæœŸåŒ–
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ã‚’ç›£è¦–
    if user_input := st.chat_input("èããŸã„ã“ã¨ã‚’å…¥åŠ›ã—ã¦ã­ï¼"):
        st.session_state.messages.append(HumanMessage(content=user_input))
        with st.spinner("GPT is typing ..."):
            response = chain.invoke(user_input)
        st.session_state.messages.append(AIMessage(content=response.content))

    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®è¡¨ç¤º
    messages = st.session_state.get("messages", [])
    for message in messages:
        if isinstance(message, AIMessage):
            with st.chat_message("assistant"):
                st.markdown(message.content)
        elif isinstance(message, HumanMessage):
            with st.chat_message("user"):
                st.markdown(message.content)
        else:
            st.write(f"System message: {message.content}")


if __name__ == "__main__":
    main()


divchatbot.py
spanchatbot.py
prefrom pathlib import Path

import streamlit as st
from dotenv import load_dotenv
from langchain import hub
from langchain.schema import AIMessage, HumanMessage
from langchain_chroma import Chroma
from langchain_community.document_loaders import TextLoader
from langchain_core.runnables import RunnablePassthrough, RunnableSequence
from langchain_core.vectorstores import VectorStoreRetriever
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_text_splitters import RecursiveCharacterTextSplitter

load_dotenv()


def initialize_vector_store() -> Chroma:
    """VectorStoreã®åˆæœŸåŒ–."""
    embeddings = OpenAIEmbeddings()

    vector_store_path = "./resources/note.db"
    if Path(vector_store_path).exists():
        vector_store = Chroma(embedding_function=embeddings, persist_directory=vector_store_path)
    else:
        loader = TextLoader("resources/note.txt")
        docs = loader.load()

        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
        splits = text_splitter.split_documents(docs)

        vector_store = Chroma.from_documents(
            documents=splits, embedding=embeddings, persist_directory=vector_store_path
        )

    return vector_store


def initialize_retriever() -> VectorStoreRetriever:
    """Retrieverã®åˆæœŸåŒ–."""
    vector_store = initialize_vector_store()
    return vector_store.as_retriever()


def initialize_chain() -> RunnableSequence:
    """Langchainã®åˆæœŸåŒ–."""
    prompt = hub.pull("rlm/rag-prompt")
    llm = ChatOpenAI()
    retriever = initialize_retriever()
    chain = (
        {"context": retriever, "question": RunnablePassthrough()} | prompt | llm
    )
    return chain


def main() -> None:
    """ChatGPTã‚’ä½¿ã£ãŸãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã®ãƒ¡ã‚¤ãƒ³é–¢æ•°."""
    chain = initialize_chain()

    # ãƒšãƒ¼ã‚¸ã®è¨­å®š
    st.set_page_config(page_title="RAG ChatGPT")
    st.header("RAG ChatGPT")

    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®åˆæœŸåŒ–
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ã‚’ç›£è¦–
    if user_input := st.chat_input("èããŸã„ã“ã¨ã‚’å…¥åŠ›ã—ã¦ã­ï¼"):
        st.session_state.messages.append(HumanMessage(content=user_input))
        with st.spinner("GPT is typing ..."):
            response = chain.invoke(user_input)
        st.session_state.messages.append(AIMessage(content=response.content))

    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®è¡¨ç¤º
    messages = st.session_state.get("messages", [])
    for message in messages:
        if isinstance(message, AIMessage):
            with st.chat_message("assistant"):
                st.markdown(message.content)
        elif isinstance(message, HumanMessage):
            with st.chat_message("user"):
                st.markdown(message.content)
        else:
            st.write(f"System message: {message.content}")


if __name__ == "__main__":
    main()

codefrom pathlib import Path

import streamlit as st
from dotenv import load_dotenv
from langchain import hub
from langchain.schema import AIMessage, HumanMessage
from langchain_chroma import Chroma
from langchain_community.document_loaders import TextLoader
from langchain_core.runnables import RunnablePassthrough, RunnableSequence
from langchain_core.vectorstores import VectorStoreRetriever
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_text_splitters import RecursiveCharacterTextSplitter

load_dotenv()


def initialize_vector_store() -> Chroma:
    """VectorStoreã®åˆæœŸåŒ–."""
    embeddings = OpenAIEmbeddings()

    vector_store_path = "./resources/note.db"
    if Path(vector_store_path).exists():
        vector_store = Chroma(embedding_function=embeddings, persist_directory=vector_store_path)
    else:
        loader = TextLoader("resources/note.txt")
        docs = loader.load()

        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
        splits = text_splitter.split_documents(docs)

        vector_store = Chroma.from_documents(
            documents=splits, embedding=embeddings, persist_directory=vector_store_path
        )

    return vector_store


def initialize_retriever() -> VectorStoreRetriever:
    """Retrieverã®åˆæœŸåŒ–."""
    vector_store = initialize_vector_store()
    return vector_store.as_retriever()


def initialize_chain() -> RunnableSequence:
    """Langchainã®åˆæœŸåŒ–."""
    prompt = hub.pull("rlm/rag-prompt")
    llm = ChatOpenAI()
    retriever = initialize_retriever()
    chain = (
        {"context": retriever, "question": RunnablePassthrough()} | prompt | llm
    )
    return chain


def main() -> None:
    """ChatGPTã‚’ä½¿ã£ãŸãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã®ãƒ¡ã‚¤ãƒ³é–¢æ•°."""
    chain = initialize_chain()

    # ãƒšãƒ¼ã‚¸ã®è¨­å®š
    st.set_page_config(page_title="RAG ChatGPT")
    st.header("RAG ChatGPT")

    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®åˆæœŸåŒ–
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ã‚’ç›£è¦–
    if user_input := st.chat_input("èããŸã„ã“ã¨ã‚’å…¥åŠ›ã—ã¦ã­ï¼"):
        st.session_state.messages.append(HumanMessage(content=user_input))
        with st.spinner("GPT is typing ..."):
            response = chain.invoke(user_input)
        st.session_state.messages.append(AIMessage(content=response.content))

    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®è¡¨ç¤º
    messages = st.session_state.get("messages", [])
    for message in messages:
        if isinstance(message, AIMessage):
            with st.chat_message("assistant"):
                st.markdown(message.content)
        elif isinstance(message, HumanMessage):
            with st.chat_message("user"):
                st.markdown(message.content)
        else:
            st.write(f"System message: {message.content}")


if __name__ == "__main__":
    main()

spanfrom
spanimport
spanimport
spanas
spanfrom
spanimport
spanfrom
spanimport
spanfrom
span.
spanimport
span,
spanfrom
spanimport
spanfrom
span.
spanimport
spanfrom
span.
spanimport
span,
spanfrom
span.
spanimport
spanfrom
spanimport
span,
spanfrom
spanimport
span(
span)
spandef
spaninitialize_vector_store
span(
span)
span-
span>
span:
span"""VectorStoreã®åˆæœŸåŒ–."""
span=
span(
span)
span=
span"./resources/note.db"
spanif
span(
span)
span.
span(
span)
span:
span=
span(
span=
span,
span=
span)
spanelse
span:
span=
span(
span"resources/note.txt"
span)
span=
span.
span(
span)
span=
span(
span=
span1000
span,
span=
span200
span)
span=
span.
span(
span)
span=
span.
span(
span=
span,
span=
span,
span=
span)
spanreturn
spandef
spaninitialize_retriever
span(
span)
span-
span>
span:
span"""Retrieverã®åˆæœŸåŒ–."""
span=
span(
span)
spanreturn
span.
span(
span)
spandef
spaninitialize_chain
span(
span)
span-
span>
span:
span"""Langchainã®åˆæœŸåŒ–."""
span=
span.
span(
span"rlm/rag-prompt"
span)
span=
span(
span)
span=
span(
span)
span=
span(
span{
span"context"
span:
span,
span"question"
span:
span(
span)
span}
span|
span|
span)
spanreturn
spandef
spanmain
span(
span)
span-
span>
spanNone
span:
span"""ChatGPTã‚’ä½¿ã£ãŸãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã®ãƒ¡ã‚¤ãƒ³é–¢æ•°."""
span=
span(
span)
span# ãƒšãƒ¼ã‚¸ã®è¨­å®š
span.
span(
span=
span"RAG ChatGPT"
span)
span.
span(
span"RAG ChatGPT"
span)
span# ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®åˆæœŸåŒ–
spanif
span"messages"
spannot
spanin
span.
span:
span.
span.
span=
span[
span]
span# ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ã‚’ç›£è¦–
spanif
span:=
span.
span(
span"èããŸã„ã“ã¨ã‚’å…¥åŠ›ã—ã¦ã­ï¼"
span)
span:
span.
span.
span.
span(
span(
span=
span)
span)
spanwith
span.
span(
span"GPT is typing ..."
span)
span:
span=
span.
span(
span)
span.
span.
span.
span(
span(
span=
span.
span)
span)
span# ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®è¡¨ç¤º
span=
span.
span.
span(
span"messages"
span,
span[
span]
span)
spanfor
spanin
span:
spanif
spanisinstance
span(
span,
span)
span:
spanwith
span.
span(
span"assistant"
span)
span:
span.
span(
span.
span)
spanelif
spanisinstance
span(
span,
span)
span:
spanwith
span.
span(
span"user"
span)
span:
span.
span(
span.
span)
spanelse
span:
span.
span(
spanf"System message: {message.content}"
spanf"System message: 
span{message.content}
span{
span.
span}
span"
span)
spanif
span==
span"__main__"
span:
span(
span)
a
divdef initialize_vector_store() -> Chroma:
    """VectorStoreã®åˆæœŸåŒ–."""
    embeddings = OpenAIEmbeddings()

    vector_store_path = "./resources/note.db"
    if Path(vector_store_path).exists():
        vector_store = Chroma(embedding_function=embeddings, persist_directory=vector_store_path)
    else:
        loader = TextLoader("resources/note.txt")
        docs = loader.load()

        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
        splits = text_splitter.split_documents(docs)

        vector_store = Chroma.from_documents(
            documents=splits, embedding=embeddings, persist_directory=vector_store_path
        )

    return vector_store

predef initialize_vector_store() -> Chroma:
    """VectorStoreã®åˆæœŸåŒ–."""
    embeddings = OpenAIEmbeddings()

    vector_store_path = "./resources/note.db"
    if Path(vector_store_path).exists():
        vector_store = Chroma(embedding_function=embeddings, persist_directory=vector_store_path)
    else:
        loader = TextLoader("resources/note.txt")
        docs = loader.load()

        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
        splits = text_splitter.split_documents(docs)

        vector_store = Chroma.from_documents(
            documents=splits, embedding=embeddings, persist_directory=vector_store_path
        )

    return vector_store

codedef initialize_vector_store() -> Chroma:
    """VectorStoreã®åˆæœŸåŒ–."""
    embeddings = OpenAIEmbeddings()

    vector_store_path = "./resources/note.db"
    if Path(vector_store_path).exists():
        vector_store = Chroma(embedding_function=embeddings, persist_directory=vector_store_path)
    else:
        loader = TextLoader("resources/note.txt")
        docs = loader.load()

        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
        splits = text_splitter.split_documents(docs)

        vector_store = Chroma.from_documents(
            documents=splits, embedding=embeddings, persist_directory=vector_store_path
        )

    return vector_store

spandef
spaninitialize_vector_store
span(
span)
span-
span>
span:
span"""VectorStoreã®åˆæœŸåŒ–."""
span=
span(
span)
span=
span"./resources/note.db"
spanif
span(
span)
span.
span(
span)
span:
span=
span(
span=
span,
span=
span)
spanelse
span:
span=
span(
span"resources/note.txt"
span)
span=
span.
span(
span)
span=
span(
span=
span1000
span,
span=
span200
span)
span=
span.
span(
span)
span=
span.
span(
span=
span,
span=
span,
span=
span)
spanreturn
a
divdef initialize_retriever() -> VectorStoreRetriever:
    """Retrieverã®åˆæœŸåŒ–."""
    vector_store = initialize_vector_store()
    return vector_store.as_retriever()

predef initialize_retriever() -> VectorStoreRetriever:
    """Retrieverã®åˆæœŸåŒ–."""
    vector_store = initialize_vector_store()
    return vector_store.as_retriever()

codedef initialize_retriever() -> VectorStoreRetriever:
    """Retrieverã®åˆæœŸåŒ–."""
    vector_store = initialize_vector_store()
    return vector_store.as_retriever()

spandef
spaninitialize_retriever
span(
span)
span-
span>
span:
span"""Retrieverã®åˆæœŸåŒ–."""
span=
span(
span)
spanreturn
span.
span(
span)
a
divdef initialize_chain() -> RunnableSequence:
    """Langchainã®åˆæœŸåŒ–."""
    prompt = hub.pull("rlm/rag-prompt")
    llm = ChatOpenAI()
    retriever = initialize_retriever()
    chain = (
        {"context": retriever, "question": RunnablePassthrough()} | prompt | llm
    )
    return chain

predef initialize_chain() -> RunnableSequence:
    """Langchainã®åˆæœŸåŒ–."""
    prompt = hub.pull("rlm/rag-prompt")
    llm = ChatOpenAI()
    retriever = initialize_retriever()
    chain = (
        {"context": retriever, "question": RunnablePassthrough()} | prompt | llm
    )
    return chain

codedef initialize_chain() -> RunnableSequence:
    """Langchainã®åˆæœŸåŒ–."""
    prompt = hub.pull("rlm/rag-prompt")
    llm = ChatOpenAI()
    retriever = initialize_retriever()
    chain = (
        {"context": retriever, "question": RunnablePassthrough()} | prompt | llm
    )
    return chain

spandef
spaninitialize_chain
span(
span)
span-
span>
span:
span"""Langchainã®åˆæœŸåŒ–."""
span=
span.
span(
span"rlm/rag-prompt"
span)
span=
span(
span)
span=
span(
span)
span=
span(
span{
span"context"
span:
span,
span"question"
span:
span(
span)
span}
span|
span|
span)
spanreturn
divimport pandas as pd

# ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
data = {
    'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Edward', 'Frank'],
    'Age': [24, 27, 22, 32, 29, 24],
    'City': ['New York', 'Los Angeles', 'New York', 'Chicago', 'Los Angeles', 'New York'],
    'Score': [85, 90, 88, 92, 95, 70]
}

df = pd.DataFrame(data)

# ãƒ¡ã‚½ãƒƒãƒ‰ãƒã‚§ãƒ¼ãƒ³ã‚’ä½¿ã£ãŸãƒ‡ãƒ¼ã‚¿å¤‰æ›
result = (df
          .query('Age > 25')                     # å¹´é½¢ãŒ25ä»¥ä¸Šã®è¡Œã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
          .groupby('City')                       # éƒ½å¸‚ã”ã¨ã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
          .agg({'Score': 'mean'})                # ã‚¹ã‚³ã‚¢ã®å¹³å‡ã‚’è¨ˆç®—
          .rename(columns={'Score': 'Average Score'})  # åˆ—åã‚’å¤‰æ›´
          .sort_values(by='Average Score', ascending=False)  # å¹³å‡ã‚¹ã‚³ã‚¢ã§ä¸¦ã¹æ›¿ãˆ
          .reset_index()                         # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ãƒªã‚»ãƒƒãƒˆ
         )

print(result)

preimport pandas as pd

# ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
data = {
    'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Edward', 'Frank'],
    'Age': [24, 27, 22, 32, 29, 24],
    'City': ['New York', 'Los Angeles', 'New York', 'Chicago', 'Los Angeles', 'New York'],
    'Score': [85, 90, 88, 92, 95, 70]
}

df = pd.DataFrame(data)

# ãƒ¡ã‚½ãƒƒãƒ‰ãƒã‚§ãƒ¼ãƒ³ã‚’ä½¿ã£ãŸãƒ‡ãƒ¼ã‚¿å¤‰æ›
result = (df
          .query('Age > 25')                     # å¹´é½¢ãŒ25ä»¥ä¸Šã®è¡Œã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
          .groupby('City')                       # éƒ½å¸‚ã”ã¨ã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
          .agg({'Score': 'mean'})                # ã‚¹ã‚³ã‚¢ã®å¹³å‡ã‚’è¨ˆç®—
          .rename(columns={'Score': 'Average Score'})  # åˆ—åã‚’å¤‰æ›´
          .sort_values(by='Average Score', ascending=False)  # å¹³å‡ã‚¹ã‚³ã‚¢ã§ä¸¦ã¹æ›¿ãˆ
          .reset_index()                         # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ãƒªã‚»ãƒƒãƒˆ
         )

print(result)

codeimport pandas as pd

# ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
data = {
    'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Edward', 'Frank'],
    'Age': [24, 27, 22, 32, 29, 24],
    'City': ['New York', 'Los Angeles', 'New York', 'Chicago', 'Los Angeles', 'New York'],
    'Score': [85, 90, 88, 92, 95, 70]
}

df = pd.DataFrame(data)

# ãƒ¡ã‚½ãƒƒãƒ‰ãƒã‚§ãƒ¼ãƒ³ã‚’ä½¿ã£ãŸãƒ‡ãƒ¼ã‚¿å¤‰æ›
result = (df
          .query('Age > 25')                     # å¹´é½¢ãŒ25ä»¥ä¸Šã®è¡Œã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
          .groupby('City')                       # éƒ½å¸‚ã”ã¨ã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
          .agg({'Score': 'mean'})                # ã‚¹ã‚³ã‚¢ã®å¹³å‡ã‚’è¨ˆç®—
          .rename(columns={'Score': 'Average Score'})  # åˆ—åã‚’å¤‰æ›´
          .sort_values(by='Average Score', ascending=False)  # å¹³å‡ã‚¹ã‚³ã‚¢ã§ä¸¦ã¹æ›¿ãˆ
          .reset_index()                         # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ãƒªã‚»ãƒƒãƒˆ
         )

print(result)

spanimport
spanas
span# ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
span=
span{
span'Name'
span:
span[
span'Alice'
span,
span'Bob'
span,
span'Charlie'
span,
span'David'
span,
span'Edward'
span,
span'Frank'
span]
span,
span'Age'
span:
span[
span24
span,
span27
span,
span22
span,
span32
span,
span29
span,
span24
span]
span,
span'City'
span:
span[
span'New York'
span,
span'Los Angeles'
span,
span'New York'
span,
span'Chicago'
span,
span'Los Angeles'
span,
span'New York'
span]
span,
span'Score'
span:
span[
span85
span,
span90
span,
span88
span,
span92
span,
span95
span,
span70
span]
span}
span=
span.
span(
span)
span# ãƒ¡ã‚½ãƒƒãƒ‰ãƒã‚§ãƒ¼ãƒ³ã‚’ä½¿ã£ãŸãƒ‡ãƒ¼ã‚¿å¤‰æ›
span=
span(
span.
span(
span'Age > 25'
span)
span# å¹´é½¢ãŒ25ä»¥ä¸Šã®è¡Œã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
span.
span(
span'City'
span)
span# éƒ½å¸‚ã”ã¨ã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
span.
span(
span{
span'Score'
span:
span'mean'
span}
span)
span# ã‚¹ã‚³ã‚¢ã®å¹³å‡ã‚’è¨ˆç®—
span.
span(
span=
span{
span'Score'
span:
span'Average Score'
span}
span)
span# åˆ—åã‚’å¤‰æ›´
span.
span(
span=
span'Average Score'
span,
span=
spanFalse
span)
span# å¹³å‡ã‚¹ã‚³ã‚¢ã§ä¸¦ã¹æ›¿ãˆ
span.
span(
span)
span# ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ãƒªã‚»ãƒƒãƒˆ
span)
spanprint
span(
span)
div    chain = (
        {"context": retriever, "question": RunnablePassthrough()} | prompt | llm
    )

pre    chain = (
        {"context": retriever, "question": RunnablePassthrough()} | prompt | llm
    )

code    chain = (
        {"context": retriever, "question": RunnablePassthrough()} | prompt | llm
    )

span=
span(
span{
span"context"
span:
span,
span"question"
span:
span(
span)
span}
span|
span|
span)
div    prompt = hub.pull("rlm/rag-prompt")

pre    prompt = hub.pull("rlm/rag-prompt")

code    prompt = hub.pull("rlm/rag-prompt")

span=
span.
span(
span"rlm/rag-prompt"
span)
span
divYou are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.
Question: {question} 
Context: {context} 
Answer:

preYou are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.
Question: {question} 
Context: {context} 
Answer:

codeYou are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.
Question: {question} 
Context: {context} 
Answer:

a
divdef main() -> None:
    """ChatGPTã‚’ä½¿ã£ãŸãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã®ãƒ¡ã‚¤ãƒ³é–¢æ•°."""
    chain = initialize_chain()

    # ãƒšãƒ¼ã‚¸ã®è¨­å®š
    st.set_page_config(page_title="RAG ChatGPT")
    st.image(img, use_column_width=False)
    st.header("RAG ChatGPT")

    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®åˆæœŸåŒ–
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ã‚’ç›£è¦–
    if user_input := st.chat_input("èããŸã„ã“ã¨ã‚’å…¥åŠ›ã—ã¦ã­ï¼"):
        st.session_state.messages.append(HumanMessage(content=user_input))
        with st.spinner("GPT is typing ..."):
            response = chain.invoke(user_input)
        st.session_state.messages.append(AIMessage(content=response.content))

    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®è¡¨ç¤º
    messages = st.session_state.get("messages", [])
    for message in messages:
        if isinstance(message, AIMessage):
            with st.chat_message("assistant"):
                st.markdown(message.content)
        elif isinstance(message, HumanMessage):
            with st.chat_message("user"):
                st.markdown(message.content)
        else:
            st.write(f"System message: {message.content}")

predef main() -> None:
    """ChatGPTã‚’ä½¿ã£ãŸãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã®ãƒ¡ã‚¤ãƒ³é–¢æ•°."""
    chain = initialize_chain()

    # ãƒšãƒ¼ã‚¸ã®è¨­å®š
    st.set_page_config(page_title="RAG ChatGPT")
    st.image(img, use_column_width=False)
    st.header("RAG ChatGPT")

    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®åˆæœŸåŒ–
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ã‚’ç›£è¦–
    if user_input := st.chat_input("èããŸã„ã“ã¨ã‚’å…¥åŠ›ã—ã¦ã­ï¼"):
        st.session_state.messages.append(HumanMessage(content=user_input))
        with st.spinner("GPT is typing ..."):
            response = chain.invoke(user_input)
        st.session_state.messages.append(AIMessage(content=response.content))

    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®è¡¨ç¤º
    messages = st.session_state.get("messages", [])
    for message in messages:
        if isinstance(message, AIMessage):
            with st.chat_message("assistant"):
                st.markdown(message.content)
        elif isinstance(message, HumanMessage):
            with st.chat_message("user"):
                st.markdown(message.content)
        else:
            st.write(f"System message: {message.content}")

codedef main() -> None:
    """ChatGPTã‚’ä½¿ã£ãŸãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã®ãƒ¡ã‚¤ãƒ³é–¢æ•°."""
    chain = initialize_chain()

    # ãƒšãƒ¼ã‚¸ã®è¨­å®š
    st.set_page_config(page_title="RAG ChatGPT")
    st.image(img, use_column_width=False)
    st.header("RAG ChatGPT")

    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®åˆæœŸåŒ–
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ã‚’ç›£è¦–
    if user_input := st.chat_input("èããŸã„ã“ã¨ã‚’å…¥åŠ›ã—ã¦ã­ï¼"):
        st.session_state.messages.append(HumanMessage(content=user_input))
        with st.spinner("GPT is typing ..."):
            response = chain.invoke(user_input)
        st.session_state.messages.append(AIMessage(content=response.content))

    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®è¡¨ç¤º
    messages = st.session_state.get("messages", [])
    for message in messages:
        if isinstance(message, AIMessage):
            with st.chat_message("assistant"):
                st.markdown(message.content)
        elif isinstance(message, HumanMessage):
            with st.chat_message("user"):
                st.markdown(message.content)
        else:
            st.write(f"System message: {message.content}")

spandef
spanmain
span(
span)
span-
span>
spanNone
span:
span"""ChatGPTã‚’ä½¿ã£ãŸãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã®ãƒ¡ã‚¤ãƒ³é–¢æ•°."""
span=
span(
span)
span# ãƒšãƒ¼ã‚¸ã®è¨­å®š
span.
span(
span=
span"RAG ChatGPT"
span)
span.
span(
span,
span=
spanFalse
span)
span.
span(
span"RAG ChatGPT"
span)
span# ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®åˆæœŸåŒ–
spanif
span"messages"
spannot
spanin
span.
span:
span.
span.
span=
span[
span]
span# ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ã‚’ç›£è¦–
spanif
span:=
span.
span(
span"èããŸã„ã“ã¨ã‚’å…¥åŠ›ã—ã¦ã­ï¼"
span)
span:
span.
span.
span.
span(
span(
span=
span)
span)
spanwith
span.
span(
span"GPT is typing ..."
span)
span:
span=
span.
span(
span)
span.
span.
span.
span(
span(
span=
span.
span)
span)
span# ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®è¡¨ç¤º
span=
span.
span.
span(
span"messages"
span,
span[
span]
span)
spanfor
spanin
span:
spanif
spanisinstance
span(
span,
span)
span:
spanwith
span.
span(
span"assistant"
span)
span:
span.
span(
span.
span)
spanelif
spanisinstance
span(
span,
span)
span:
spanwith
span.
span(
span"user"
span)
span:
span.
span(
span.
span)
spanelse
span:
span.
span(
spanf"System message: {message.content}"
spanf"System message: 
span{message.content}
span{
span.
span}
span"
span)
div    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®åˆæœŸåŒ–
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ã‚’ç›£è¦–
    if user_input := st.chat_input("èããŸã„ã“ã¨ã‚’å…¥åŠ›ã—ã¦ã­ï¼"):
        st.session_state.messages.append(HumanMessage(content=user_input))
        with st.spinner("GPT is typing ..."):
            response = chain.invoke(user_input)
        st.session_state.messages.append(AIMessage(content=response.content))

pre    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®åˆæœŸåŒ–
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ã‚’ç›£è¦–
    if user_input := st.chat_input("èããŸã„ã“ã¨ã‚’å…¥åŠ›ã—ã¦ã­ï¼"):
        st.session_state.messages.append(HumanMessage(content=user_input))
        with st.spinner("GPT is typing ..."):
            response = chain.invoke(user_input)
        st.session_state.messages.append(AIMessage(content=response.content))

code    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®åˆæœŸåŒ–
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ã‚’ç›£è¦–
    if user_input := st.chat_input("èããŸã„ã“ã¨ã‚’å…¥åŠ›ã—ã¦ã­ï¼"):
        st.session_state.messages.append(HumanMessage(content=user_input))
        with st.spinner("GPT is typing ..."):
            response = chain.invoke(user_input)
        st.session_state.messages.append(AIMessage(content=response.content))

span# ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®åˆæœŸåŒ–
spanif
span"messages"
spannot
spanin
span.
span:
span.
span.
span=
span[
span]
span# ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ã‚’ç›£è¦–
spanif
span:=
span.
span(
span"èããŸã„ã“ã¨ã‚’å…¥åŠ›ã—ã¦ã­ï¼"
span)
span:
span.
span.
span.
span(
span(
span=
span)
span)
spanwith
span.
span(
span"GPT is typing ..."
span)
span:
span=
span.
span(
span)
span.
span.
span.
span(
span(
span=
span.
span)
span)
div        with st.spinner("GPT is typing ..."):
            response = chain.invoke(user_input)
        st.session_state.messages.append(AIMessage(content=response.content))

pre        with st.spinner("GPT is typing ..."):
            response = chain.invoke(user_input)
        st.session_state.messages.append(AIMessage(content=response.content))

code        with st.spinner("GPT is typing ..."):
            response = chain.invoke(user_input)
        st.session_state.messages.append(AIMessage(content=response.content))

spanwith
span.
span(
span"GPT is typing ..."
span)
span:
span=
span.
span(
span)
span.
span.
span.
span(
span(
span=
span.
span)
span)
a
div> streamlit run chatbot.py

Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.


  You can now view your Streamlit app in your browser.

  Local URL: http://localhost:8501
  Network URL: http://10.200.0.4:8501
  External URL: http://13.73.233.61:8501

pre> streamlit run chatbot.py

Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.


  You can now view your Streamlit app in your browser.

  Local URL: http://localhost:8501
  Network URL: http://10.200.0.4:8501
  External URL: http://13.73.233.61:8501

code> streamlit run chatbot.py

Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.


  You can now view your Streamlit app in your browser.

  Local URL: http://localhost:8501
  Network URL: http://10.200.0.4:8501
  External URL: http://13.73.233.61:8501

span>
spanset
spanin
img
img
a
div
div
button
svg
path
path
g
div
button
a
a
a
asideyamasaKitcheminformatics, machine learning, board game
divyamasaKitcheminformatics, machine learning, board game
a
img
divyamasaKit
ayamasaKit
divcheminformatics, machine learning, board game
pcheminformatics, machine learning, board game
div
span
a
a
a
divCykinso's Tech BlogPublicationã€Œç´°èŒå¢ã®åŠ›ã§äººã€…ã‚’å¥åº·ã«ã€ã‚’ãƒŸãƒƒã‚·ãƒ§ãƒ³ã«æ²ã’ã‚‹ãƒã‚¤ã‚ªãƒ†ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆã‚¢ãƒƒãƒ—ã€Œã‚µã‚¤ã‚­ãƒ³ã‚½ãƒ¼ã€ã®æŠ€è¡“ãƒ–ãƒ­ã‚°ã€‚ 
divCykinso's Tech BlogPublicationã€Œç´°èŒå¢ã®åŠ›ã§äººã€…ã‚’å¥åº·ã«ã€ã‚’ãƒŸãƒƒã‚·ãƒ§ãƒ³ã«æ²ã’ã‚‹ãƒã‚¤ã‚ªãƒ†ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆã‚¢ãƒƒãƒ—ã€Œã‚µã‚¤ã‚­ãƒ³ã‚½ãƒ¼ã€ã®æŠ€è¡“ãƒ–ãƒ­ã‚°ã€‚ 
a
img
divCykinso's Tech BlogPublication
aCykinso's Tech Blog
aPublication
divã€Œç´°èŒå¢ã®åŠ›ã§äººã€…ã‚’å¥åº·ã«ã€ã‚’ãƒŸãƒƒã‚·ãƒ§ãƒ³ã«æ²ã’ã‚‹ãƒã‚¤ã‚ªãƒ†ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆã‚¢ãƒƒãƒ—ã€Œã‚µã‚¤ã‚­ãƒ³ã‚½ãƒ¼ã€ã®æŠ€è¡“ãƒ–ãƒ­ã‚°ã€‚ 
pã€Œç´°èŒå¢ã®åŠ›ã§äººã€…ã‚’å¥åº·ã«ã€ã‚’ãƒŸãƒƒã‚·ãƒ§ãƒ³ã«æ²ã’ã‚‹ãƒã‚¤ã‚ªãƒ†ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆã‚¢ãƒƒãƒ—ã€Œã‚µã‚¤ã‚­ãƒ³ã‚½ãƒ¼ã€ã®æŠ€è¡“ãƒ–ãƒ­ã‚°ã€‚ 
div
span
a
a
asideãƒãƒƒã‚¸ã‚’è´ˆã£ã¦è‘—è€…ã‚’å¿œæ´ã—ã‚ˆã†ãƒãƒƒã‚¸ã‚’å—ã‘å–ã£ãŸè‘—è€…ã«ã¯Zennã‹ã‚‰ç¾é‡‘ã‚„Amazonã‚®ãƒ•ãƒˆã‚«ãƒ¼ãƒ‰ãŒé‚„å…ƒã•ã‚Œã¾ã™ã€‚ãƒãƒƒã‚¸ã‚’è´ˆã‚‹
divãƒãƒƒã‚¸ã‚’è´ˆã£ã¦è‘—è€…ã‚’å¿œæ´ã—ã‚ˆã†ãƒãƒƒã‚¸ã‚’å—ã‘å–ã£ãŸè‘—è€…ã«ã¯Zennã‹ã‚‰ç¾é‡‘ã‚„Amazonã‚®ãƒ•ãƒˆã‚«ãƒ¼ãƒ‰ãŒé‚„å…ƒã•ã‚Œã¾ã™ã€‚ãƒãƒƒã‚¸ã‚’è´ˆã‚‹
divãƒãƒƒã‚¸ã‚’è´ˆã£ã¦è‘—è€…ã‚’å¿œæ´ã—ã‚ˆã†
pãƒãƒƒã‚¸ã‚’å—ã‘å–ã£ãŸè‘—è€…ã«ã¯Zennã‹ã‚‰ç¾é‡‘ã‚„Amazonã‚®ãƒ•ãƒˆã‚«ãƒ¼ãƒ‰ãŒé‚„å…ƒã•ã‚Œã¾ã™ã€‚
divãƒãƒƒã‚¸ã‚’è´ˆã‚‹
buttonãƒãƒƒã‚¸ã‚’è´ˆã‚‹
svg
divDiscussion
sectionDiscussion
divDiscussion
h3Discussion
img
asideyamasaKitcheminformatics, machine learning, board gameãƒãƒƒã‚¸ã‚’è´ˆã‚‹ãƒãƒƒã‚¸ã‚’è´ˆã‚‹ã¨ã¯ç›®æ¬¡èƒŒæ™¯ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ãªã©æ–¹æ³•.envãƒ‡ãƒ¼ã‚¿ã‚³ãƒ¼ãƒ‰initialize_vector_storeinitialize_retriverinitialize_chainmainãƒ†ã‚¹ãƒˆğŸ’¡ ã¾ã¨ã‚
divyamasaKitcheminformatics, machine learning, board gameãƒãƒƒã‚¸ã‚’è´ˆã‚‹ãƒãƒƒã‚¸ã‚’è´ˆã‚‹ã¨ã¯ç›®æ¬¡èƒŒæ™¯ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ãªã©æ–¹æ³•.envãƒ‡ãƒ¼ã‚¿ã‚³ãƒ¼ãƒ‰initialize_vector_storeinitialize_retriverinitialize_chainmainãƒ†ã‚¹ãƒˆğŸ’¡ ã¾ã¨ã‚
divyamasaKitcheminformatics, machine learning, board gameãƒãƒƒã‚¸ã‚’è´ˆã‚‹ãƒãƒƒã‚¸ã‚’è´ˆã‚‹ã¨ã¯
divyamasaKit
img
divyamasaKit
ayamasaKit
div
a
a
a
pcheminformatics, machine learning, board game
buttonãƒãƒƒã‚¸ã‚’è´ˆã‚‹
divãƒãƒƒã‚¸ã‚’è´ˆã‚‹ã¨ã¯
aãƒãƒƒã‚¸ã‚’è´ˆã‚‹ã¨ã¯
svg
divç›®æ¬¡èƒŒæ™¯ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ãªã©æ–¹æ³•.envãƒ‡ãƒ¼ã‚¿ã‚³ãƒ¼ãƒ‰initialize_vector_storeinitialize_retriverinitialize_chainmainãƒ†ã‚¹ãƒˆğŸ’¡ ã¾ã¨ã‚
divç›®æ¬¡èƒŒæ™¯ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ãªã©æ–¹æ³•.envãƒ‡ãƒ¼ã‚¿ã‚³ãƒ¼ãƒ‰initialize_vector_storeinitialize_retriverinitialize_chainmainãƒ†ã‚¹ãƒˆğŸ’¡ ã¾ã¨ã‚
divç›®æ¬¡
divèƒŒæ™¯ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ãªã©æ–¹æ³•.envãƒ‡ãƒ¼ã‚¿ã‚³ãƒ¼ãƒ‰initialize_vector_storeinitialize_retriverinitialize_chainmainãƒ†ã‚¹ãƒˆğŸ’¡ ã¾ã¨ã‚
olèƒŒæ™¯ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ãªã©æ–¹æ³•.envãƒ‡ãƒ¼ã‚¿ã‚³ãƒ¼ãƒ‰initialize_vector_storeinitialize_retriverinitialize_chainmainãƒ†ã‚¹ãƒˆğŸ’¡ ã¾ã¨ã‚
ol.envãƒ‡ãƒ¼ã‚¿ã‚³ãƒ¼ãƒ‰initialize_vector_storeinitialize_retriverinitialize_chainmain
footerZennã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã®ãŸã‚ã®æƒ…å ±å…±æœ‰ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£AboutZennã«ã¤ã„ã¦é‹å–¶ä¼šç¤¾ãŠçŸ¥ã‚‰ã›ãƒ»ãƒªãƒªãƒ¼ã‚¹Guidesä½¿ã„æ–¹Publication / ProNewã‚ˆãã‚ã‚‹è³ªå•LinksX(Twitter)GitHubãƒ¡ãƒ‡ã‚£ã‚¢ã‚­ãƒƒãƒˆLegalåˆ©ç”¨è¦ç´„ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ãƒãƒªã‚·ãƒ¼ç‰¹å•†æ³•è¡¨è¨˜
divZennã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã®ãŸã‚ã®æƒ…å ±å…±æœ‰ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£AboutZennã«ã¤ã„ã¦é‹å–¶ä¼šç¤¾ãŠçŸ¥ã‚‰ã›ãƒ»ãƒªãƒªãƒ¼ã‚¹Guidesä½¿ã„æ–¹Publication / ProNewã‚ˆãã‚ã‚‹è³ªå•LinksX(Twitter)GitHubãƒ¡ãƒ‡ã‚£ã‚¢ã‚­ãƒƒãƒˆLegalåˆ©ç”¨è¦ç´„ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ãƒãƒªã‚·ãƒ¼ç‰¹å•†æ³•è¡¨è¨˜
divZennã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã®ãŸã‚ã®æƒ…å ±å…±æœ‰ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£AboutZennã«ã¤ã„ã¦é‹å–¶ä¼šç¤¾ãŠçŸ¥ã‚‰ã›ãƒ»ãƒªãƒªãƒ¼ã‚¹Guidesä½¿ã„æ–¹Publication / ProNewã‚ˆãã‚ã‚‹è³ªå•LinksX(Twitter)GitHubãƒ¡ãƒ‡ã‚£ã‚¢ã‚­ãƒƒãƒˆLegalåˆ©ç”¨è¦ç´„ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ãƒãƒªã‚·ãƒ¼ç‰¹å•†æ³•è¡¨è¨˜
divZennã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã®ãŸã‚ã®æƒ…å ±å…±æœ‰ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£
path
path
pã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã®ãŸã‚ã®æƒ…å ±å…±æœ‰ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£
divAboutZennã«ã¤ã„ã¦é‹å–¶ä¼šç¤¾ãŠçŸ¥ã‚‰ã›ãƒ»ãƒªãƒªãƒ¼ã‚¹Guidesä½¿ã„æ–¹Publication / ProNewã‚ˆãã‚ã‚‹è³ªå•LinksX(Twitter)GitHubãƒ¡ãƒ‡ã‚£ã‚¢ã‚­ãƒƒãƒˆLegalåˆ©ç”¨è¦ç´„ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ãƒãƒªã‚·ãƒ¼ç‰¹å•†æ³•è¡¨è¨˜
navAboutZennã«ã¤ã„ã¦é‹å–¶ä¼šç¤¾ãŠçŸ¥ã‚‰ã›ãƒ»ãƒªãƒªãƒ¼ã‚¹
h4About
navGuidesä½¿ã„æ–¹Publication / ProNewã‚ˆãã‚ã‚‹è³ªå•
h4Guides
spanNew
navLinksX(Twitter)GitHubãƒ¡ãƒ‡ã‚£ã‚¢ã‚­ãƒƒãƒˆ
h4Links
navLegalåˆ©ç”¨è¦ç´„ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ãƒãƒªã‚·ãƒ¼ç‰¹å•†æ³•è¡¨è¨˜
h4Legal
div
div
div
